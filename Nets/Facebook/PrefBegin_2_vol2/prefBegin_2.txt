I1130 16:45:18.795912 28372 caffe.cpp:217] Using GPUs 0
I1130 16:45:18.809289 28372 caffe.cpp:222] GPU 0: GeForce GTX TITAN X
I1130 16:45:19.464915 28372 solver.cpp:48] Initializing solver from parameters: 
test_iter: 240
test_interval: 200
base_lr: 0.001
display: 50
max_iter: 30000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 5000
snapshot: 10000
snapshot_prefix: "/home/tbochens/Nets/FineTuning/Facebook/thumb_2/solver2/facebook_solv2"
solver_mode: GPU
device_id: 0
random_seed: 7341
net: "/home/tbochens/Nets/FineTuning/Facebook/thumb_2/train_val.prototxt"
train_state {
  level: 0
  stage: ""
}
I1130 16:45:19.465128 28372 solver.cpp:91] Creating training net from net file: /home/tbochens/Nets/FineTuning/Facebook/thumb_2/train_val.prototxt
I1130 16:45:19.465553 28372 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1130 16:45:19.465577 28372 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1130 16:45:19.465761 28372 net.cpp:58] Initializing net from parameters: 
name: "VideoPopularityCaffeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/tbochens/Nets/FineTuning/imagenet_mean.binaryproto"
  }
  data_param {
    source: "/home/tbochens/Nets/FineTuning/Facebook/thumb_2/train_thumb_2_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_2"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_2"
  param {
    lr_mult: 7
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_2"
  bottom: "label"
  top: "loss"
}
I1130 16:45:19.465894 28372 layer_factory.hpp:77] Creating layer data
I1130 16:45:19.466073 28372 net.cpp:100] Creating Layer data
I1130 16:45:19.466085 28372 net.cpp:408] data -> data
I1130 16:45:19.466119 28372 net.cpp:408] data -> label
I1130 16:45:19.466140 28372 data_transformer.cpp:25] Loading mean file from: /home/tbochens/Nets/FineTuning/imagenet_mean.binaryproto
I1130 16:45:19.467864 28380 db_lmdb.cpp:35] Opened lmdb /home/tbochens/Nets/FineTuning/Facebook/thumb_2/train_thumb_2_lmdb
I1130 16:45:19.487668 28372 data_layer.cpp:41] output data size: 64,3,227,227
I1130 16:45:19.585844 28372 net.cpp:150] Setting up data
I1130 16:45:19.585889 28372 net.cpp:157] Top shape: 64 3 227 227 (9893568)
I1130 16:45:19.585894 28372 net.cpp:157] Top shape: 64 (64)
I1130 16:45:19.585897 28372 net.cpp:165] Memory required for data: 39574528
I1130 16:45:19.585914 28372 layer_factory.hpp:77] Creating layer conv1
I1130 16:45:19.585949 28372 net.cpp:100] Creating Layer conv1
I1130 16:45:19.585955 28372 net.cpp:434] conv1 <- data
I1130 16:45:19.585975 28372 net.cpp:408] conv1 -> conv1
I1130 16:45:19.821226 28372 net.cpp:150] Setting up conv1
I1130 16:45:19.821271 28372 net.cpp:157] Top shape: 64 96 55 55 (18585600)
I1130 16:45:19.821275 28372 net.cpp:165] Memory required for data: 113916928
I1130 16:45:19.821312 28372 layer_factory.hpp:77] Creating layer relu1
I1130 16:45:19.821329 28372 net.cpp:100] Creating Layer relu1
I1130 16:45:19.821333 28372 net.cpp:434] relu1 <- conv1
I1130 16:45:19.821341 28372 net.cpp:395] relu1 -> conv1 (in-place)
I1130 16:45:19.821688 28372 net.cpp:150] Setting up relu1
I1130 16:45:19.821704 28372 net.cpp:157] Top shape: 64 96 55 55 (18585600)
I1130 16:45:19.821707 28372 net.cpp:165] Memory required for data: 188259328
I1130 16:45:19.821712 28372 layer_factory.hpp:77] Creating layer pool1
I1130 16:45:19.821720 28372 net.cpp:100] Creating Layer pool1
I1130 16:45:19.821723 28372 net.cpp:434] pool1 <- conv1
I1130 16:45:19.821729 28372 net.cpp:408] pool1 -> pool1
I1130 16:45:19.821792 28372 net.cpp:150] Setting up pool1
I1130 16:45:19.821799 28372 net.cpp:157] Top shape: 64 96 27 27 (4478976)
I1130 16:45:19.821801 28372 net.cpp:165] Memory required for data: 206175232
I1130 16:45:19.821828 28372 layer_factory.hpp:77] Creating layer norm1
I1130 16:45:19.821842 28372 net.cpp:100] Creating Layer norm1
I1130 16:45:19.821846 28372 net.cpp:434] norm1 <- pool1
I1130 16:45:19.821851 28372 net.cpp:408] norm1 -> norm1
I1130 16:45:19.822060 28372 net.cpp:150] Setting up norm1
I1130 16:45:19.822074 28372 net.cpp:157] Top shape: 64 96 27 27 (4478976)
I1130 16:45:19.822077 28372 net.cpp:165] Memory required for data: 224091136
I1130 16:45:19.822079 28372 layer_factory.hpp:77] Creating layer conv2
I1130 16:45:19.822094 28372 net.cpp:100] Creating Layer conv2
I1130 16:45:19.822098 28372 net.cpp:434] conv2 <- norm1
I1130 16:45:19.822103 28372 net.cpp:408] conv2 -> conv2
I1130 16:45:19.828588 28372 net.cpp:150] Setting up conv2
I1130 16:45:19.828605 28372 net.cpp:157] Top shape: 64 256 27 27 (11943936)
I1130 16:45:19.828608 28372 net.cpp:165] Memory required for data: 271866880
I1130 16:45:19.828618 28372 layer_factory.hpp:77] Creating layer relu2
I1130 16:45:19.828624 28372 net.cpp:100] Creating Layer relu2
I1130 16:45:19.828627 28372 net.cpp:434] relu2 <- conv2
I1130 16:45:19.828634 28372 net.cpp:395] relu2 -> conv2 (in-place)
I1130 16:45:19.828817 28372 net.cpp:150] Setting up relu2
I1130 16:45:19.828830 28372 net.cpp:157] Top shape: 64 256 27 27 (11943936)
I1130 16:45:19.828832 28372 net.cpp:165] Memory required for data: 319642624
I1130 16:45:19.828835 28372 layer_factory.hpp:77] Creating layer pool2
I1130 16:45:19.828842 28372 net.cpp:100] Creating Layer pool2
I1130 16:45:19.828845 28372 net.cpp:434] pool2 <- conv2
I1130 16:45:19.828850 28372 net.cpp:408] pool2 -> pool2
I1130 16:45:19.828893 28372 net.cpp:150] Setting up pool2
I1130 16:45:19.828899 28372 net.cpp:157] Top shape: 64 256 13 13 (2768896)
I1130 16:45:19.828902 28372 net.cpp:165] Memory required for data: 330718208
I1130 16:45:19.828904 28372 layer_factory.hpp:77] Creating layer norm2
I1130 16:45:19.828912 28372 net.cpp:100] Creating Layer norm2
I1130 16:45:19.828913 28372 net.cpp:434] norm2 <- pool2
I1130 16:45:19.828917 28372 net.cpp:408] norm2 -> norm2
I1130 16:45:19.829272 28372 net.cpp:150] Setting up norm2
I1130 16:45:19.829287 28372 net.cpp:157] Top shape: 64 256 13 13 (2768896)
I1130 16:45:19.829289 28372 net.cpp:165] Memory required for data: 341793792
I1130 16:45:19.829293 28372 layer_factory.hpp:77] Creating layer conv3
I1130 16:45:19.829303 28372 net.cpp:100] Creating Layer conv3
I1130 16:45:19.829305 28372 net.cpp:434] conv3 <- norm2
I1130 16:45:19.829311 28372 net.cpp:408] conv3 -> conv3
I1130 16:45:19.841900 28372 net.cpp:150] Setting up conv3
I1130 16:45:19.841918 28372 net.cpp:157] Top shape: 64 384 13 13 (4153344)
I1130 16:45:19.841922 28372 net.cpp:165] Memory required for data: 358407168
I1130 16:45:19.841933 28372 layer_factory.hpp:77] Creating layer relu3
I1130 16:45:19.841940 28372 net.cpp:100] Creating Layer relu3
I1130 16:45:19.841943 28372 net.cpp:434] relu3 <- conv3
I1130 16:45:19.841950 28372 net.cpp:395] relu3 -> conv3 (in-place)
I1130 16:45:19.842154 28372 net.cpp:150] Setting up relu3
I1130 16:45:19.842166 28372 net.cpp:157] Top shape: 64 384 13 13 (4153344)
I1130 16:45:19.842169 28372 net.cpp:165] Memory required for data: 375020544
I1130 16:45:19.842172 28372 layer_factory.hpp:77] Creating layer conv4
I1130 16:45:19.842183 28372 net.cpp:100] Creating Layer conv4
I1130 16:45:19.842186 28372 net.cpp:434] conv4 <- conv3
I1130 16:45:19.842193 28372 net.cpp:408] conv4 -> conv4
I1130 16:45:19.852893 28372 net.cpp:150] Setting up conv4
I1130 16:45:19.852913 28372 net.cpp:157] Top shape: 64 384 13 13 (4153344)
I1130 16:45:19.852917 28372 net.cpp:165] Memory required for data: 391633920
I1130 16:45:19.852924 28372 layer_factory.hpp:77] Creating layer relu4
I1130 16:45:19.852931 28372 net.cpp:100] Creating Layer relu4
I1130 16:45:19.852933 28372 net.cpp:434] relu4 <- conv4
I1130 16:45:19.852942 28372 net.cpp:395] relu4 -> conv4 (in-place)
I1130 16:45:19.853174 28372 net.cpp:150] Setting up relu4
I1130 16:45:19.853188 28372 net.cpp:157] Top shape: 64 384 13 13 (4153344)
I1130 16:45:19.853205 28372 net.cpp:165] Memory required for data: 408247296
I1130 16:45:19.853209 28372 layer_factory.hpp:77] Creating layer conv5
I1130 16:45:19.853221 28372 net.cpp:100] Creating Layer conv5
I1130 16:45:19.853236 28372 net.cpp:434] conv5 <- conv4
I1130 16:45:19.853247 28372 net.cpp:408] conv5 -> conv5
I1130 16:45:19.861368 28372 net.cpp:150] Setting up conv5
I1130 16:45:19.861385 28372 net.cpp:157] Top shape: 64 256 13 13 (2768896)
I1130 16:45:19.861388 28372 net.cpp:165] Memory required for data: 419322880
I1130 16:45:19.861400 28372 layer_factory.hpp:77] Creating layer relu5
I1130 16:45:19.861407 28372 net.cpp:100] Creating Layer relu5
I1130 16:45:19.861412 28372 net.cpp:434] relu5 <- conv5
I1130 16:45:19.861418 28372 net.cpp:395] relu5 -> conv5 (in-place)
I1130 16:45:19.861776 28372 net.cpp:150] Setting up relu5
I1130 16:45:19.861791 28372 net.cpp:157] Top shape: 64 256 13 13 (2768896)
I1130 16:45:19.861794 28372 net.cpp:165] Memory required for data: 430398464
I1130 16:45:19.861798 28372 layer_factory.hpp:77] Creating layer pool5
I1130 16:45:19.861804 28372 net.cpp:100] Creating Layer pool5
I1130 16:45:19.861807 28372 net.cpp:434] pool5 <- conv5
I1130 16:45:19.861814 28372 net.cpp:408] pool5 -> pool5
I1130 16:45:19.861866 28372 net.cpp:150] Setting up pool5
I1130 16:45:19.861872 28372 net.cpp:157] Top shape: 64 256 6 6 (589824)
I1130 16:45:19.861874 28372 net.cpp:165] Memory required for data: 432757760
I1130 16:45:19.861877 28372 layer_factory.hpp:77] Creating layer fc6
I1130 16:45:19.861891 28372 net.cpp:100] Creating Layer fc6
I1130 16:45:19.861894 28372 net.cpp:434] fc6 <- pool5
I1130 16:45:19.861898 28372 net.cpp:408] fc6 -> fc6
I1130 16:45:20.370738 28372 net.cpp:150] Setting up fc6
I1130 16:45:20.370792 28372 net.cpp:157] Top shape: 64 4096 (262144)
I1130 16:45:20.370797 28372 net.cpp:165] Memory required for data: 433806336
I1130 16:45:20.370827 28372 layer_factory.hpp:77] Creating layer relu6
I1130 16:45:20.370883 28372 net.cpp:100] Creating Layer relu6
I1130 16:45:20.370908 28372 net.cpp:434] relu6 <- fc6
I1130 16:45:20.370919 28372 net.cpp:395] relu6 -> fc6 (in-place)
I1130 16:45:20.371361 28372 net.cpp:150] Setting up relu6
I1130 16:45:20.371374 28372 net.cpp:157] Top shape: 64 4096 (262144)
I1130 16:45:20.371377 28372 net.cpp:165] Memory required for data: 434854912
I1130 16:45:20.371381 28372 layer_factory.hpp:77] Creating layer drop6
I1130 16:45:20.371409 28372 net.cpp:100] Creating Layer drop6
I1130 16:45:20.371413 28372 net.cpp:434] drop6 <- fc6
I1130 16:45:20.371420 28372 net.cpp:395] drop6 -> fc6 (in-place)
I1130 16:45:20.371461 28372 net.cpp:150] Setting up drop6
I1130 16:45:20.371466 28372 net.cpp:157] Top shape: 64 4096 (262144)
I1130 16:45:20.371469 28372 net.cpp:165] Memory required for data: 435903488
I1130 16:45:20.371471 28372 layer_factory.hpp:77] Creating layer fc7
I1130 16:45:20.371484 28372 net.cpp:100] Creating Layer fc7
I1130 16:45:20.371487 28372 net.cpp:434] fc7 <- fc6
I1130 16:45:20.371495 28372 net.cpp:408] fc7 -> fc7
I1130 16:45:20.554496 28372 net.cpp:150] Setting up fc7
I1130 16:45:20.554538 28372 net.cpp:157] Top shape: 64 4096 (262144)
I1130 16:45:20.554540 28372 net.cpp:165] Memory required for data: 436952064
I1130 16:45:20.554564 28372 layer_factory.hpp:77] Creating layer relu7
I1130 16:45:20.554594 28372 net.cpp:100] Creating Layer relu7
I1130 16:45:20.554599 28372 net.cpp:434] relu7 <- fc7
I1130 16:45:20.554607 28372 net.cpp:395] relu7 -> fc7 (in-place)
I1130 16:45:20.555234 28372 net.cpp:150] Setting up relu7
I1130 16:45:20.555248 28372 net.cpp:157] Top shape: 64 4096 (262144)
I1130 16:45:20.555249 28372 net.cpp:165] Memory required for data: 438000640
I1130 16:45:20.555251 28372 layer_factory.hpp:77] Creating layer drop7
I1130 16:45:20.555258 28372 net.cpp:100] Creating Layer drop7
I1130 16:45:20.555272 28372 net.cpp:434] drop7 <- fc7
I1130 16:45:20.555280 28372 net.cpp:395] drop7 -> fc7 (in-place)
I1130 16:45:20.555308 28372 net.cpp:150] Setting up drop7
I1130 16:45:20.555318 28372 net.cpp:157] Top shape: 64 4096 (262144)
I1130 16:45:20.555352 28372 net.cpp:165] Memory required for data: 439049216
I1130 16:45:20.555356 28372 layer_factory.hpp:77] Creating layer fc8_2
I1130 16:45:20.555377 28372 net.cpp:100] Creating Layer fc8_2
I1130 16:45:20.555378 28372 net.cpp:434] fc8_2 <- fc7
I1130 16:45:20.555384 28372 net.cpp:408] fc8_2 -> fc8_2
I1130 16:45:20.556155 28372 net.cpp:150] Setting up fc8_2
I1130 16:45:20.556167 28372 net.cpp:157] Top shape: 64 2 (128)
I1130 16:45:20.556169 28372 net.cpp:165] Memory required for data: 439049728
I1130 16:45:20.556175 28372 layer_factory.hpp:77] Creating layer loss
I1130 16:45:20.556195 28372 net.cpp:100] Creating Layer loss
I1130 16:45:20.556197 28372 net.cpp:434] loss <- fc8_2
I1130 16:45:20.556200 28372 net.cpp:434] loss <- label
I1130 16:45:20.556226 28372 net.cpp:408] loss -> loss
I1130 16:45:20.556252 28372 layer_factory.hpp:77] Creating layer loss
I1130 16:45:20.556522 28372 net.cpp:150] Setting up loss
I1130 16:45:20.556534 28372 net.cpp:157] Top shape: (1)
I1130 16:45:20.556535 28372 net.cpp:160]     with loss weight 1
I1130 16:45:20.556591 28372 net.cpp:165] Memory required for data: 439049732
I1130 16:45:20.556593 28372 net.cpp:226] loss needs backward computation.
I1130 16:45:20.556602 28372 net.cpp:226] fc8_2 needs backward computation.
I1130 16:45:20.556603 28372 net.cpp:226] drop7 needs backward computation.
I1130 16:45:20.556605 28372 net.cpp:226] relu7 needs backward computation.
I1130 16:45:20.556607 28372 net.cpp:226] fc7 needs backward computation.
I1130 16:45:20.556618 28372 net.cpp:226] drop6 needs backward computation.
I1130 16:45:20.556620 28372 net.cpp:226] relu6 needs backward computation.
I1130 16:45:20.556622 28372 net.cpp:226] fc6 needs backward computation.
I1130 16:45:20.556625 28372 net.cpp:226] pool5 needs backward computation.
I1130 16:45:20.556627 28372 net.cpp:226] relu5 needs backward computation.
I1130 16:45:20.556630 28372 net.cpp:226] conv5 needs backward computation.
I1130 16:45:20.556634 28372 net.cpp:226] relu4 needs backward computation.
I1130 16:45:20.556638 28372 net.cpp:226] conv4 needs backward computation.
I1130 16:45:20.556640 28372 net.cpp:226] relu3 needs backward computation.
I1130 16:45:20.556643 28372 net.cpp:226] conv3 needs backward computation.
I1130 16:45:20.556645 28372 net.cpp:226] norm2 needs backward computation.
I1130 16:45:20.556648 28372 net.cpp:226] pool2 needs backward computation.
I1130 16:45:20.556651 28372 net.cpp:226] relu2 needs backward computation.
I1130 16:45:20.556654 28372 net.cpp:226] conv2 needs backward computation.
I1130 16:45:20.556658 28372 net.cpp:226] norm1 needs backward computation.
I1130 16:45:20.556660 28372 net.cpp:226] pool1 needs backward computation.
I1130 16:45:20.556663 28372 net.cpp:226] relu1 needs backward computation.
I1130 16:45:20.556665 28372 net.cpp:226] conv1 needs backward computation.
I1130 16:45:20.556669 28372 net.cpp:228] data does not need backward computation.
I1130 16:45:20.556671 28372 net.cpp:270] This network produces output loss
I1130 16:45:20.556686 28372 net.cpp:283] Network initialization done.
I1130 16:45:20.557184 28372 solver.cpp:181] Creating test net (#0) specified by net file: /home/tbochens/Nets/FineTuning/Facebook/thumb_2/train_val.prototxt
I1130 16:45:20.557231 28372 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1130 16:45:20.557387 28372 net.cpp:58] Initializing net from parameters: 
name: "VideoPopularityCaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "/home/tbochens/Nets/FineTuning/imagenet_mean.binaryproto"
  }
  data_param {
    source: "/home/tbochens/Nets/FineTuning/Facebook/thumb_2/val_thumb_2_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8_2"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8_2"
  param {
    lr_mult: 7
    decay_mult: 1
  }
  param {
    lr_mult: 20
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8_2"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8_2"
  bottom: "label"
  top: "loss"
}
I1130 16:45:20.557500 28372 layer_factory.hpp:77] Creating layer data
I1130 16:45:20.557621 28372 net.cpp:100] Creating Layer data
I1130 16:45:20.557637 28372 net.cpp:408] data -> data
I1130 16:45:20.557646 28372 net.cpp:408] data -> label
I1130 16:45:20.557653 28372 data_transformer.cpp:25] Loading mean file from: /home/tbochens/Nets/FineTuning/imagenet_mean.binaryproto
I1130 16:45:20.559299 28467 db_lmdb.cpp:35] Opened lmdb /home/tbochens/Nets/FineTuning/Facebook/thumb_2/val_thumb_2_lmdb
I1130 16:45:20.560281 28372 data_layer.cpp:41] output data size: 64,3,227,227
I1130 16:45:20.644964 28372 net.cpp:150] Setting up data
I1130 16:45:20.645009 28372 net.cpp:157] Top shape: 64 3 227 227 (9893568)
I1130 16:45:20.645014 28372 net.cpp:157] Top shape: 64 (64)
I1130 16:45:20.645015 28372 net.cpp:165] Memory required for data: 39574528
I1130 16:45:20.645022 28372 layer_factory.hpp:77] Creating layer label_data_1_split
I1130 16:45:20.645037 28372 net.cpp:100] Creating Layer label_data_1_split
I1130 16:45:20.645040 28372 net.cpp:434] label_data_1_split <- label
I1130 16:45:20.645048 28372 net.cpp:408] label_data_1_split -> label_data_1_split_0
I1130 16:45:20.645068 28372 net.cpp:408] label_data_1_split -> label_data_1_split_1
I1130 16:45:20.645187 28372 net.cpp:150] Setting up label_data_1_split
I1130 16:45:20.645196 28372 net.cpp:157] Top shape: 64 (64)
I1130 16:45:20.645198 28372 net.cpp:157] Top shape: 64 (64)
I1130 16:45:20.645200 28372 net.cpp:165] Memory required for data: 39575040
I1130 16:45:20.645203 28372 layer_factory.hpp:77] Creating layer conv1
I1130 16:45:20.645217 28372 net.cpp:100] Creating Layer conv1
I1130 16:45:20.645220 28372 net.cpp:434] conv1 <- data
I1130 16:45:20.645226 28372 net.cpp:408] conv1 -> conv1
I1130 16:45:20.646855 28372 net.cpp:150] Setting up conv1
I1130 16:45:20.646868 28372 net.cpp:157] Top shape: 64 96 55 55 (18585600)
I1130 16:45:20.646883 28372 net.cpp:165] Memory required for data: 113917440
I1130 16:45:20.646893 28372 layer_factory.hpp:77] Creating layer relu1
I1130 16:45:20.646899 28372 net.cpp:100] Creating Layer relu1
I1130 16:45:20.646903 28372 net.cpp:434] relu1 <- conv1
I1130 16:45:20.646908 28372 net.cpp:395] relu1 -> conv1 (in-place)
I1130 16:45:20.653334 28372 net.cpp:150] Setting up relu1
I1130 16:45:20.653360 28372 net.cpp:157] Top shape: 64 96 55 55 (18585600)
I1130 16:45:20.653362 28372 net.cpp:165] Memory required for data: 188259840
I1130 16:45:20.653365 28372 layer_factory.hpp:77] Creating layer pool1
I1130 16:45:20.653374 28372 net.cpp:100] Creating Layer pool1
I1130 16:45:20.653378 28372 net.cpp:434] pool1 <- conv1
I1130 16:45:20.653383 28372 net.cpp:408] pool1 -> pool1
I1130 16:45:20.653444 28372 net.cpp:150] Setting up pool1
I1130 16:45:20.653447 28372 net.cpp:157] Top shape: 64 96 27 27 (4478976)
I1130 16:45:20.653450 28372 net.cpp:165] Memory required for data: 206175744
I1130 16:45:20.653451 28372 layer_factory.hpp:77] Creating layer norm1
I1130 16:45:20.653458 28372 net.cpp:100] Creating Layer norm1
I1130 16:45:20.653460 28372 net.cpp:434] norm1 <- pool1
I1130 16:45:20.653465 28372 net.cpp:408] norm1 -> norm1
I1130 16:45:20.653645 28372 net.cpp:150] Setting up norm1
I1130 16:45:20.653656 28372 net.cpp:157] Top shape: 64 96 27 27 (4478976)
I1130 16:45:20.653658 28372 net.cpp:165] Memory required for data: 224091648
I1130 16:45:20.653661 28372 layer_factory.hpp:77] Creating layer conv2
I1130 16:45:20.653669 28372 net.cpp:100] Creating Layer conv2
I1130 16:45:20.653671 28372 net.cpp:434] conv2 <- norm1
I1130 16:45:20.653677 28372 net.cpp:408] conv2 -> conv2
I1130 16:45:20.658617 28372 net.cpp:150] Setting up conv2
I1130 16:45:20.658632 28372 net.cpp:157] Top shape: 64 256 27 27 (11943936)
I1130 16:45:20.658645 28372 net.cpp:165] Memory required for data: 271867392
I1130 16:45:20.658675 28372 layer_factory.hpp:77] Creating layer relu2
I1130 16:45:20.658682 28372 net.cpp:100] Creating Layer relu2
I1130 16:45:20.658685 28372 net.cpp:434] relu2 <- conv2
I1130 16:45:20.658701 28372 net.cpp:395] relu2 -> conv2 (in-place)
I1130 16:45:20.658895 28372 net.cpp:150] Setting up relu2
I1130 16:45:20.658905 28372 net.cpp:157] Top shape: 64 256 27 27 (11943936)
I1130 16:45:20.658907 28372 net.cpp:165] Memory required for data: 319643136
I1130 16:45:20.658910 28372 layer_factory.hpp:77] Creating layer pool2
I1130 16:45:20.658917 28372 net.cpp:100] Creating Layer pool2
I1130 16:45:20.658920 28372 net.cpp:434] pool2 <- conv2
I1130 16:45:20.658926 28372 net.cpp:408] pool2 -> pool2
I1130 16:45:20.658969 28372 net.cpp:150] Setting up pool2
I1130 16:45:20.658974 28372 net.cpp:157] Top shape: 64 256 13 13 (2768896)
I1130 16:45:20.658977 28372 net.cpp:165] Memory required for data: 330718720
I1130 16:45:20.658978 28372 layer_factory.hpp:77] Creating layer norm2
I1130 16:45:20.658983 28372 net.cpp:100] Creating Layer norm2
I1130 16:45:20.658987 28372 net.cpp:434] norm2 <- pool2
I1130 16:45:20.658990 28372 net.cpp:408] norm2 -> norm2
I1130 16:45:20.659312 28372 net.cpp:150] Setting up norm2
I1130 16:45:20.659345 28372 net.cpp:157] Top shape: 64 256 13 13 (2768896)
I1130 16:45:20.659348 28372 net.cpp:165] Memory required for data: 341794304
I1130 16:45:20.659350 28372 layer_factory.hpp:77] Creating layer conv3
I1130 16:45:20.659370 28372 net.cpp:100] Creating Layer conv3
I1130 16:45:20.659373 28372 net.cpp:434] conv3 <- norm2
I1130 16:45:20.659384 28372 net.cpp:408] conv3 -> conv3
I1130 16:45:20.669736 28372 net.cpp:150] Setting up conv3
I1130 16:45:20.669751 28372 net.cpp:157] Top shape: 64 384 13 13 (4153344)
I1130 16:45:20.669765 28372 net.cpp:165] Memory required for data: 358407680
I1130 16:45:20.669773 28372 layer_factory.hpp:77] Creating layer relu3
I1130 16:45:20.669780 28372 net.cpp:100] Creating Layer relu3
I1130 16:45:20.669782 28372 net.cpp:434] relu3 <- conv3
I1130 16:45:20.669786 28372 net.cpp:395] relu3 -> conv3 (in-place)
I1130 16:45:20.669957 28372 net.cpp:150] Setting up relu3
I1130 16:45:20.669967 28372 net.cpp:157] Top shape: 64 384 13 13 (4153344)
I1130 16:45:20.669970 28372 net.cpp:165] Memory required for data: 375021056
I1130 16:45:20.669972 28372 layer_factory.hpp:77] Creating layer conv4
I1130 16:45:20.669981 28372 net.cpp:100] Creating Layer conv4
I1130 16:45:20.669983 28372 net.cpp:434] conv4 <- conv3
I1130 16:45:20.669989 28372 net.cpp:408] conv4 -> conv4
I1130 16:45:20.678776 28372 net.cpp:150] Setting up conv4
I1130 16:45:20.678803 28372 net.cpp:157] Top shape: 64 384 13 13 (4153344)
I1130 16:45:20.678805 28372 net.cpp:165] Memory required for data: 391634432
I1130 16:45:20.678812 28372 layer_factory.hpp:77] Creating layer relu4
I1130 16:45:20.678817 28372 net.cpp:100] Creating Layer relu4
I1130 16:45:20.678819 28372 net.cpp:434] relu4 <- conv4
I1130 16:45:20.678824 28372 net.cpp:395] relu4 -> conv4 (in-place)
I1130 16:45:20.679018 28372 net.cpp:150] Setting up relu4
I1130 16:45:20.679028 28372 net.cpp:157] Top shape: 64 384 13 13 (4153344)
I1130 16:45:20.679031 28372 net.cpp:165] Memory required for data: 408247808
I1130 16:45:20.679033 28372 layer_factory.hpp:77] Creating layer conv5
I1130 16:45:20.679041 28372 net.cpp:100] Creating Layer conv5
I1130 16:45:20.679044 28372 net.cpp:434] conv5 <- conv4
I1130 16:45:20.679050 28372 net.cpp:408] conv5 -> conv5
I1130 16:45:20.685420 28372 net.cpp:150] Setting up conv5
I1130 16:45:20.685433 28372 net.cpp:157] Top shape: 64 256 13 13 (2768896)
I1130 16:45:20.685447 28372 net.cpp:165] Memory required for data: 419323392
I1130 16:45:20.685456 28372 layer_factory.hpp:77] Creating layer relu5
I1130 16:45:20.685461 28372 net.cpp:100] Creating Layer relu5
I1130 16:45:20.685464 28372 net.cpp:434] relu5 <- conv5
I1130 16:45:20.685469 28372 net.cpp:395] relu5 -> conv5 (in-place)
I1130 16:45:20.685649 28372 net.cpp:150] Setting up relu5
I1130 16:45:20.685659 28372 net.cpp:157] Top shape: 64 256 13 13 (2768896)
I1130 16:45:20.685689 28372 net.cpp:165] Memory required for data: 430398976
I1130 16:45:20.685693 28372 layer_factory.hpp:77] Creating layer pool5
I1130 16:45:20.685701 28372 net.cpp:100] Creating Layer pool5
I1130 16:45:20.685704 28372 net.cpp:434] pool5 <- conv5
I1130 16:45:20.685708 28372 net.cpp:408] pool5 -> pool5
I1130 16:45:20.685757 28372 net.cpp:150] Setting up pool5
I1130 16:45:20.685763 28372 net.cpp:157] Top shape: 64 256 6 6 (589824)
I1130 16:45:20.685765 28372 net.cpp:165] Memory required for data: 432758272
I1130 16:45:20.685767 28372 layer_factory.hpp:77] Creating layer fc6
I1130 16:45:20.685775 28372 net.cpp:100] Creating Layer fc6
I1130 16:45:20.685777 28372 net.cpp:434] fc6 <- pool5
I1130 16:45:20.685782 28372 net.cpp:408] fc6 -> fc6
I1130 16:45:21.084792 28372 net.cpp:150] Setting up fc6
I1130 16:45:21.084837 28372 net.cpp:157] Top shape: 64 4096 (262144)
I1130 16:45:21.084841 28372 net.cpp:165] Memory required for data: 433806848
I1130 16:45:21.084852 28372 layer_factory.hpp:77] Creating layer relu6
I1130 16:45:21.084866 28372 net.cpp:100] Creating Layer relu6
I1130 16:45:21.084868 28372 net.cpp:434] relu6 <- fc6
I1130 16:45:21.084877 28372 net.cpp:395] relu6 -> fc6 (in-place)
I1130 16:45:21.085420 28372 net.cpp:150] Setting up relu6
I1130 16:45:21.085443 28372 net.cpp:157] Top shape: 64 4096 (262144)
I1130 16:45:21.085445 28372 net.cpp:165] Memory required for data: 434855424
I1130 16:45:21.085448 28372 layer_factory.hpp:77] Creating layer drop6
I1130 16:45:21.085466 28372 net.cpp:100] Creating Layer drop6
I1130 16:45:21.085469 28372 net.cpp:434] drop6 <- fc6
I1130 16:45:21.085474 28372 net.cpp:395] drop6 -> fc6 (in-place)
I1130 16:45:21.085515 28372 net.cpp:150] Setting up drop6
I1130 16:45:21.085520 28372 net.cpp:157] Top shape: 64 4096 (262144)
I1130 16:45:21.085522 28372 net.cpp:165] Memory required for data: 435904000
I1130 16:45:21.085523 28372 layer_factory.hpp:77] Creating layer fc7
I1130 16:45:21.085531 28372 net.cpp:100] Creating Layer fc7
I1130 16:45:21.085533 28372 net.cpp:434] fc7 <- fc6
I1130 16:45:21.085538 28372 net.cpp:408] fc7 -> fc7
I1130 16:45:21.257485 28372 net.cpp:150] Setting up fc7
I1130 16:45:21.257527 28372 net.cpp:157] Top shape: 64 4096 (262144)
I1130 16:45:21.257530 28372 net.cpp:165] Memory required for data: 436952576
I1130 16:45:21.257544 28372 layer_factory.hpp:77] Creating layer relu7
I1130 16:45:21.257555 28372 net.cpp:100] Creating Layer relu7
I1130 16:45:21.257560 28372 net.cpp:434] relu7 <- fc7
I1130 16:45:21.257566 28372 net.cpp:395] relu7 -> fc7 (in-place)
I1130 16:45:21.257824 28372 net.cpp:150] Setting up relu7
I1130 16:45:21.257835 28372 net.cpp:157] Top shape: 64 4096 (262144)
I1130 16:45:21.257838 28372 net.cpp:165] Memory required for data: 438001152
I1130 16:45:21.257840 28372 layer_factory.hpp:77] Creating layer drop7
I1130 16:45:21.257848 28372 net.cpp:100] Creating Layer drop7
I1130 16:45:21.257849 28372 net.cpp:434] drop7 <- fc7
I1130 16:45:21.257854 28372 net.cpp:395] drop7 -> fc7 (in-place)
I1130 16:45:21.257884 28372 net.cpp:150] Setting up drop7
I1130 16:45:21.257889 28372 net.cpp:157] Top shape: 64 4096 (262144)
I1130 16:45:21.257890 28372 net.cpp:165] Memory required for data: 439049728
I1130 16:45:21.257892 28372 layer_factory.hpp:77] Creating layer fc8_2
I1130 16:45:21.257901 28372 net.cpp:100] Creating Layer fc8_2
I1130 16:45:21.257903 28372 net.cpp:434] fc8_2 <- fc7
I1130 16:45:21.257908 28372 net.cpp:408] fc8_2 -> fc8_2
I1130 16:45:21.258093 28372 net.cpp:150] Setting up fc8_2
I1130 16:45:21.258102 28372 net.cpp:157] Top shape: 64 2 (128)
I1130 16:45:21.258105 28372 net.cpp:165] Memory required for data: 439050240
I1130 16:45:21.258110 28372 layer_factory.hpp:77] Creating layer fc8_2_fc8_2_0_split
I1130 16:45:21.258116 28372 net.cpp:100] Creating Layer fc8_2_fc8_2_0_split
I1130 16:45:21.258117 28372 net.cpp:434] fc8_2_fc8_2_0_split <- fc8_2
I1130 16:45:21.258122 28372 net.cpp:408] fc8_2_fc8_2_0_split -> fc8_2_fc8_2_0_split_0
I1130 16:45:21.258128 28372 net.cpp:408] fc8_2_fc8_2_0_split -> fc8_2_fc8_2_0_split_1
I1130 16:45:21.258163 28372 net.cpp:150] Setting up fc8_2_fc8_2_0_split
I1130 16:45:21.258186 28372 net.cpp:157] Top shape: 64 2 (128)
I1130 16:45:21.258189 28372 net.cpp:157] Top shape: 64 2 (128)
I1130 16:45:21.258191 28372 net.cpp:165] Memory required for data: 439051264
I1130 16:45:21.258193 28372 layer_factory.hpp:77] Creating layer accuracy
I1130 16:45:21.258214 28372 net.cpp:100] Creating Layer accuracy
I1130 16:45:21.258219 28372 net.cpp:434] accuracy <- fc8_2_fc8_2_0_split_0
I1130 16:45:21.258222 28372 net.cpp:434] accuracy <- label_data_1_split_0
I1130 16:45:21.258247 28372 net.cpp:408] accuracy -> accuracy
I1130 16:45:21.258256 28372 net.cpp:150] Setting up accuracy
I1130 16:45:21.258260 28372 net.cpp:157] Top shape: (1)
I1130 16:45:21.258261 28372 net.cpp:165] Memory required for data: 439051268
I1130 16:45:21.258263 28372 layer_factory.hpp:77] Creating layer loss
I1130 16:45:21.258270 28372 net.cpp:100] Creating Layer loss
I1130 16:45:21.258271 28372 net.cpp:434] loss <- fc8_2_fc8_2_0_split_1
I1130 16:45:21.258275 28372 net.cpp:434] loss <- label_data_1_split_1
I1130 16:45:21.258278 28372 net.cpp:408] loss -> loss
I1130 16:45:21.258286 28372 layer_factory.hpp:77] Creating layer loss
I1130 16:45:21.258807 28372 net.cpp:150] Setting up loss
I1130 16:45:21.258819 28372 net.cpp:157] Top shape: (1)
I1130 16:45:21.258821 28372 net.cpp:160]     with loss weight 1
I1130 16:45:21.258842 28372 net.cpp:165] Memory required for data: 439051272
I1130 16:45:21.258846 28372 net.cpp:226] loss needs backward computation.
I1130 16:45:21.258849 28372 net.cpp:228] accuracy does not need backward computation.
I1130 16:45:21.258852 28372 net.cpp:226] fc8_2_fc8_2_0_split needs backward computation.
I1130 16:45:21.258854 28372 net.cpp:226] fc8_2 needs backward computation.
I1130 16:45:21.258857 28372 net.cpp:226] drop7 needs backward computation.
I1130 16:45:21.258858 28372 net.cpp:226] relu7 needs backward computation.
I1130 16:45:21.258860 28372 net.cpp:226] fc7 needs backward computation.
I1130 16:45:21.258862 28372 net.cpp:226] drop6 needs backward computation.
I1130 16:45:21.258864 28372 net.cpp:226] relu6 needs backward computation.
I1130 16:45:21.258867 28372 net.cpp:226] fc6 needs backward computation.
I1130 16:45:21.258868 28372 net.cpp:226] pool5 needs backward computation.
I1130 16:45:21.258872 28372 net.cpp:226] relu5 needs backward computation.
I1130 16:45:21.258884 28372 net.cpp:226] conv5 needs backward computation.
I1130 16:45:21.258886 28372 net.cpp:226] relu4 needs backward computation.
I1130 16:45:21.258889 28372 net.cpp:226] conv4 needs backward computation.
I1130 16:45:21.258891 28372 net.cpp:226] relu3 needs backward computation.
I1130 16:45:21.258893 28372 net.cpp:226] conv3 needs backward computation.
I1130 16:45:21.258895 28372 net.cpp:226] norm2 needs backward computation.
I1130 16:45:21.258898 28372 net.cpp:226] pool2 needs backward computation.
I1130 16:45:21.258900 28372 net.cpp:226] relu2 needs backward computation.
I1130 16:45:21.258903 28372 net.cpp:226] conv2 needs backward computation.
I1130 16:45:21.258904 28372 net.cpp:226] norm1 needs backward computation.
I1130 16:45:21.258906 28372 net.cpp:226] pool1 needs backward computation.
I1130 16:45:21.258908 28372 net.cpp:226] relu1 needs backward computation.
I1130 16:45:21.258910 28372 net.cpp:226] conv1 needs backward computation.
I1130 16:45:21.258914 28372 net.cpp:228] label_data_1_split does not need backward computation.
I1130 16:45:21.258918 28372 net.cpp:228] data does not need backward computation.
I1130 16:45:21.258919 28372 net.cpp:270] This network produces output accuracy
I1130 16:45:21.258922 28372 net.cpp:270] This network produces output loss
I1130 16:45:21.258935 28372 net.cpp:283] Network initialization done.
I1130 16:45:21.259021 28372 solver.cpp:60] Solver scaffolding done.
I1130 16:45:21.259618 28372 caffe.cpp:155] Finetuning from /home/tbochens/Nets/FineTuning/bvlc_reference_caffenet.caffemodel
I1130 16:45:21.421509 28372 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /home/tbochens/Nets/FineTuning/bvlc_reference_caffenet.caffemodel
I1130 16:45:21.421569 28372 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W1130 16:45:21.421576 28372 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I1130 16:45:21.421725 28372 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/tbochens/Nets/FineTuning/bvlc_reference_caffenet.caffemodel
I1130 16:45:21.658161 28372 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I1130 16:45:21.701550 28372 net.cpp:761] Ignoring source layer fc8
I1130 16:45:21.871716 28372 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: /home/tbochens/Nets/FineTuning/bvlc_reference_caffenet.caffemodel
I1130 16:45:21.871747 28372 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.
W1130 16:45:21.871749 28372 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.
I1130 16:45:21.871778 28372 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: /home/tbochens/Nets/FineTuning/bvlc_reference_caffenet.caffemodel
I1130 16:45:22.109782 28372 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter
I1130 16:45:22.152918 28372 net.cpp:761] Ignoring source layer fc8
I1130 16:45:22.156554 28372 caffe.cpp:251] Starting Optimization
I1130 16:45:22.156577 28372 solver.cpp:279] Solving VideoPopularityCaffeNet
I1130 16:45:22.156580 28372 solver.cpp:280] Learning Rate Policy: step
I1130 16:45:22.158167 28372 solver.cpp:337] Iteration 0, Testing net (#0)
I1130 16:45:22.364737 28372 blocking_queue.cpp:50] Data layer prefetch queue empty
I1130 16:45:31.208895 28372 solver.cpp:404]     Test net output #0: accuracy = 0.507552
I1130 16:45:31.208947 28372 solver.cpp:404]     Test net output #1: loss = 0.761928 (* 1 = 0.761928 loss)
I1130 16:45:31.246862 28372 solver.cpp:228] Iteration 0, loss = 0.992097
I1130 16:45:31.246917 28372 solver.cpp:244]     Train net output #0: loss = 0.992097 (* 1 = 0.992097 loss)
I1130 16:45:31.246938 28372 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I1130 16:45:36.444660 28372 solver.cpp:228] Iteration 50, loss = 0.864657
I1130 16:45:36.444722 28372 solver.cpp:244]     Train net output #0: loss = 0.864657 (* 1 = 0.864657 loss)
I1130 16:45:36.444733 28372 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I1130 16:45:40.485963 28372 solver.cpp:228] Iteration 100, loss = 0.682076
I1130 16:45:40.486057 28372 solver.cpp:244]     Train net output #0: loss = 0.682076 (* 1 = 0.682076 loss)
I1130 16:45:40.486064 28372 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I1130 16:45:45.056468 28372 solver.cpp:228] Iteration 150, loss = 0.693054
I1130 16:45:45.056574 28372 solver.cpp:244]     Train net output #0: loss = 0.693054 (* 1 = 0.693054 loss)
I1130 16:45:45.056594 28372 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I1130 16:45:50.237169 28372 solver.cpp:337] Iteration 200, Testing net (#0)
I1130 16:45:58.283094 28372 solver.cpp:404]     Test net output #0: accuracy = 0.530794
I1130 16:45:58.283154 28372 solver.cpp:404]     Test net output #1: loss = 0.687183 (* 1 = 0.687183 loss)
I1130 16:45:58.312206 28372 solver.cpp:228] Iteration 200, loss = 0.675697
I1130 16:45:58.312263 28372 solver.cpp:244]     Train net output #0: loss = 0.675697 (* 1 = 0.675697 loss)
I1130 16:45:58.312273 28372 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I1130 16:46:02.335152 28372 solver.cpp:228] Iteration 250, loss = 0.697408
I1130 16:46:02.335219 28372 solver.cpp:244]     Train net output #0: loss = 0.697408 (* 1 = 0.697408 loss)
I1130 16:46:02.335227 28372 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I1130 16:46:08.438766 28372 solver.cpp:228] Iteration 300, loss = 0.667915
I1130 16:46:08.438823 28372 solver.cpp:244]     Train net output #0: loss = 0.667915 (* 1 = 0.667915 loss)
I1130 16:46:08.438830 28372 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I1130 16:46:13.816280 28372 solver.cpp:228] Iteration 350, loss = 0.694343
I1130 16:46:13.816330 28372 solver.cpp:244]     Train net output #0: loss = 0.694343 (* 1 = 0.694343 loss)
I1130 16:46:13.816336 28372 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I1130 16:46:19.039811 28372 solver.cpp:337] Iteration 400, Testing net (#0)
I1130 16:46:27.902979 28372 solver.cpp:404]     Test net output #0: accuracy = 0.550521
I1130 16:46:27.903301 28372 solver.cpp:404]     Test net output #1: loss = 0.685051 (* 1 = 0.685051 loss)
I1130 16:46:27.929656 28372 solver.cpp:228] Iteration 400, loss = 0.673549
I1130 16:46:27.929719 28372 solver.cpp:244]     Train net output #0: loss = 0.673549 (* 1 = 0.673549 loss)
I1130 16:46:27.929736 28372 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I1130 16:46:32.437270 28372 solver.cpp:228] Iteration 450, loss = 0.701345
I1130 16:46:32.437326 28372 solver.cpp:244]     Train net output #0: loss = 0.701345 (* 1 = 0.701345 loss)
I1130 16:46:32.437335 28372 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I1130 16:46:36.936072 28372 solver.cpp:228] Iteration 500, loss = 0.694993
I1130 16:46:36.936125 28372 solver.cpp:244]     Train net output #0: loss = 0.694993 (* 1 = 0.694993 loss)
I1130 16:46:36.936133 28372 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I1130 16:46:40.875851 28372 solver.cpp:228] Iteration 550, loss = 0.701002
I1130 16:46:40.875903 28372 solver.cpp:244]     Train net output #0: loss = 0.701002 (* 1 = 0.701002 loss)
I1130 16:46:40.875910 28372 sgd_solver.cpp:106] Iteration 550, lr = 0.001
I1130 16:46:45.422855 28372 solver.cpp:337] Iteration 600, Testing net (#0)
I1130 16:46:53.882773 28372 solver.cpp:404]     Test net output #0: accuracy = 0.54707
I1130 16:46:53.882853 28372 solver.cpp:404]     Test net output #1: loss = 0.682758 (* 1 = 0.682758 loss)
I1130 16:46:53.913168 28372 solver.cpp:228] Iteration 600, loss = 0.672939
I1130 16:46:53.913221 28372 solver.cpp:244]     Train net output #0: loss = 0.672939 (* 1 = 0.672939 loss)
I1130 16:46:53.913238 28372 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I1130 16:46:59.079329 28372 solver.cpp:228] Iteration 650, loss = 0.683422
I1130 16:46:59.079535 28372 solver.cpp:244]     Train net output #0: loss = 0.683422 (* 1 = 0.683422 loss)
I1130 16:46:59.079560 28372 sgd_solver.cpp:106] Iteration 650, lr = 0.001
I1130 16:47:04.985939 28372 solver.cpp:228] Iteration 700, loss = 0.67091
I1130 16:47:04.985986 28372 solver.cpp:244]     Train net output #0: loss = 0.67091 (* 1 = 0.67091 loss)
I1130 16:47:04.985993 28372 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I1130 16:47:09.166612 28372 solver.cpp:228] Iteration 750, loss = 0.708828
I1130 16:47:09.166654 28372 solver.cpp:244]     Train net output #0: loss = 0.708828 (* 1 = 0.708828 loss)
I1130 16:47:09.166661 28372 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I1130 16:47:14.260335 28372 solver.cpp:337] Iteration 800, Testing net (#0)
I1130 16:47:23.799737 28372 solver.cpp:404]     Test net output #0: accuracy = 0.563021
I1130 16:47:23.799798 28372 solver.cpp:404]     Test net output #1: loss = 0.67971 (* 1 = 0.67971 loss)
I1130 16:47:23.829291 28372 solver.cpp:228] Iteration 800, loss = 0.722114
I1130 16:47:23.829341 28372 solver.cpp:244]     Train net output #0: loss = 0.722114 (* 1 = 0.722114 loss)
I1130 16:47:23.829354 28372 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I1130 16:47:28.929697 28372 solver.cpp:228] Iteration 850, loss = 0.652856
I1130 16:47:28.929766 28372 solver.cpp:244]     Train net output #0: loss = 0.652856 (* 1 = 0.652856 loss)
I1130 16:47:28.929774 28372 sgd_solver.cpp:106] Iteration 850, lr = 0.001
I1130 16:47:33.405021 28372 solver.cpp:228] Iteration 900, loss = 0.687018
I1130 16:47:33.405294 28372 solver.cpp:244]     Train net output #0: loss = 0.687018 (* 1 = 0.687018 loss)
I1130 16:47:33.405341 28372 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I1130 16:47:38.119225 28372 solver.cpp:228] Iteration 950, loss = 0.68714
I1130 16:47:38.119269 28372 solver.cpp:244]     Train net output #0: loss = 0.68714 (* 1 = 0.68714 loss)
I1130 16:47:38.119277 28372 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I1130 16:47:44.329396 28372 solver.cpp:337] Iteration 1000, Testing net (#0)
I1130 16:47:53.289002 28372 solver.cpp:404]     Test net output #0: accuracy = 0.584245
I1130 16:47:53.289060 28372 solver.cpp:404]     Test net output #1: loss = 0.669327 (* 1 = 0.669327 loss)
I1130 16:47:53.318820 28372 solver.cpp:228] Iteration 1000, loss = 0.66966
I1130 16:47:53.318872 28372 solver.cpp:244]     Train net output #0: loss = 0.66966 (* 1 = 0.66966 loss)
I1130 16:47:53.318882 28372 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I1130 16:47:56.392215 28381 blocking_queue.cpp:50] Waiting for data
I1130 16:47:57.353328 28372 solver.cpp:228] Iteration 1050, loss = 0.651235
I1130 16:47:57.353380 28372 solver.cpp:244]     Train net output #0: loss = 0.651235 (* 1 = 0.651235 loss)
I1130 16:47:57.353387 28372 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I1130 16:48:01.924818 28372 solver.cpp:228] Iteration 1100, loss = 0.700335
I1130 16:48:01.924880 28372 solver.cpp:244]     Train net output #0: loss = 0.700335 (* 1 = 0.700335 loss)
I1130 16:48:01.924887 28372 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I1130 16:48:07.865270 28372 solver.cpp:228] Iteration 1150, loss = 0.69466
I1130 16:48:07.971496 28372 solver.cpp:244]     Train net output #0: loss = 0.69466 (* 1 = 0.69466 loss)
I1130 16:48:07.971524 28372 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
I1130 16:48:13.025244 28372 solver.cpp:337] Iteration 1200, Testing net (#0)
I1130 16:48:16.780259 28372 blocking_queue.cpp:50] Data layer prefetch queue empty
I1130 16:48:22.981979 28372 solver.cpp:404]     Test net output #0: accuracy = 0.568294
I1130 16:48:22.982036 28372 solver.cpp:404]     Test net output #1: loss = 0.675671 (* 1 = 0.675671 loss)
I1130 16:48:23.011219 28372 solver.cpp:228] Iteration 1200, loss = 0.66843
I1130 16:48:23.011258 28372 solver.cpp:244]     Train net output #0: loss = 0.66843 (* 1 = 0.66843 loss)
I1130 16:48:23.011268 28372 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I1130 16:48:28.060094 28372 solver.cpp:228] Iteration 1250, loss = 0.682802
I1130 16:48:28.060151 28372 solver.cpp:244]     Train net output #0: loss = 0.682802 (* 1 = 0.682802 loss)
I1130 16:48:28.060158 28372 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I1130 16:48:32.803421 28372 solver.cpp:228] Iteration 1300, loss = 0.687779
I1130 16:48:32.803484 28372 solver.cpp:244]     Train net output #0: loss = 0.687779 (* 1 = 0.687779 loss)
I1130 16:48:32.803495 28372 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I1130 16:48:38.080906 28372 solver.cpp:228] Iteration 1350, loss = 0.686495
I1130 16:48:38.133958 28372 solver.cpp:244]     Train net output #0: loss = 0.686495 (* 1 = 0.686495 loss)
I1130 16:48:38.133987 28372 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I1130 16:48:42.054101 28372 solver.cpp:337] Iteration 1400, Testing net (#0)
I1130 16:48:52.008896 28372 solver.cpp:404]     Test net output #0: accuracy = 0.591276
I1130 16:48:52.008955 28372 solver.cpp:404]     Test net output #1: loss = 0.665118 (* 1 = 0.665118 loss)
I1130 16:48:52.038187 28372 solver.cpp:228] Iteration 1400, loss = 0.683805
I1130 16:48:52.038290 28372 solver.cpp:244]     Train net output #0: loss = 0.683805 (* 1 = 0.683805 loss)
I1130 16:48:52.038308 28372 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I1130 16:48:57.156219 28372 solver.cpp:228] Iteration 1450, loss = 0.642977
I1130 16:48:57.156311 28372 solver.cpp:244]     Train net output #0: loss = 0.642977 (* 1 = 0.642977 loss)
I1130 16:48:57.156318 28372 sgd_solver.cpp:106] Iteration 1450, lr = 0.001
I1130 16:49:03.018805 28372 solver.cpp:228] Iteration 1500, loss = 0.649448
I1130 16:49:03.018863 28372 solver.cpp:244]     Train net output #0: loss = 0.649448 (* 1 = 0.649448 loss)
I1130 16:49:03.018874 28372 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I1130 16:49:08.759826 28372 solver.cpp:228] Iteration 1550, loss = 0.644363
I1130 16:49:10.543009 28372 solver.cpp:244]     Train net output #0: loss = 0.644363 (* 1 = 0.644363 loss)
I1130 16:49:10.543045 28372 sgd_solver.cpp:106] Iteration 1550, lr = 0.001
I1130 16:49:16.145505 28372 solver.cpp:337] Iteration 1600, Testing net (#0)
I1130 16:49:24.063194 28372 solver.cpp:404]     Test net output #0: accuracy = 0.588607
I1130 16:49:24.063249 28372 solver.cpp:404]     Test net output #1: loss = 0.66216 (* 1 = 0.66216 loss)
I1130 16:49:24.106375 28372 solver.cpp:228] Iteration 1600, loss = 0.726835
I1130 16:49:24.106428 28372 solver.cpp:244]     Train net output #0: loss = 0.726835 (* 1 = 0.726835 loss)
I1130 16:49:24.106441 28372 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I1130 16:49:30.060806 28372 solver.cpp:228] Iteration 1650, loss = 0.640821
I1130 16:49:30.060870 28372 solver.cpp:244]     Train net output #0: loss = 0.640821 (* 1 = 0.640821 loss)
I1130 16:49:30.060880 28372 sgd_solver.cpp:106] Iteration 1650, lr = 0.001
I1130 16:49:35.904095 28372 solver.cpp:228] Iteration 1700, loss = 0.710973
I1130 16:49:35.904158 28372 solver.cpp:244]     Train net output #0: loss = 0.710973 (* 1 = 0.710973 loss)
I1130 16:49:35.904166 28372 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I1130 16:49:41.166057 28372 solver.cpp:228] Iteration 1750, loss = 0.696563
I1130 16:49:41.166353 28372 solver.cpp:244]     Train net output #0: loss = 0.696563 (* 1 = 0.696563 loss)
I1130 16:49:41.166385 28372 sgd_solver.cpp:106] Iteration 1750, lr = 0.001
I1130 16:49:46.981005 28372 solver.cpp:337] Iteration 1800, Testing net (#0)
I1130 16:49:56.558897 28372 solver.cpp:404]     Test net output #0: accuracy = 0.597331
I1130 16:49:56.558959 28372 solver.cpp:404]     Test net output #1: loss = 0.662708 (* 1 = 0.662708 loss)
I1130 16:49:56.588153 28372 solver.cpp:228] Iteration 1800, loss = 0.624516
I1130 16:49:56.588208 28372 solver.cpp:244]     Train net output #0: loss = 0.624516 (* 1 = 0.624516 loss)
I1130 16:49:56.588222 28372 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I1130 16:50:02.466747 28372 solver.cpp:228] Iteration 1850, loss = 0.617458
I1130 16:50:02.466804 28372 solver.cpp:244]     Train net output #0: loss = 0.617458 (* 1 = 0.617458 loss)
I1130 16:50:02.466822 28372 sgd_solver.cpp:106] Iteration 1850, lr = 0.001
I1130 16:50:07.582900 28372 solver.cpp:228] Iteration 1900, loss = 0.640006
I1130 16:50:07.582962 28372 solver.cpp:244]     Train net output #0: loss = 0.640006 (* 1 = 0.640006 loss)
I1130 16:50:07.582967 28372 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I1130 16:50:11.560178 28372 solver.cpp:228] Iteration 1950, loss = 0.713175
I1130 16:50:11.597038 28372 solver.cpp:244]     Train net output #0: loss = 0.713175 (* 1 = 0.713175 loss)
I1130 16:50:11.597071 28372 sgd_solver.cpp:106] Iteration 1950, lr = 0.001
I1130 16:50:15.554946 28372 solver.cpp:337] Iteration 2000, Testing net (#0)
I1130 16:50:25.645203 28372 solver.cpp:404]     Test net output #0: accuracy = 0.599284
I1130 16:50:25.645269 28372 solver.cpp:404]     Test net output #1: loss = 0.657337 (* 1 = 0.657337 loss)
I1130 16:50:25.695228 28372 solver.cpp:228] Iteration 2000, loss = 0.621313
I1130 16:50:25.695286 28372 solver.cpp:244]     Train net output #0: loss = 0.621313 (* 1 = 0.621313 loss)
I1130 16:50:25.695302 28372 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I1130 16:50:31.765453 28372 solver.cpp:228] Iteration 2050, loss = 0.663544
I1130 16:50:31.765506 28372 solver.cpp:244]     Train net output #0: loss = 0.663544 (* 1 = 0.663544 loss)
I1130 16:50:31.765516 28372 sgd_solver.cpp:106] Iteration 2050, lr = 0.001
I1130 16:50:37.027750 28372 solver.cpp:228] Iteration 2100, loss = 0.655109
I1130 16:50:37.027844 28372 solver.cpp:244]     Train net output #0: loss = 0.655109 (* 1 = 0.655109 loss)
I1130 16:50:37.027864 28372 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I1130 16:50:43.080221 28372 solver.cpp:228] Iteration 2150, loss = 0.723696
I1130 16:50:43.102416 28372 solver.cpp:244]     Train net output #0: loss = 0.723696 (* 1 = 0.723696 loss)
I1130 16:50:43.102442 28372 sgd_solver.cpp:106] Iteration 2150, lr = 0.001
I1130 16:50:47.108139 28372 solver.cpp:337] Iteration 2200, Testing net (#0)
I1130 16:50:55.930244 28372 solver.cpp:404]     Test net output #0: accuracy = 0.594596
I1130 16:50:55.930310 28372 solver.cpp:404]     Test net output #1: loss = 0.660127 (* 1 = 0.660127 loss)
I1130 16:50:55.960314 28372 solver.cpp:228] Iteration 2200, loss = 0.6171
I1130 16:50:55.960383 28372 solver.cpp:244]     Train net output #0: loss = 0.6171 (* 1 = 0.6171 loss)
I1130 16:50:55.960393 28372 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I1130 16:50:59.874958 28372 solver.cpp:228] Iteration 2250, loss = 0.732676
I1130 16:50:59.875012 28372 solver.cpp:244]     Train net output #0: loss = 0.732676 (* 1 = 0.732676 loss)
I1130 16:50:59.875021 28372 sgd_solver.cpp:106] Iteration 2250, lr = 0.001
I1130 16:51:03.893050 28372 solver.cpp:228] Iteration 2300, loss = 0.675014
I1130 16:51:03.893095 28372 solver.cpp:244]     Train net output #0: loss = 0.675014 (* 1 = 0.675014 loss)
I1130 16:51:03.893103 28372 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I1130 16:51:08.722573 28372 solver.cpp:228] Iteration 2350, loss = 0.633802
I1130 16:51:08.722631 28372 solver.cpp:244]     Train net output #0: loss = 0.633802 (* 1 = 0.633802 loss)
I1130 16:51:08.722640 28372 sgd_solver.cpp:106] Iteration 2350, lr = 0.001
I1130 16:51:14.973419 28372 solver.cpp:337] Iteration 2400, Testing net (#0)
I1130 16:51:18.187337 28372 blocking_queue.cpp:50] Data layer prefetch queue empty
I1130 16:51:22.451540 28372 solver.cpp:404]     Test net output #0: accuracy = 0.591992
I1130 16:51:22.451601 28372 solver.cpp:404]     Test net output #1: loss = 0.657573 (* 1 = 0.657573 loss)
I1130 16:51:22.481575 28372 solver.cpp:228] Iteration 2400, loss = 0.696135
I1130 16:51:22.481631 28372 solver.cpp:244]     Train net output #0: loss = 0.696135 (* 1 = 0.696135 loss)
I1130 16:51:22.481645 28372 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I1130 16:51:27.659060 28372 solver.cpp:228] Iteration 2450, loss = 0.685026
I1130 16:51:27.659111 28372 solver.cpp:244]     Train net output #0: loss = 0.685026 (* 1 = 0.685026 loss)
I1130 16:51:27.659118 28372 sgd_solver.cpp:106] Iteration 2450, lr = 0.001
I1130 16:51:31.598129 28372 solver.cpp:228] Iteration 2500, loss = 0.719763
I1130 16:51:31.598188 28372 solver.cpp:244]     Train net output #0: loss = 0.719763 (* 1 = 0.719763 loss)
I1130 16:51:31.598193 28372 sgd_solver.cpp:106] Iteration 2500, lr = 0.001
I1130 16:51:35.661695 28372 solver.cpp:228] Iteration 2550, loss = 0.607172
I1130 16:51:35.661752 28372 solver.cpp:244]     Train net output #0: loss = 0.607172 (* 1 = 0.607172 loss)
I1130 16:51:35.661761 28372 sgd_solver.cpp:106] Iteration 2550, lr = 0.001
I1130 16:51:39.626127 28372 solver.cpp:337] Iteration 2600, Testing net (#0)
I1130 16:51:48.327806 28372 solver.cpp:404]     Test net output #0: accuracy = 0.604948
I1130 16:51:48.328089 28372 solver.cpp:404]     Test net output #1: loss = 0.653984 (* 1 = 0.653984 loss)
I1130 16:51:48.355255 28372 solver.cpp:228] Iteration 2600, loss = 0.602089
I1130 16:51:48.355298 28372 solver.cpp:244]     Train net output #0: loss = 0.602089 (* 1 = 0.602089 loss)
I1130 16:51:48.355310 28372 sgd_solver.cpp:106] Iteration 2600, lr = 0.001
I1130 16:51:52.307679 28372 solver.cpp:228] Iteration 2650, loss = 0.605991
I1130 16:51:52.307745 28372 solver.cpp:244]     Train net output #0: loss = 0.605991 (* 1 = 0.605991 loss)
I1130 16:51:52.307752 28372 sgd_solver.cpp:106] Iteration 2650, lr = 0.001
I1130 16:51:56.343142 28372 solver.cpp:228] Iteration 2700, loss = 0.630785
I1130 16:51:56.343204 28372 solver.cpp:244]     Train net output #0: loss = 0.630785 (* 1 = 0.630785 loss)
I1130 16:51:56.343212 28372 sgd_solver.cpp:106] Iteration 2700, lr = 0.001
I1130 16:52:00.701681 28372 solver.cpp:228] Iteration 2750, loss = 0.661452
I1130 16:52:00.701738 28372 solver.cpp:244]     Train net output #0: loss = 0.661452 (* 1 = 0.661452 loss)
I1130 16:52:00.701745 28372 sgd_solver.cpp:106] Iteration 2750, lr = 0.001
I1130 16:52:06.297632 28372 solver.cpp:337] Iteration 2800, Testing net (#0)
I1130 16:52:14.759919 28372 solver.cpp:404]     Test net output #0: accuracy = 0.592839
I1130 16:52:14.759980 28372 solver.cpp:404]     Test net output #1: loss = 0.661202 (* 1 = 0.661202 loss)
I1130 16:52:14.789579 28372 solver.cpp:228] Iteration 2800, loss = 0.664625
I1130 16:52:14.789630 28372 solver.cpp:244]     Train net output #0: loss = 0.664625 (* 1 = 0.664625 loss)
I1130 16:52:14.789640 28372 sgd_solver.cpp:106] Iteration 2800, lr = 0.001
I1130 16:52:18.836652 28372 solver.cpp:228] Iteration 2850, loss = 0.662719
I1130 16:52:18.875062 28372 solver.cpp:244]     Train net output #0: loss = 0.662719 (* 1 = 0.662719 loss)
I1130 16:52:18.875080 28372 sgd_solver.cpp:106] Iteration 2850, lr = 0.001
I1130 16:52:24.406533 28372 solver.cpp:228] Iteration 2900, loss = 0.649808
I1130 16:52:24.406608 28372 solver.cpp:244]     Train net output #0: loss = 0.649808 (* 1 = 0.649808 loss)
I1130 16:52:24.406617 28372 sgd_solver.cpp:106] Iteration 2900, lr = 0.001
I1130 16:52:29.817205 28372 solver.cpp:228] Iteration 2950, loss = 0.606471
I1130 16:52:29.817253 28372 solver.cpp:244]     Train net output #0: loss = 0.606471 (* 1 = 0.606471 loss)
I1130 16:52:29.817260 28372 sgd_solver.cpp:106] Iteration 2950, lr = 0.001
I1130 16:52:35.170413 28372 solver.cpp:337] Iteration 3000, Testing net (#0)
I1130 16:52:43.397526 28372 solver.cpp:404]     Test net output #0: accuracy = 0.618815
I1130 16:52:43.397601 28372 solver.cpp:404]     Test net output #1: loss = 0.647353 (* 1 = 0.647353 loss)
I1130 16:52:43.424738 28372 solver.cpp:228] Iteration 3000, loss = 0.676565
I1130 16:52:43.424790 28372 solver.cpp:244]     Train net output #0: loss = 0.676565 (* 1 = 0.676565 loss)
I1130 16:52:43.424806 28372 sgd_solver.cpp:106] Iteration 3000, lr = 0.001
I1130 16:52:48.128839 28372 solver.cpp:228] Iteration 3050, loss = 0.667379
I1130 16:52:48.128890 28372 solver.cpp:244]     Train net output #0: loss = 0.667379 (* 1 = 0.667379 loss)
I1130 16:52:48.128898 28372 sgd_solver.cpp:106] Iteration 3050, lr = 0.001
I1130 16:52:53.897275 28372 solver.cpp:228] Iteration 3100, loss = 0.672149
I1130 16:52:53.897490 28372 solver.cpp:244]     Train net output #0: loss = 0.672149 (* 1 = 0.672149 loss)
I1130 16:52:53.897511 28372 sgd_solver.cpp:106] Iteration 3100, lr = 0.001
I1130 16:52:59.265328 28372 solver.cpp:228] Iteration 3150, loss = 0.724143
I1130 16:52:59.265396 28372 solver.cpp:244]     Train net output #0: loss = 0.724143 (* 1 = 0.724143 loss)
I1130 16:52:59.265403 28372 sgd_solver.cpp:106] Iteration 3150, lr = 0.001
I1130 16:53:04.493181 28372 solver.cpp:337] Iteration 3200, Testing net (#0)
I1130 16:53:12.782613 28372 solver.cpp:404]     Test net output #0: accuracy = 0.612891
I1130 16:53:12.782688 28372 solver.cpp:404]     Test net output #1: loss = 0.648637 (* 1 = 0.648637 loss)
I1130 16:53:12.812942 28372 solver.cpp:228] Iteration 3200, loss = 0.70008
I1130 16:53:12.812997 28372 solver.cpp:244]     Train net output #0: loss = 0.70008 (* 1 = 0.70008 loss)
I1130 16:53:12.813009 28372 sgd_solver.cpp:106] Iteration 3200, lr = 0.001
I1130 16:53:16.765946 28372 solver.cpp:228] Iteration 3250, loss = 0.658265
I1130 16:53:16.766000 28372 solver.cpp:244]     Train net output #0: loss = 0.658265 (* 1 = 0.658265 loss)
I1130 16:53:16.766005 28372 sgd_solver.cpp:106] Iteration 3250, lr = 0.001
I1130 16:53:20.850958 28372 solver.cpp:228] Iteration 3300, loss = 0.71902
I1130 16:53:20.851017 28372 solver.cpp:244]     Train net output #0: loss = 0.71902 (* 1 = 0.71902 loss)
I1130 16:53:20.851025 28372 sgd_solver.cpp:106] Iteration 3300, lr = 0.001
I1130 16:53:25.201282 28372 solver.cpp:228] Iteration 3350, loss = 0.680426
I1130 16:53:25.201514 28372 solver.cpp:244]     Train net output #0: loss = 0.680426 (* 1 = 0.680426 loss)
I1130 16:53:25.201524 28372 sgd_solver.cpp:106] Iteration 3350, lr = 0.001
I1130 16:53:30.752430 28372 solver.cpp:337] Iteration 3400, Testing net (#0)
I1130 16:53:33.841104 28372 blocking_queue.cpp:50] Data layer prefetch queue empty
I1130 16:53:38.126873 28372 solver.cpp:404]     Test net output #0: accuracy = 0.610677
I1130 16:53:38.126925 28372 solver.cpp:404]     Test net output #1: loss = 0.647535 (* 1 = 0.647535 loss)
I1130 16:53:38.154433 28372 solver.cpp:228] Iteration 3400, loss = 0.691189
I1130 16:53:38.154505 28372 solver.cpp:244]     Train net output #0: loss = 0.691189 (* 1 = 0.691189 loss)
I1130 16:53:38.154525 28372 sgd_solver.cpp:106] Iteration 3400, lr = 0.001
I1130 16:53:42.119437 28372 solver.cpp:228] Iteration 3450, loss = 0.629423
I1130 16:53:42.119503 28372 solver.cpp:244]     Train net output #0: loss = 0.629423 (* 1 = 0.629423 loss)
I1130 16:53:42.119510 28372 sgd_solver.cpp:106] Iteration 3450, lr = 0.001
I1130 16:53:47.663034 28372 solver.cpp:228] Iteration 3500, loss = 0.609944
I1130 16:53:47.663099 28372 solver.cpp:244]     Train net output #0: loss = 0.609944 (* 1 = 0.609944 loss)
I1130 16:53:47.663107 28372 sgd_solver.cpp:106] Iteration 3500, lr = 0.001
I1130 16:53:51.895818 28372 solver.cpp:228] Iteration 3550, loss = 0.669655
I1130 16:53:51.895867 28372 solver.cpp:244]     Train net output #0: loss = 0.669655 (* 1 = 0.669655 loss)
I1130 16:53:51.895875 28372 sgd_solver.cpp:106] Iteration 3550, lr = 0.001
I1130 16:53:57.298532 28372 solver.cpp:337] Iteration 3600, Testing net (#0)
I1130 16:54:06.571485 28372 solver.cpp:404]     Test net output #0: accuracy = 0.614909
I1130 16:54:06.571559 28372 solver.cpp:404]     Test net output #1: loss = 0.648463 (* 1 = 0.648463 loss)
I1130 16:54:06.618995 28372 solver.cpp:228] Iteration 3600, loss = 0.752308
I1130 16:54:06.619051 28372 solver.cpp:244]     Train net output #0: loss = 0.752308 (* 1 = 0.752308 loss)
I1130 16:54:06.619061 28372 sgd_solver.cpp:106] Iteration 3600, lr = 0.001
I1130 16:54:11.709488 28372 solver.cpp:228] Iteration 3650, loss = 0.690487
I1130 16:54:11.709547 28372 solver.cpp:244]     Train net output #0: loss = 0.690487 (* 1 = 0.690487 loss)
I1130 16:54:11.709565 28372 sgd_solver.cpp:106] Iteration 3650, lr = 0.001
I1130 16:54:15.693271 28372 solver.cpp:228] Iteration 3700, loss = 0.652738
I1130 16:54:15.693328 28372 solver.cpp:244]     Train net output #0: loss = 0.652738 (* 1 = 0.652738 loss)
I1130 16:54:15.693346 28372 sgd_solver.cpp:106] Iteration 3700, lr = 0.001
I1130 16:54:19.727010 28372 solver.cpp:228] Iteration 3750, loss = 0.628998
I1130 16:54:19.727071 28372 solver.cpp:244]     Train net output #0: loss = 0.628998 (* 1 = 0.628998 loss)
I1130 16:54:19.727089 28372 sgd_solver.cpp:106] Iteration 3750, lr = 0.001
I1130 16:54:24.494962 28372 solver.cpp:337] Iteration 3800, Testing net (#0)
I1130 16:54:33.964826 28372 solver.cpp:404]     Test net output #0: accuracy = 0.622331
I1130 16:54:33.965004 28372 solver.cpp:404]     Test net output #1: loss = 0.643692 (* 1 = 0.643692 loss)
I1130 16:54:34.006877 28372 solver.cpp:228] Iteration 3800, loss = 0.679534
I1130 16:54:34.006919 28372 solver.cpp:244]     Train net output #0: loss = 0.679534 (* 1 = 0.679534 loss)
I1130 16:54:34.006928 28372 sgd_solver.cpp:106] Iteration 3800, lr = 0.001
I1130 16:54:38.011037 28372 solver.cpp:228] Iteration 3850, loss = 0.648023
I1130 16:54:38.011081 28372 solver.cpp:244]     Train net output #0: loss = 0.648023 (* 1 = 0.648023 loss)
I1130 16:54:38.011087 28372 sgd_solver.cpp:106] Iteration 3850, lr = 0.001
I1130 16:54:42.044266 28372 solver.cpp:228] Iteration 3900, loss = 0.617859
I1130 16:54:42.044317 28372 solver.cpp:244]     Train net output #0: loss = 0.617859 (* 1 = 0.617859 loss)
I1130 16:54:42.044323 28372 sgd_solver.cpp:106] Iteration 3900, lr = 0.001
I1130 16:54:46.710458 28372 solver.cpp:228] Iteration 3950, loss = 0.668505
I1130 16:54:46.710507 28372 solver.cpp:244]     Train net output #0: loss = 0.668505 (* 1 = 0.668505 loss)
I1130 16:54:46.710515 28372 sgd_solver.cpp:106] Iteration 3950, lr = 0.001
I1130 16:54:51.683190 28372 solver.cpp:337] Iteration 4000, Testing net (#0)
I1130 16:54:59.938570 28372 solver.cpp:404]     Test net output #0: accuracy = 0.605794
I1130 16:54:59.938633 28372 solver.cpp:404]     Test net output #1: loss = 0.654036 (* 1 = 0.654036 loss)
I1130 16:54:59.968749 28372 solver.cpp:228] Iteration 4000, loss = 0.630529
I1130 16:54:59.968816 28372 solver.cpp:244]     Train net output #0: loss = 0.630529 (* 1 = 0.630529 loss)
I1130 16:54:59.968827 28372 sgd_solver.cpp:106] Iteration 4000, lr = 0.001
I1130 16:55:04.301316 28372 solver.cpp:228] Iteration 4050, loss = 0.65705
I1130 16:55:04.332145 28372 solver.cpp:244]     Train net output #0: loss = 0.65705 (* 1 = 0.65705 loss)
I1130 16:55:04.332157 28372 sgd_solver.cpp:106] Iteration 4050, lr = 0.001
I1130 16:55:09.341892 28372 solver.cpp:228] Iteration 4100, loss = 0.692671
I1130 16:55:09.341950 28372 solver.cpp:244]     Train net output #0: loss = 0.692671 (* 1 = 0.692671 loss)
I1130 16:55:09.341969 28372 sgd_solver.cpp:106] Iteration 4100, lr = 0.001
I1130 16:55:14.378518 28372 solver.cpp:228] Iteration 4150, loss = 0.556183
I1130 16:55:14.378582 28372 solver.cpp:244]     Train net output #0: loss = 0.556183 (* 1 = 0.556183 loss)
I1130 16:55:14.378589 28372 sgd_solver.cpp:106] Iteration 4150, lr = 0.001
I1130 16:55:18.865303 28372 solver.cpp:337] Iteration 4200, Testing net (#0)
I1130 16:55:28.512540 28372 solver.cpp:404]     Test net output #0: accuracy = 0.620117
I1130 16:55:28.512598 28372 solver.cpp:404]     Test net output #1: loss = 0.645481 (* 1 = 0.645481 loss)
I1130 16:55:28.543318 28372 solver.cpp:228] Iteration 4200, loss = 0.655071
I1130 16:55:28.543362 28372 solver.cpp:244]     Train net output #0: loss = 0.655071 (* 1 = 0.655071 loss)
I1130 16:55:28.543373 28372 sgd_solver.cpp:106] Iteration 4200, lr = 0.001
I1130 16:55:34.469805 28372 solver.cpp:228] Iteration 4250, loss = 0.610066
I1130 16:55:34.470037 28372 solver.cpp:244]     Train net output #0: loss = 0.610066 (* 1 = 0.610066 loss)
I1130 16:55:34.470068 28372 sgd_solver.cpp:106] Iteration 4250, lr = 0.001
I1130 16:55:39.922374 28372 solver.cpp:228] Iteration 4300, loss = 0.600878
I1130 16:55:39.922425 28372 solver.cpp:244]     Train net output #0: loss = 0.600878 (* 1 = 0.600878 loss)
I1130 16:55:39.922433 28372 sgd_solver.cpp:106] Iteration 4300, lr = 0.001
I1130 16:55:45.285778 28372 solver.cpp:228] Iteration 4350, loss = 0.596073
I1130 16:55:45.285851 28372 solver.cpp:244]     Train net output #0: loss = 0.596073 (* 1 = 0.596073 loss)
I1130 16:55:45.285858 28372 sgd_solver.cpp:106] Iteration 4350, lr = 0.001
I1130 16:55:49.496613 28372 solver.cpp:337] Iteration 4400, Testing net (#0)
I1130 16:55:58.111827 28372 solver.cpp:404]     Test net output #0: accuracy = 0.619727
I1130 16:55:58.111881 28372 solver.cpp:404]     Test net output #1: loss = 0.642901 (* 1 = 0.642901 loss)
I1130 16:55:58.138775 28372 solver.cpp:228] Iteration 4400, loss = 0.61224
I1130 16:55:58.138831 28372 solver.cpp:244]     Train net output #0: loss = 0.61224 (* 1 = 0.61224 loss)
I1130 16:55:58.138847 28372 sgd_solver.cpp:106] Iteration 4400, lr = 0.001
I1130 16:56:03.887163 28372 solver.cpp:228] Iteration 4450, loss = 0.617631
I1130 16:56:03.887212 28372 solver.cpp:244]     Train net output #0: loss = 0.617631 (* 1 = 0.617631 loss)
I1130 16:56:03.887219 28372 sgd_solver.cpp:106] Iteration 4450, lr = 0.001
I1130 16:56:07.789158 28372 solver.cpp:228] Iteration 4500, loss = 0.570719
I1130 16:56:08.362690 28372 solver.cpp:244]     Train net output #0: loss = 0.570719 (* 1 = 0.570719 loss)
I1130 16:56:08.362723 28372 sgd_solver.cpp:106] Iteration 4500, lr = 0.001
I1130 16:56:13.356091 28372 solver.cpp:228] Iteration 4550, loss = 0.613508
I1130 16:56:13.356148 28372 solver.cpp:244]     Train net output #0: loss = 0.613508 (* 1 = 0.613508 loss)
I1130 16:56:13.356156 28372 sgd_solver.cpp:106] Iteration 4550, lr = 0.001
I1130 16:56:17.417923 28372 solver.cpp:337] Iteration 4600, Testing net (#0)
I1130 16:56:21.667347 28372 blocking_queue.cpp:50] Data layer prefetch queue empty
I1130 16:56:26.762840 28372 solver.cpp:404]     Test net output #0: accuracy = 0.609961
I1130 16:56:26.762883 28372 solver.cpp:404]     Test net output #1: loss = 0.646489 (* 1 = 0.646489 loss)
I1130 16:56:26.788795 28372 solver.cpp:228] Iteration 4600, loss = 0.640098
I1130 16:56:26.788841 28372 solver.cpp:244]     Train net output #0: loss = 0.640098 (* 1 = 0.640098 loss)
I1130 16:56:26.788851 28372 sgd_solver.cpp:106] Iteration 4600, lr = 0.001
I1130 16:56:31.798643 28372 solver.cpp:228] Iteration 4650, loss = 0.595902
I1130 16:56:31.798693 28372 solver.cpp:244]     Train net output #0: loss = 0.595902 (* 1 = 0.595902 loss)
I1130 16:56:31.798698 28372 sgd_solver.cpp:106] Iteration 4650, lr = 0.001
I1130 16:56:36.603312 28372 solver.cpp:228] Iteration 4700, loss = 0.578651
I1130 16:56:36.603365 28372 solver.cpp:244]     Train net output #0: loss = 0.578651 (* 1 = 0.578651 loss)
I1130 16:56:36.603373 28372 sgd_solver.cpp:106] Iteration 4700, lr = 0.001
I1130 16:56:42.214857 28372 solver.cpp:228] Iteration 4750, loss = 0.693152
I1130 16:56:42.236340 28372 solver.cpp:244]     Train net output #0: loss = 0.693152 (* 1 = 0.693152 loss)
I1130 16:56:42.236361 28372 sgd_solver.cpp:106] Iteration 4750, lr = 0.001
I1130 16:56:46.320061 28372 solver.cpp:337] Iteration 4800, Testing net (#0)
I1130 16:56:54.019127 28372 solver.cpp:404]     Test net output #0: accuracy = 0.613086
I1130 16:56:54.019207 28372 solver.cpp:404]     Test net output #1: loss = 0.644546 (* 1 = 0.644546 loss)
I1130 16:56:54.046452 28372 solver.cpp:228] Iteration 4800, loss = 0.69166
I1130 16:56:54.046514 28372 solver.cpp:244]     Train net output #0: loss = 0.69166 (* 1 = 0.69166 loss)
I1130 16:56:54.046535 28372 sgd_solver.cpp:106] Iteration 4800, lr = 0.001
I1130 16:56:58.869540 28372 solver.cpp:228] Iteration 4850, loss = 0.660972
I1130 16:56:58.869585 28372 solver.cpp:244]     Train net output #0: loss = 0.660972 (* 1 = 0.660972 loss)
I1130 16:56:58.869595 28372 sgd_solver.cpp:106] Iteration 4850, lr = 0.001
I1130 16:57:04.229482 28372 solver.cpp:228] Iteration 4900, loss = 0.672271
I1130 16:57:04.229526 28372 solver.cpp:244]     Train net output #0: loss = 0.672271 (* 1 = 0.672271 loss)
I1130 16:57:04.229543 28372 sgd_solver.cpp:106] Iteration 4900, lr = 0.001
I1130 16:57:09.088551 28372 solver.cpp:228] Iteration 4950, loss = 0.562887
I1130 16:57:09.088608 28372 solver.cpp:244]     Train net output #0: loss = 0.562887 (* 1 = 0.562887 loss)
I1130 16:57:09.088613 28372 sgd_solver.cpp:106] Iteration 4950, lr = 0.001
I1130 16:57:13.797010 28372 solver.cpp:337] Iteration 5000, Testing net (#0)
I1130 16:57:22.659705 28372 solver.cpp:404]     Test net output #0: accuracy = 0.620768
I1130 16:57:22.659759 28372 solver.cpp:404]     Test net output #1: loss = 0.643504 (* 1 = 0.643504 loss)
I1130 16:57:22.689256 28372 solver.cpp:228] Iteration 5000, loss = 0.565223
I1130 16:57:22.689302 28372 solver.cpp:244]     Train net output #0: loss = 0.565223 (* 1 = 0.565223 loss)
I1130 16:57:22.689313 28372 sgd_solver.cpp:106] Iteration 5000, lr = 0.0001
I1130 16:57:26.573612 28372 solver.cpp:228] Iteration 5050, loss = 0.629909
I1130 16:57:26.573671 28372 solver.cpp:244]     Train net output #0: loss = 0.629909 (* 1 = 0.629909 loss)
I1130 16:57:26.573678 28372 sgd_solver.cpp:106] Iteration 5050, lr = 0.0001
I1130 16:57:30.560791 28372 solver.cpp:228] Iteration 5100, loss = 0.701178
I1130 16:57:30.560840 28372 solver.cpp:244]     Train net output #0: loss = 0.701178 (* 1 = 0.701178 loss)
I1130 16:57:30.560859 28372 sgd_solver.cpp:106] Iteration 5100, lr = 0.0001
I1130 16:57:34.642204 28372 solver.cpp:228] Iteration 5150, loss = 0.629261
I1130 16:57:34.642254 28372 solver.cpp:244]     Train net output #0: loss = 0.629261 (* 1 = 0.629261 loss)
I1130 16:57:34.642262 28372 sgd_solver.cpp:106] Iteration 5150, lr = 0.0001
I1130 16:57:40.700858 28372 solver.cpp:337] Iteration 5200, Testing net (#0)
I1130 16:57:49.722828 28372 solver.cpp:404]     Test net output #0: accuracy = 0.628516
I1130 16:57:49.723052 28372 solver.cpp:404]     Test net output #1: loss = 0.635487 (* 1 = 0.635487 loss)
I1130 16:57:49.749630 28372 solver.cpp:228] Iteration 5200, loss = 0.70544
I1130 16:57:49.749650 28372 solver.cpp:244]     Train net output #0: loss = 0.70544 (* 1 = 0.70544 loss)
I1130 16:57:49.749672 28372 sgd_solver.cpp:106] Iteration 5200, lr = 0.0001
I1130 16:57:54.419571 28372 solver.cpp:228] Iteration 5250, loss = 0.58089
I1130 16:57:54.419636 28372 solver.cpp:244]     Train net output #0: loss = 0.58089 (* 1 = 0.58089 loss)
I1130 16:57:54.419643 28372 sgd_solver.cpp:106] Iteration 5250, lr = 0.0001
I1130 16:58:00.272804 28372 solver.cpp:228] Iteration 5300, loss = 0.622872
I1130 16:58:00.272866 28372 solver.cpp:244]     Train net output #0: loss = 0.622872 (* 1 = 0.622872 loss)
I1130 16:58:00.272874 28372 sgd_solver.cpp:106] Iteration 5300, lr = 0.0001
I1130 16:58:04.608155 28372 solver.cpp:228] Iteration 5350, loss = 0.691654
I1130 16:58:04.608207 28372 solver.cpp:244]     Train net output #0: loss = 0.691654 (* 1 = 0.691654 loss)
I1130 16:58:04.608216 28372 sgd_solver.cpp:106] Iteration 5350, lr = 0.0001
I1130 16:58:09.182211 28372 solver.cpp:337] Iteration 5400, Testing net (#0)
I1130 16:58:17.770591 28372 solver.cpp:404]     Test net output #0: accuracy = 0.632422
I1130 16:58:17.770642 28372 solver.cpp:404]     Test net output #1: loss = 0.633542 (* 1 = 0.633542 loss)
I1130 16:58:17.800215 28372 solver.cpp:228] Iteration 5400, loss = 0.513263
I1130 16:58:17.800271 28372 solver.cpp:244]     Train net output #0: loss = 0.513263 (* 1 = 0.513263 loss)
I1130 16:58:17.800290 28372 sgd_solver.cpp:106] Iteration 5400, lr = 0.0001
I1130 16:58:23.193039 28372 solver.cpp:228] Iteration 5450, loss = 0.598239
I1130 16:58:26.542958 28372 solver.cpp:244]     Train net output #0: loss = 0.598239 (* 1 = 0.598239 loss)
I1130 16:58:26.543095 28372 sgd_solver.cpp:106] Iteration 5450, lr = 0.0001
I1130 16:58:30.277498 28372 solver.cpp:228] Iteration 5500, loss = 0.587382
I1130 16:58:30.277562 28372 solver.cpp:244]     Train net output #0: loss = 0.587382 (* 1 = 0.587382 loss)
I1130 16:58:30.277570 28372 sgd_solver.cpp:106] Iteration 5500, lr = 0.0001
I1130 16:58:34.018739 28372 solver.cpp:228] Iteration 5550, loss = 0.675667
I1130 16:58:34.018785 28372 solver.cpp:244]     Train net output #0: loss = 0.675667 (* 1 = 0.675667 loss)
I1130 16:58:34.018792 28372 sgd_solver.cpp:106] Iteration 5550, lr = 0.0001
I1130 16:58:37.739526 28372 solver.cpp:337] Iteration 5600, Testing net (#0)
I1130 16:58:47.914800 28372 solver.cpp:404]     Test net output #0: accuracy = 0.63444
I1130 16:58:47.914863 28372 solver.cpp:404]     Test net output #1: loss = 0.632207 (* 1 = 0.632207 loss)
I1130 16:58:47.967190 28372 solver.cpp:228] Iteration 5600, loss = 0.570107
I1130 16:58:47.967255 28372 solver.cpp:244]     Train net output #0: loss = 0.570107 (* 1 = 0.570107 loss)
I1130 16:58:47.967273 28372 sgd_solver.cpp:106] Iteration 5600, lr = 0.0001
I1130 16:58:53.038527 28372 solver.cpp:228] Iteration 5650, loss = 0.619622
I1130 16:58:53.038589 28372 solver.cpp:244]     Train net output #0: loss = 0.619622 (* 1 = 0.619622 loss)
I1130 16:58:53.038596 28372 sgd_solver.cpp:106] Iteration 5650, lr = 0.0001
I1130 16:58:57.571038 28372 solver.cpp:228] Iteration 5700, loss = 0.559098
I1130 16:58:58.542644 28372 solver.cpp:244]     Train net output #0: loss = 0.559098 (* 1 = 0.559098 loss)
I1130 16:58:58.542671 28372 sgd_solver.cpp:106] Iteration 5700, lr = 0.0001
I1130 16:59:03.718870 28372 solver.cpp:228] Iteration 5750, loss = 0.597695
I1130 16:59:03.718914 28372 solver.cpp:244]     Train net output #0: loss = 0.597695 (* 1 = 0.597695 loss)
I1130 16:59:03.718921 28372 sgd_solver.cpp:106] Iteration 5750, lr = 0.0001
I1130 16:59:09.314872 28372 solver.cpp:337] Iteration 5800, Testing net (#0)
I1130 16:59:14.166744 28372 blocking_queue.cpp:50] Data layer prefetch queue empty
I1130 16:59:18.536876 28372 solver.cpp:404]     Test net output #0: accuracy = 0.635091
I1130 16:59:18.536936 28372 solver.cpp:404]     Test net output #1: loss = 0.631917 (* 1 = 0.631917 loss)
I1130 16:59:18.566294 28372 solver.cpp:228] Iteration 5800, loss = 0.548124
I1130 16:59:18.566335 28372 solver.cpp:244]     Train net output #0: loss = 0.548124 (* 1 = 0.548124 loss)
I1130 16:59:18.566346 28372 sgd_solver.cpp:106] Iteration 5800, lr = 0.0001
I1130 16:59:23.855043 28372 solver.cpp:228] Iteration 5850, loss = 0.625306
I1130 16:59:23.855090 28372 solver.cpp:244]     Train net output #0: loss = 0.625306 (* 1 = 0.625306 loss)
I1130 16:59:23.855098 28372 sgd_solver.cpp:106] Iteration 5850, lr = 0.0001
I1130 16:59:29.522686 28372 solver.cpp:228] Iteration 5900, loss = 0.496045
I1130 16:59:29.633177 28372 solver.cpp:244]     Train net output #0: loss = 0.496045 (* 1 = 0.496045 loss)
I1130 16:59:29.633210 28372 sgd_solver.cpp:106] Iteration 5900, lr = 0.0001
I1130 16:59:33.758970 28372 solver.cpp:228] Iteration 5950, loss = 0.598019
I1130 16:59:33.759022 28372 solver.cpp:244]     Train net output #0: loss = 0.598019 (* 1 = 0.598019 loss)
I1130 16:59:33.759030 28372 sgd_solver.cpp:106] Iteration 5950, lr = 0.0001
I1130 16:59:37.656584 28372 solver.cpp:337] Iteration 6000, Testing net (#0)
I1130 16:59:46.334908 28372 solver.cpp:404]     Test net output #0: accuracy = 0.634375
I1130 16:59:46.334956 28372 solver.cpp:404]     Test net output #1: loss = 0.631765 (* 1 = 0.631765 loss)
I1130 16:59:46.375078 28372 solver.cpp:228] Iteration 6000, loss = 0.699207
I1130 16:59:46.375121 28372 solver.cpp:244]     Train net output #0: loss = 0.699207 (* 1 = 0.699207 loss)
I1130 16:59:46.375131 28372 sgd_solver.cpp:106] Iteration 6000, lr = 0.0001
I1130 16:59:51.956641 28372 solver.cpp:228] Iteration 6050, loss = 0.528699
I1130 16:59:51.956688 28372 solver.cpp:244]     Train net output #0: loss = 0.528699 (* 1 = 0.528699 loss)
I1130 16:59:51.956696 28372 sgd_solver.cpp:106] Iteration 6050, lr = 0.0001
I1130 16:59:57.042305 28372 solver.cpp:228] Iteration 6100, loss = 0.60495
I1130 16:59:57.042356 28372 solver.cpp:244]     Train net output #0: loss = 0.60495 (* 1 = 0.60495 loss)
I1130 16:59:57.042362 28372 sgd_solver.cpp:106] Iteration 6100, lr = 0.0001
I1130 17:00:01.405215 28372 solver.cpp:228] Iteration 6150, loss = 0.657508
I1130 17:00:01.405462 28372 solver.cpp:244]     Train net output #0: loss = 0.657508 (* 1 = 0.657508 loss)
I1130 17:00:01.405470 28372 sgd_solver.cpp:106] Iteration 6150, lr = 0.0001
I1130 17:00:05.339102 28372 solver.cpp:337] Iteration 6200, Testing net (#0)
I1130 17:00:15.052708 28372 solver.cpp:404]     Test net output #0: accuracy = 0.636654
I1130 17:00:15.052757 28372 solver.cpp:404]     Test net output #1: loss = 0.63101 (* 1 = 0.63101 loss)
I1130 17:00:15.082103 28372 solver.cpp:228] Iteration 6200, loss = 0.602024
I1130 17:00:15.082151 28372 solver.cpp:244]     Train net output #0: loss = 0.602024 (* 1 = 0.602024 loss)
I1130 17:00:15.082161 28372 sgd_solver.cpp:106] Iteration 6200, lr = 0.0001
I1130 17:00:19.264986 28372 solver.cpp:228] Iteration 6250, loss = 0.620713
I1130 17:00:19.265046 28372 solver.cpp:244]     Train net output #0: loss = 0.620713 (* 1 = 0.620713 loss)
I1130 17:00:19.265053 28372 sgd_solver.cpp:106] Iteration 6250, lr = 0.0001
I1130 17:00:25.160245 28372 solver.cpp:228] Iteration 6300, loss = 0.676531
I1130 17:00:25.160302 28372 solver.cpp:244]     Train net output #0: loss = 0.676531 (* 1 = 0.676531 loss)
I1130 17:00:25.160310 28372 sgd_solver.cpp:106] Iteration 6300, lr = 0.0001
I1130 17:00:30.602957 28372 solver.cpp:228] Iteration 6350, loss = 0.625212
I1130 17:00:30.603008 28372 solver.cpp:244]     Train net output #0: loss = 0.625212 (* 1 = 0.625212 loss)
I1130 17:00:30.603015 28372 sgd_solver.cpp:106] Iteration 6350, lr = 0.0001
I1130 17:00:35.590080 28372 solver.cpp:337] Iteration 6400, Testing net (#0)
I1130 17:00:45.037889 28372 solver.cpp:404]     Test net output #0: accuracy = 0.63776
I1130 17:00:45.037979 28372 solver.cpp:404]     Test net output #1: loss = 0.629619 (* 1 = 0.629619 loss)
I1130 17:00:45.066009 28372 solver.cpp:228] Iteration 6400, loss = 0.587037
I1130 17:00:45.066058 28372 solver.cpp:244]     Train net output #0: loss = 0.587037 (* 1 = 0.587037 loss)
I1130 17:00:45.066068 28372 sgd_solver.cpp:106] Iteration 6400, lr = 0.0001
I1130 17:00:49.251212 28372 solver.cpp:228] Iteration 6450, loss = 0.580037
I1130 17:00:49.251258 28372 solver.cpp:244]     Train net output #0: loss = 0.580037 (* 1 = 0.580037 loss)
I1130 17:00:49.251266 28372 sgd_solver.cpp:106] Iteration 6450, lr = 0.0001
I1130 17:00:53.561514 28372 solver.cpp:228] Iteration 6500, loss = 0.658663
I1130 17:00:53.561575 28372 solver.cpp:244]     Train net output #0: loss = 0.658663 (* 1 = 0.658663 loss)
I1130 17:00:53.561584 28372 sgd_solver.cpp:106] Iteration 6500, lr = 0.0001
I1130 17:00:58.315765 28372 solver.cpp:228] Iteration 6550, loss = 0.661389
I1130 17:00:58.315829 28372 solver.cpp:244]     Train net output #0: loss = 0.661389 (* 1 = 0.661389 loss)
I1130 17:00:58.315839 28372 sgd_solver.cpp:106] Iteration 6550, lr = 0.0001
I1130 17:01:03.040050 28372 solver.cpp:337] Iteration 6600, Testing net (#0)
I1130 17:01:11.729023 28372 solver.cpp:404]     Test net output #0: accuracy = 0.635417
I1130 17:01:11.771729 28372 solver.cpp:404]     Test net output #1: loss = 0.630749 (* 1 = 0.630749 loss)
I1130 17:01:11.800671 28372 solver.cpp:228] Iteration 6600, loss = 0.603305
I1130 17:01:11.800734 28372 solver.cpp:244]     Train net output #0: loss = 0.603305 (* 1 = 0.603305 loss)
I1130 17:01:11.800751 28372 sgd_solver.cpp:106] Iteration 6600, lr = 0.0001
I1130 17:01:15.676663 28372 solver.cpp:228] Iteration 6650, loss = 0.561922
I1130 17:01:15.676735 28372 solver.cpp:244]     Train net output #0: loss = 0.561922 (* 1 = 0.561922 loss)
I1130 17:01:15.676754 28372 sgd_solver.cpp:106] Iteration 6650, lr = 0.0001
I1130 17:01:19.938741 28372 solver.cpp:228] Iteration 6700, loss = 0.607211
I1130 17:01:19.938794 28372 solver.cpp:244]     Train net output #0: loss = 0.607211 (* 1 = 0.607211 loss)
I1130 17:01:19.938802 28372 sgd_solver.cpp:106] Iteration 6700, lr = 0.0001
I1130 17:01:24.055519 28372 solver.cpp:228] Iteration 6750, loss = 0.535689
I1130 17:01:24.055584 28372 solver.cpp:244]     Train net output #0: loss = 0.535689 (* 1 = 0.535689 loss)
I1130 17:01:24.055595 28372 sgd_solver.cpp:106] Iteration 6750, lr = 0.0001
I1130 17:01:29.561636 28372 solver.cpp:337] Iteration 6800, Testing net (#0)
I1130 17:01:39.007063 28372 solver.cpp:404]     Test net output #0: accuracy = 0.635807
I1130 17:01:39.007130 28372 solver.cpp:404]     Test net output #1: loss = 0.630023 (* 1 = 0.630023 loss)
I1130 17:01:39.055958 28372 solver.cpp:228] Iteration 6800, loss = 0.598167
I1130 17:01:39.056004 28372 solver.cpp:244]     Train net output #0: loss = 0.598167 (* 1 = 0.598167 loss)
I1130 17:01:39.056013 28372 sgd_solver.cpp:106] Iteration 6800, lr = 0.0001
I1130 17:01:45.069433 28372 solver.cpp:228] Iteration 6850, loss = 0.558243
I1130 17:01:45.069656 28372 solver.cpp:244]     Train net output #0: loss = 0.558243 (* 1 = 0.558243 loss)
I1130 17:01:45.069665 28372 sgd_solver.cpp:106] Iteration 6850, lr = 0.0001
I1130 17:01:50.300907 28372 solver.cpp:228] Iteration 6900, loss = 0.582095
I1130 17:01:50.300954 28372 solver.cpp:244]     Train net output #0: loss = 0.582095 (* 1 = 0.582095 loss)
I1130 17:01:50.300962 28372 sgd_solver.cpp:106] Iteration 6900, lr = 0.0001
I1130 17:01:55.518992 28372 solver.cpp:228] Iteration 6950, loss = 0.621985
I1130 17:01:55.519048 28372 solver.cpp:244]     Train net output #0: loss = 0.621985 (* 1 = 0.621985 loss)
I1130 17:01:55.519053 28372 sgd_solver.cpp:106] Iteration 6950, lr = 0.0001
I1130 17:01:59.837162 28372 solver.cpp:337] Iteration 7000, Testing net (#0)
I1130 17:02:06.788038 28372 blocking_queue.cpp:50] Data layer prefetch queue empty
I1130 17:02:08.227538 28372 solver.cpp:404]     Test net output #0: accuracy = 0.636133
I1130 17:02:08.227586 28372 solver.cpp:404]     Test net output #1: loss = 0.629574 (* 1 = 0.629574 loss)
I1130 17:02:08.267362 28372 solver.cpp:228] Iteration 7000, loss = 0.633221
I1130 17:02:08.267403 28372 solver.cpp:244]     Train net output #0: loss = 0.633221 (* 1 = 0.633221 loss)
I1130 17:02:08.267413 28372 sgd_solver.cpp:106] Iteration 7000, lr = 0.0001
I1130 17:02:13.931614 28372 solver.cpp:228] Iteration 7050, loss = 0.5584
I1130 17:02:13.931685 28372 solver.cpp:244]     Train net output #0: loss = 0.5584 (* 1 = 0.5584 loss)
I1130 17:02:13.931694 28372 sgd_solver.cpp:106] Iteration 7050, lr = 0.0001
I1130 17:02:18.005028 28372 solver.cpp:228] Iteration 7100, loss = 0.670259
I1130 17:02:18.058408 28372 solver.cpp:244]     Train net output #0: loss = 0.670259 (* 1 = 0.670259 loss)
I1130 17:02:18.058440 28372 sgd_solver.cpp:106] Iteration 7100, lr = 0.0001
I1130 17:02:21.965941 28372 solver.cpp:228] Iteration 7150, loss = 0.574728
I1130 17:02:21.966003 28372 solver.cpp:244]     Train net output #0: loss = 0.574728 (* 1 = 0.574728 loss)
I1130 17:02:21.966012 28372 sgd_solver.cpp:106] Iteration 7150, lr = 0.0001
I1130 17:02:26.950462 28372 solver.cpp:337] Iteration 7200, Testing net (#0)
I1130 17:02:35.733633 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641211
I1130 17:02:35.733696 28372 solver.cpp:404]     Test net output #1: loss = 0.62808 (* 1 = 0.62808 loss)
I1130 17:02:35.776486 28372 solver.cpp:228] Iteration 7200, loss = 0.629672
I1130 17:02:35.776532 28372 solver.cpp:244]     Train net output #0: loss = 0.629672 (* 1 = 0.629672 loss)
I1130 17:02:35.776542 28372 sgd_solver.cpp:106] Iteration 7200, lr = 0.0001
I1130 17:02:41.683692 28372 solver.cpp:228] Iteration 7250, loss = 0.630119
I1130 17:02:41.683743 28372 solver.cpp:244]     Train net output #0: loss = 0.630119 (* 1 = 0.630119 loss)
I1130 17:02:41.683750 28372 sgd_solver.cpp:106] Iteration 7250, lr = 0.0001
I1130 17:02:46.902256 28372 solver.cpp:228] Iteration 7300, loss = 0.57545
I1130 17:02:46.902318 28372 solver.cpp:244]     Train net output #0: loss = 0.57545 (* 1 = 0.57545 loss)
I1130 17:02:46.902326 28372 sgd_solver.cpp:106] Iteration 7300, lr = 0.0001
I1130 17:02:51.861531 28372 solver.cpp:228] Iteration 7350, loss = 0.657418
I1130 17:02:51.916380 28372 solver.cpp:244]     Train net output #0: loss = 0.657418 (* 1 = 0.657418 loss)
I1130 17:02:51.916406 28372 sgd_solver.cpp:106] Iteration 7350, lr = 0.0001
I1130 17:02:57.566377 28372 solver.cpp:337] Iteration 7400, Testing net (#0)
I1130 17:03:05.298265 28372 solver.cpp:404]     Test net output #0: accuracy = 0.638021
I1130 17:03:05.298326 28372 solver.cpp:404]     Test net output #1: loss = 0.62851 (* 1 = 0.62851 loss)
I1130 17:03:05.327020 28372 solver.cpp:228] Iteration 7400, loss = 0.518584
I1130 17:03:05.327072 28372 solver.cpp:244]     Train net output #0: loss = 0.518584 (* 1 = 0.518584 loss)
I1130 17:03:05.327085 28372 sgd_solver.cpp:106] Iteration 7400, lr = 0.0001
I1130 17:03:10.575747 28372 solver.cpp:228] Iteration 7450, loss = 0.555472
I1130 17:03:10.575806 28372 solver.cpp:244]     Train net output #0: loss = 0.555472 (* 1 = 0.555472 loss)
I1130 17:03:10.575814 28372 sgd_solver.cpp:106] Iteration 7450, lr = 0.0001
I1130 17:03:15.846508 28372 solver.cpp:228] Iteration 7500, loss = 0.59474
I1130 17:03:15.846573 28372 solver.cpp:244]     Train net output #0: loss = 0.59474 (* 1 = 0.59474 loss)
I1130 17:03:15.846580 28372 sgd_solver.cpp:106] Iteration 7500, lr = 0.0001
I1130 17:03:20.529801 28372 solver.cpp:228] Iteration 7550, loss = 0.585307
I1130 17:03:20.529872 28372 solver.cpp:244]     Train net output #0: loss = 0.585307 (* 1 = 0.585307 loss)
I1130 17:03:20.529881 28372 sgd_solver.cpp:106] Iteration 7550, lr = 0.0001
I1130 17:03:26.114950 28372 solver.cpp:337] Iteration 7600, Testing net (#0)
I1130 17:03:34.463748 28372 solver.cpp:404]     Test net output #0: accuracy = 0.640104
I1130 17:03:34.463804 28372 solver.cpp:404]     Test net output #1: loss = 0.628916 (* 1 = 0.628916 loss)
I1130 17:03:34.490752 28372 solver.cpp:228] Iteration 7600, loss = 0.653573
I1130 17:03:34.490818 28372 solver.cpp:244]     Train net output #0: loss = 0.653573 (* 1 = 0.653573 loss)
I1130 17:03:34.490833 28372 sgd_solver.cpp:106] Iteration 7600, lr = 0.0001
I1130 17:03:39.280856 28372 solver.cpp:228] Iteration 7650, loss = 0.56896
I1130 17:03:39.280906 28372 solver.cpp:244]     Train net output #0: loss = 0.56896 (* 1 = 0.56896 loss)
I1130 17:03:39.280915 28372 sgd_solver.cpp:106] Iteration 7650, lr = 0.0001
I1130 17:03:45.413406 28372 solver.cpp:228] Iteration 7700, loss = 0.537184
I1130 17:03:45.413458 28372 solver.cpp:244]     Train net output #0: loss = 0.537184 (* 1 = 0.537184 loss)
I1130 17:03:45.413465 28372 sgd_solver.cpp:106] Iteration 7700, lr = 0.0001
I1130 17:03:49.458662 28372 solver.cpp:228] Iteration 7750, loss = 0.587022
I1130 17:03:49.458720 28372 solver.cpp:244]     Train net output #0: loss = 0.587022 (* 1 = 0.587022 loss)
I1130 17:03:49.458725 28372 sgd_solver.cpp:106] Iteration 7750, lr = 0.0001
I1130 17:03:53.387109 28372 solver.cpp:337] Iteration 7800, Testing net (#0)
I1130 17:04:01.407929 28372 solver.cpp:404]     Test net output #0: accuracy = 0.640625
I1130 17:04:01.429396 28372 solver.cpp:404]     Test net output #1: loss = 0.627772 (* 1 = 0.627772 loss)
I1130 17:04:01.459229 28372 solver.cpp:228] Iteration 7800, loss = 0.662911
I1130 17:04:01.459290 28372 solver.cpp:244]     Train net output #0: loss = 0.662911 (* 1 = 0.662911 loss)
I1130 17:04:01.459307 28372 sgd_solver.cpp:106] Iteration 7800, lr = 0.0001
I1130 17:04:05.771520 28372 solver.cpp:228] Iteration 7850, loss = 0.580008
I1130 17:04:05.771575 28372 solver.cpp:244]     Train net output #0: loss = 0.580008 (* 1 = 0.580008 loss)
I1130 17:04:05.771584 28372 sgd_solver.cpp:106] Iteration 7850, lr = 0.0001
I1130 17:04:11.562443 28372 solver.cpp:228] Iteration 7900, loss = 0.612022
I1130 17:04:11.562495 28372 solver.cpp:244]     Train net output #0: loss = 0.612022 (* 1 = 0.612022 loss)
I1130 17:04:11.562503 28372 sgd_solver.cpp:106] Iteration 7900, lr = 0.0001
I1130 17:04:16.705400 28372 solver.cpp:228] Iteration 7950, loss = 0.670876
I1130 17:04:16.705453 28372 solver.cpp:244]     Train net output #0: loss = 0.670876 (* 1 = 0.670876 loss)
I1130 17:04:16.705461 28372 sgd_solver.cpp:106] Iteration 7950, lr = 0.0001
I1130 17:04:21.915958 28372 solver.cpp:337] Iteration 8000, Testing net (#0)
I1130 17:04:28.042043 28372 blocking_queue.cpp:50] Data layer prefetch queue empty
I1130 17:04:29.687199 28372 solver.cpp:404]     Test net output #0: accuracy = 0.639518
I1130 17:04:29.687258 28372 solver.cpp:404]     Test net output #1: loss = 0.628251 (* 1 = 0.628251 loss)
I1130 17:04:29.717165 28372 solver.cpp:228] Iteration 8000, loss = 0.536639
I1130 17:04:29.717221 28372 solver.cpp:244]     Train net output #0: loss = 0.536639 (* 1 = 0.536639 loss)
I1130 17:04:29.717231 28372 sgd_solver.cpp:106] Iteration 8000, lr = 0.0001
I1130 17:04:35.565160 28372 solver.cpp:228] Iteration 8050, loss = 0.623538
I1130 17:04:35.778424 28372 solver.cpp:244]     Train net output #0: loss = 0.623538 (* 1 = 0.623538 loss)
I1130 17:04:35.778439 28372 sgd_solver.cpp:106] Iteration 8050, lr = 0.0001
I1130 17:04:40.813875 28372 solver.cpp:228] Iteration 8100, loss = 0.624006
I1130 17:04:40.813935 28372 solver.cpp:244]     Train net output #0: loss = 0.624006 (* 1 = 0.624006 loss)
I1130 17:04:40.813941 28372 sgd_solver.cpp:106] Iteration 8100, lr = 0.0001
I1130 17:04:46.860186 28372 solver.cpp:228] Iteration 8150, loss = 0.600684
I1130 17:04:46.860249 28372 solver.cpp:244]     Train net output #0: loss = 0.600684 (* 1 = 0.600684 loss)
I1130 17:04:46.860256 28372 sgd_solver.cpp:106] Iteration 8150, lr = 0.0001
I1130 17:04:52.150768 28372 solver.cpp:337] Iteration 8200, Testing net (#0)
I1130 17:05:01.533704 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641276
I1130 17:05:01.533761 28372 solver.cpp:404]     Test net output #1: loss = 0.627089 (* 1 = 0.627089 loss)
I1130 17:05:01.579260 28372 solver.cpp:228] Iteration 8200, loss = 0.595489
I1130 17:05:01.579311 28372 solver.cpp:244]     Train net output #0: loss = 0.595489 (* 1 = 0.595489 loss)
I1130 17:05:01.579324 28372 sgd_solver.cpp:106] Iteration 8200, lr = 0.0001
I1130 17:05:06.845113 28372 solver.cpp:228] Iteration 8250, loss = 0.626059
I1130 17:05:10.542959 28372 solver.cpp:244]     Train net output #0: loss = 0.626059 (* 1 = 0.626059 loss)
I1130 17:05:10.542989 28372 sgd_solver.cpp:106] Iteration 8250, lr = 0.0001
I1130 17:05:15.613808 28372 solver.cpp:228] Iteration 8300, loss = 0.587693
I1130 17:05:15.613860 28372 solver.cpp:244]     Train net output #0: loss = 0.587693 (* 1 = 0.587693 loss)
I1130 17:05:15.613879 28372 sgd_solver.cpp:106] Iteration 8300, lr = 0.0001
I1130 17:05:20.954816 28372 solver.cpp:228] Iteration 8350, loss = 0.653598
I1130 17:05:20.954865 28372 solver.cpp:244]     Train net output #0: loss = 0.653598 (* 1 = 0.653598 loss)
I1130 17:05:20.954874 28372 sgd_solver.cpp:106] Iteration 8350, lr = 0.0001
I1130 17:05:26.710916 28372 solver.cpp:337] Iteration 8400, Testing net (#0)
I1130 17:05:36.979802 28372 solver.cpp:404]     Test net output #0: accuracy = 0.640365
I1130 17:05:38.542968 28372 solver.cpp:404]     Test net output #1: loss = 0.62751 (* 1 = 0.62751 loss)
I1130 17:05:38.579538 28372 solver.cpp:228] Iteration 8400, loss = 0.55753
I1130 17:05:38.579618 28372 solver.cpp:244]     Train net output #0: loss = 0.55753 (* 1 = 0.55753 loss)
I1130 17:05:38.579638 28372 sgd_solver.cpp:106] Iteration 8400, lr = 0.0001
I1130 17:05:43.554527 28372 solver.cpp:228] Iteration 8450, loss = 0.628431
I1130 17:05:43.554597 28372 solver.cpp:244]     Train net output #0: loss = 0.628431 (* 1 = 0.628431 loss)
I1130 17:05:43.554605 28372 sgd_solver.cpp:106] Iteration 8450, lr = 0.0001
I1130 17:05:48.758750 28372 solver.cpp:228] Iteration 8500, loss = 0.589055
I1130 17:05:48.758813 28372 solver.cpp:244]     Train net output #0: loss = 0.589055 (* 1 = 0.589055 loss)
I1130 17:05:48.758821 28372 sgd_solver.cpp:106] Iteration 8500, lr = 0.0001
I1130 17:05:54.654877 28372 solver.cpp:228] Iteration 8550, loss = 0.683537
I1130 17:05:54.654938 28372 solver.cpp:244]     Train net output #0: loss = 0.683537 (* 1 = 0.683537 loss)
I1130 17:05:54.654945 28372 sgd_solver.cpp:106] Iteration 8550, lr = 0.0001
I1130 17:06:00.162828 28372 solver.cpp:337] Iteration 8600, Testing net (#0)
I1130 17:06:09.113950 28372 solver.cpp:404]     Test net output #0: accuracy = 0.636003
I1130 17:06:10.542735 28372 solver.cpp:404]     Test net output #1: loss = 0.629347 (* 1 = 0.629347 loss)
I1130 17:06:10.580027 28372 solver.cpp:228] Iteration 8600, loss = 0.613591
I1130 17:06:10.580099 28372 solver.cpp:244]     Train net output #0: loss = 0.613591 (* 1 = 0.613591 loss)
I1130 17:06:10.580117 28372 sgd_solver.cpp:106] Iteration 8600, lr = 0.0001
I1130 17:06:15.738834 28372 solver.cpp:228] Iteration 8650, loss = 0.559917
I1130 17:06:15.738888 28372 solver.cpp:244]     Train net output #0: loss = 0.559917 (* 1 = 0.559917 loss)
I1130 17:06:15.738896 28372 sgd_solver.cpp:106] Iteration 8650, lr = 0.0001
I1130 17:06:19.616250 28372 solver.cpp:228] Iteration 8700, loss = 0.574809
I1130 17:06:19.616307 28372 solver.cpp:244]     Train net output #0: loss = 0.574809 (* 1 = 0.574809 loss)
I1130 17:06:19.616314 28372 sgd_solver.cpp:106] Iteration 8700, lr = 0.0001
I1130 17:06:24.288400 28372 solver.cpp:228] Iteration 8750, loss = 0.773352
I1130 17:06:24.288462 28372 solver.cpp:244]     Train net output #0: loss = 0.773352 (* 1 = 0.773352 loss)
I1130 17:06:24.288470 28372 sgd_solver.cpp:106] Iteration 8750, lr = 0.0001
I1130 17:06:28.911275 28372 solver.cpp:337] Iteration 8800, Testing net (#0)
I1130 17:06:36.572355 28372 solver.cpp:404]     Test net output #0: accuracy = 0.638737
I1130 17:06:36.572417 28372 solver.cpp:404]     Test net output #1: loss = 0.62663 (* 1 = 0.62663 loss)
I1130 17:06:36.602820 28372 solver.cpp:228] Iteration 8800, loss = 0.585413
I1130 17:06:36.602879 28372 solver.cpp:244]     Train net output #0: loss = 0.585413 (* 1 = 0.585413 loss)
I1130 17:06:36.602890 28372 sgd_solver.cpp:106] Iteration 8800, lr = 0.0001
I1130 17:06:40.544800 28372 solver.cpp:228] Iteration 8850, loss = 0.486091
I1130 17:06:42.542965 28372 solver.cpp:244]     Train net output #0: loss = 0.486091 (* 1 = 0.486091 loss)
I1130 17:06:42.542995 28372 sgd_solver.cpp:106] Iteration 8850, lr = 0.0001
I1130 17:06:46.270275 28372 solver.cpp:228] Iteration 8900, loss = 0.610432
I1130 17:06:46.270344 28372 solver.cpp:244]     Train net output #0: loss = 0.610432 (* 1 = 0.610432 loss)
I1130 17:06:46.270351 28372 sgd_solver.cpp:106] Iteration 8900, lr = 0.0001
I1130 17:06:51.942476 28372 solver.cpp:228] Iteration 8950, loss = 0.604225
I1130 17:06:51.942529 28372 solver.cpp:244]     Train net output #0: loss = 0.604225 (* 1 = 0.604225 loss)
I1130 17:06:51.942536 28372 sgd_solver.cpp:106] Iteration 8950, lr = 0.0001
I1130 17:06:56.400179 28372 solver.cpp:337] Iteration 9000, Testing net (#0)
I1130 17:07:05.674000 28372 solver.cpp:404]     Test net output #0: accuracy = 0.636523
I1130 17:07:05.674057 28372 solver.cpp:404]     Test net output #1: loss = 0.6269 (* 1 = 0.6269 loss)
I1130 17:07:05.719796 28372 solver.cpp:228] Iteration 9000, loss = 0.581765
I1130 17:07:05.719867 28372 solver.cpp:244]     Train net output #0: loss = 0.581765 (* 1 = 0.581765 loss)
I1130 17:07:05.719882 28372 sgd_solver.cpp:106] Iteration 9000, lr = 0.0001
I1130 17:07:11.400436 28372 solver.cpp:228] Iteration 9050, loss = 0.596361
I1130 17:07:11.522452 28372 solver.cpp:244]     Train net output #0: loss = 0.596361 (* 1 = 0.596361 loss)
I1130 17:07:11.522480 28372 sgd_solver.cpp:106] Iteration 9050, lr = 0.0001
I1130 17:07:17.146555 28372 solver.cpp:228] Iteration 9100, loss = 0.599102
I1130 17:07:17.146606 28372 solver.cpp:244]     Train net output #0: loss = 0.599102 (* 1 = 0.599102 loss)
I1130 17:07:17.146626 28372 sgd_solver.cpp:106] Iteration 9100, lr = 0.0001
I1130 17:07:22.370343 28372 solver.cpp:228] Iteration 9150, loss = 0.591943
I1130 17:07:22.370394 28372 solver.cpp:244]     Train net output #0: loss = 0.591943 (* 1 = 0.591943 loss)
I1130 17:07:22.370403 28372 sgd_solver.cpp:106] Iteration 9150, lr = 0.0001
I1130 17:07:27.125425 28372 solver.cpp:337] Iteration 9200, Testing net (#0)
I1130 17:07:34.869580 28372 blocking_queue.cpp:50] Data layer prefetch queue empty
I1130 17:07:35.525367 28372 solver.cpp:404]     Test net output #0: accuracy = 0.638997
I1130 17:07:35.525421 28372 solver.cpp:404]     Test net output #1: loss = 0.625896 (* 1 = 0.625896 loss)
I1130 17:07:35.551856 28372 solver.cpp:228] Iteration 9200, loss = 0.605815
I1130 17:07:35.551885 28372 solver.cpp:244]     Train net output #0: loss = 0.605815 (* 1 = 0.605815 loss)
I1130 17:07:35.551894 28372 sgd_solver.cpp:106] Iteration 9200, lr = 0.0001
I1130 17:07:39.565958 28372 solver.cpp:228] Iteration 9250, loss = 0.584341
I1130 17:07:39.566030 28372 solver.cpp:244]     Train net output #0: loss = 0.584341 (* 1 = 0.584341 loss)
I1130 17:07:39.566048 28372 sgd_solver.cpp:106] Iteration 9250, lr = 0.0001
I1130 17:07:44.328291 28372 solver.cpp:228] Iteration 9300, loss = 0.606681
I1130 17:07:44.670600 28372 solver.cpp:244]     Train net output #0: loss = 0.606681 (* 1 = 0.606681 loss)
I1130 17:07:44.670632 28372 sgd_solver.cpp:106] Iteration 9300, lr = 0.0001
I1130 17:07:50.288395 28372 solver.cpp:228] Iteration 9350, loss = 0.703847
I1130 17:07:50.288461 28372 solver.cpp:244]     Train net output #0: loss = 0.703847 (* 1 = 0.703847 loss)
I1130 17:07:50.288468 28372 sgd_solver.cpp:106] Iteration 9350, lr = 0.0001
I1130 17:07:55.334503 28372 solver.cpp:337] Iteration 9400, Testing net (#0)
I1130 17:08:04.142434 28372 solver.cpp:404]     Test net output #0: accuracy = 0.63776
I1130 17:08:04.142493 28372 solver.cpp:404]     Test net output #1: loss = 0.626226 (* 1 = 0.626226 loss)
I1130 17:08:04.194067 28372 solver.cpp:228] Iteration 9400, loss = 0.66348
I1130 17:08:04.194118 28372 solver.cpp:244]     Train net output #0: loss = 0.66348 (* 1 = 0.66348 loss)
I1130 17:08:04.194128 28372 sgd_solver.cpp:106] Iteration 9400, lr = 0.0001
I1130 17:08:09.854511 28372 solver.cpp:228] Iteration 9450, loss = 0.640291
I1130 17:08:09.854586 28372 solver.cpp:244]     Train net output #0: loss = 0.640291 (* 1 = 0.640291 loss)
I1130 17:08:09.854594 28372 sgd_solver.cpp:106] Iteration 9450, lr = 0.0001
I1130 17:08:14.842291 28372 solver.cpp:228] Iteration 9500, loss = 0.607768
I1130 17:08:18.542959 28372 solver.cpp:244]     Train net output #0: loss = 0.607768 (* 1 = 0.607768 loss)
I1130 17:08:18.542994 28372 sgd_solver.cpp:106] Iteration 9500, lr = 0.0001
I1130 17:08:24.143721 28372 solver.cpp:228] Iteration 9550, loss = 0.562093
I1130 17:08:24.143784 28372 solver.cpp:244]     Train net output #0: loss = 0.562093 (* 1 = 0.562093 loss)
I1130 17:08:24.143791 28372 sgd_solver.cpp:106] Iteration 9550, lr = 0.0001
I1130 17:08:29.670917 28372 solver.cpp:337] Iteration 9600, Testing net (#0)
I1130 17:08:37.375066 28372 solver.cpp:404]     Test net output #0: accuracy = 0.643034
I1130 17:08:37.375119 28372 solver.cpp:404]     Test net output #1: loss = 0.624909 (* 1 = 0.624909 loss)
I1130 17:08:37.405194 28372 solver.cpp:228] Iteration 9600, loss = 0.478782
I1130 17:08:37.405236 28372 solver.cpp:244]     Train net output #0: loss = 0.478782 (* 1 = 0.478782 loss)
I1130 17:08:37.405249 28372 sgd_solver.cpp:106] Iteration 9600, lr = 0.0001
I1130 17:08:43.030201 28372 solver.cpp:228] Iteration 9650, loss = 0.647439
I1130 17:08:43.030258 28372 solver.cpp:244]     Train net output #0: loss = 0.647439 (* 1 = 0.647439 loss)
I1130 17:08:43.030267 28372 sgd_solver.cpp:106] Iteration 9650, lr = 0.0001
I1130 17:08:48.968333 28372 solver.cpp:228] Iteration 9700, loss = 0.637858
I1130 17:08:49.024395 28372 solver.cpp:244]     Train net output #0: loss = 0.637858 (* 1 = 0.637858 loss)
I1130 17:08:49.024420 28372 sgd_solver.cpp:106] Iteration 9700, lr = 0.0001
I1130 17:08:54.901559 28372 solver.cpp:228] Iteration 9750, loss = 0.622462
I1130 17:08:54.901620 28372 solver.cpp:244]     Train net output #0: loss = 0.622462 (* 1 = 0.622462 loss)
I1130 17:08:54.901638 28372 sgd_solver.cpp:106] Iteration 9750, lr = 0.0001
I1130 17:08:59.943425 28372 solver.cpp:337] Iteration 9800, Testing net (#0)
I1130 17:09:08.849310 28372 solver.cpp:404]     Test net output #0: accuracy = 0.638607
I1130 17:09:08.849349 28372 solver.cpp:404]     Test net output #1: loss = 0.625798 (* 1 = 0.625798 loss)
I1130 17:09:08.875764 28372 solver.cpp:228] Iteration 9800, loss = 0.50626
I1130 17:09:08.875793 28372 solver.cpp:244]     Train net output #0: loss = 0.50626 (* 1 = 0.50626 loss)
I1130 17:09:08.875803 28372 sgd_solver.cpp:106] Iteration 9800, lr = 0.0001
I1130 17:09:14.073227 28372 solver.cpp:228] Iteration 9850, loss = 0.735711
I1130 17:09:14.073287 28372 solver.cpp:244]     Train net output #0: loss = 0.735711 (* 1 = 0.735711 loss)
I1130 17:09:14.073293 28372 sgd_solver.cpp:106] Iteration 9850, lr = 0.0001
I1130 17:09:20.052590 28372 solver.cpp:228] Iteration 9900, loss = 0.590281
I1130 17:09:20.667136 28372 solver.cpp:244]     Train net output #0: loss = 0.590281 (* 1 = 0.590281 loss)
I1130 17:09:20.667167 28372 sgd_solver.cpp:106] Iteration 9900, lr = 0.0001
I1130 17:09:25.822934 28372 solver.cpp:228] Iteration 9950, loss = 0.565207
I1130 17:09:25.822983 28372 solver.cpp:244]     Train net output #0: loss = 0.565207 (* 1 = 0.565207 loss)
I1130 17:09:25.822990 28372 sgd_solver.cpp:106] Iteration 9950, lr = 0.0001
I1130 17:09:31.300489 28372 solver.cpp:454] Snapshotting to binary proto file /home/tbochens/Nets/FineTuning/Facebook/thumb_2/solver2/facebook_solv2_iter_10000.caffemodel
I1130 17:09:32.338536 28372 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/tbochens/Nets/FineTuning/Facebook/thumb_2/solver2/facebook_solv2_iter_10000.solverstate
I1130 17:09:32.667752 28372 solver.cpp:337] Iteration 10000, Testing net (#0)
I1130 17:09:41.427803 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641081
I1130 17:09:41.427862 28372 solver.cpp:404]     Test net output #1: loss = 0.625001 (* 1 = 0.625001 loss)
I1130 17:09:41.458271 28372 solver.cpp:228] Iteration 10000, loss = 0.626049
I1130 17:09:41.458346 28372 solver.cpp:244]     Train net output #0: loss = 0.626049 (* 1 = 0.626049 loss)
I1130 17:09:41.458365 28372 sgd_solver.cpp:106] Iteration 10000, lr = 1e-05
I1130 17:09:46.674962 28372 solver.cpp:228] Iteration 10050, loss = 0.587828
I1130 17:09:46.675040 28372 solver.cpp:244]     Train net output #0: loss = 0.587828 (* 1 = 0.587828 loss)
I1130 17:09:46.675047 28372 sgd_solver.cpp:106] Iteration 10050, lr = 1e-05
I1130 17:09:50.664145 28372 solver.cpp:228] Iteration 10100, loss = 0.587143
I1130 17:09:50.664377 28372 solver.cpp:244]     Train net output #0: loss = 0.587143 (* 1 = 0.587143 loss)
I1130 17:09:50.664386 28372 sgd_solver.cpp:106] Iteration 10100, lr = 1e-05
I1130 17:09:56.637969 28372 solver.cpp:228] Iteration 10150, loss = 0.567164
I1130 17:09:56.638015 28372 solver.cpp:244]     Train net output #0: loss = 0.567164 (* 1 = 0.567164 loss)
I1130 17:09:56.638021 28372 sgd_solver.cpp:106] Iteration 10150, lr = 1e-05
I1130 17:10:01.981385 28372 solver.cpp:337] Iteration 10200, Testing net (#0)
I1130 17:10:11.505090 28372 solver.cpp:404]     Test net output #0: accuracy = 0.640625
I1130 17:10:11.505156 28372 solver.cpp:404]     Test net output #1: loss = 0.625264 (* 1 = 0.625264 loss)
I1130 17:10:11.534389 28372 solver.cpp:228] Iteration 10200, loss = 0.613737
I1130 17:10:11.534443 28372 solver.cpp:244]     Train net output #0: loss = 0.613737 (* 1 = 0.613737 loss)
I1130 17:10:11.534454 28372 sgd_solver.cpp:106] Iteration 10200, lr = 1e-05
I1130 17:10:17.305292 28372 solver.cpp:228] Iteration 10250, loss = 0.56018
I1130 17:10:17.305356 28372 solver.cpp:244]     Train net output #0: loss = 0.56018 (* 1 = 0.56018 loss)
I1130 17:10:17.305363 28372 sgd_solver.cpp:106] Iteration 10250, lr = 1e-05
I1130 17:10:23.203505 28372 solver.cpp:228] Iteration 10300, loss = 0.657223
I1130 17:10:23.642566 28372 solver.cpp:244]     Train net output #0: loss = 0.657223 (* 1 = 0.657223 loss)
I1130 17:10:23.642594 28372 sgd_solver.cpp:106] Iteration 10300, lr = 1e-05
I1130 17:10:27.579198 28372 solver.cpp:228] Iteration 10350, loss = 0.565101
I1130 17:10:27.579257 28372 solver.cpp:244]     Train net output #0: loss = 0.565101 (* 1 = 0.565101 loss)
I1130 17:10:27.579264 28372 sgd_solver.cpp:106] Iteration 10350, lr = 1e-05
I1130 17:10:32.149335 28372 solver.cpp:337] Iteration 10400, Testing net (#0)
I1130 17:10:39.810605 28372 blocking_queue.cpp:50] Data layer prefetch queue empty
I1130 17:10:40.984635 28372 solver.cpp:404]     Test net output #0: accuracy = 0.642122
I1130 17:10:40.984712 28372 solver.cpp:404]     Test net output #1: loss = 0.624816 (* 1 = 0.624816 loss)
I1130 17:10:41.009289 28372 solver.cpp:228] Iteration 10400, loss = 0.585666
I1130 17:10:41.009336 28372 solver.cpp:244]     Train net output #0: loss = 0.585666 (* 1 = 0.585666 loss)
I1130 17:10:41.009356 28372 sgd_solver.cpp:106] Iteration 10400, lr = 1e-05
I1130 17:10:45.543566 28372 solver.cpp:228] Iteration 10450, loss = 0.699964
I1130 17:10:45.543618 28372 solver.cpp:244]     Train net output #0: loss = 0.699964 (* 1 = 0.699964 loss)
I1130 17:10:45.543625 28372 sgd_solver.cpp:106] Iteration 10450, lr = 1e-05
I1130 17:10:51.774866 28372 solver.cpp:228] Iteration 10500, loss = 0.577445
I1130 17:10:51.774931 28372 solver.cpp:244]     Train net output #0: loss = 0.577445 (* 1 = 0.577445 loss)
I1130 17:10:51.774940 28372 sgd_solver.cpp:106] Iteration 10500, lr = 1e-05
I1130 17:10:57.740756 28372 solver.cpp:228] Iteration 10550, loss = 0.609666
I1130 17:10:58.542970 28372 solver.cpp:244]     Train net output #0: loss = 0.609666 (* 1 = 0.609666 loss)
I1130 17:10:58.542999 28372 sgd_solver.cpp:106] Iteration 10550, lr = 1e-05
I1130 17:11:03.463423 28372 solver.cpp:337] Iteration 10600, Testing net (#0)
I1130 17:11:12.192072 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641797
I1130 17:11:12.192131 28372 solver.cpp:404]     Test net output #1: loss = 0.624543 (* 1 = 0.624543 loss)
I1130 17:11:12.218763 28372 solver.cpp:228] Iteration 10600, loss = 0.588559
I1130 17:11:12.218816 28372 solver.cpp:244]     Train net output #0: loss = 0.588559 (* 1 = 0.588559 loss)
I1130 17:11:12.218827 28372 sgd_solver.cpp:106] Iteration 10600, lr = 1e-05
I1130 17:11:18.428814 28372 solver.cpp:228] Iteration 10650, loss = 0.604941
I1130 17:11:18.428879 28372 solver.cpp:244]     Train net output #0: loss = 0.604941 (* 1 = 0.604941 loss)
I1130 17:11:18.428886 28372 sgd_solver.cpp:106] Iteration 10650, lr = 1e-05
I1130 17:11:23.878463 28372 solver.cpp:228] Iteration 10700, loss = 0.581758
I1130 17:11:23.878521 28372 solver.cpp:244]     Train net output #0: loss = 0.581758 (* 1 = 0.581758 loss)
I1130 17:11:23.878528 28372 sgd_solver.cpp:106] Iteration 10700, lr = 1e-05
I1130 17:11:29.583417 28372 solver.cpp:228] Iteration 10750, loss = 0.649555
I1130 17:11:30.542925 28372 solver.cpp:244]     Train net output #0: loss = 0.649555 (* 1 = 0.649555 loss)
I1130 17:11:30.542953 28372 sgd_solver.cpp:106] Iteration 10750, lr = 1e-05
I1130 17:11:35.231369 28372 solver.cpp:337] Iteration 10800, Testing net (#0)
I1130 17:11:44.602854 28372 solver.cpp:404]     Test net output #0: accuracy = 0.642253
I1130 17:11:44.602910 28372 solver.cpp:404]     Test net output #1: loss = 0.624461 (* 1 = 0.624461 loss)
I1130 17:11:44.632860 28372 solver.cpp:228] Iteration 10800, loss = 0.573032
I1130 17:11:44.632906 28372 solver.cpp:244]     Train net output #0: loss = 0.573032 (* 1 = 0.573032 loss)
I1130 17:11:44.632917 28372 sgd_solver.cpp:106] Iteration 10800, lr = 1e-05
I1130 17:11:49.177096 28372 solver.cpp:228] Iteration 10850, loss = 0.576787
I1130 17:11:49.177147 28372 solver.cpp:244]     Train net output #0: loss = 0.576787 (* 1 = 0.576787 loss)
I1130 17:11:49.177155 28372 sgd_solver.cpp:106] Iteration 10850, lr = 1e-05
I1130 17:11:54.122078 28372 solver.cpp:228] Iteration 10900, loss = 0.567401
I1130 17:11:54.122135 28372 solver.cpp:244]     Train net output #0: loss = 0.567401 (* 1 = 0.567401 loss)
I1130 17:11:54.122145 28372 sgd_solver.cpp:106] Iteration 10900, lr = 1e-05
I1130 17:11:59.666920 28372 solver.cpp:228] Iteration 10950, loss = 0.627982
I1130 17:12:02.542960 28372 solver.cpp:244]     Train net output #0: loss = 0.627982 (* 1 = 0.627982 loss)
I1130 17:12:02.542989 28372 sgd_solver.cpp:106] Iteration 10950, lr = 1e-05
I1130 17:12:06.273494 28372 solver.cpp:337] Iteration 11000, Testing net (#0)
I1130 17:12:13.617689 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641276
I1130 17:12:13.617739 28372 solver.cpp:404]     Test net output #1: loss = 0.624153 (* 1 = 0.624153 loss)
I1130 17:12:13.648058 28372 solver.cpp:228] Iteration 11000, loss = 0.552143
I1130 17:12:13.648118 28372 solver.cpp:244]     Train net output #0: loss = 0.552143 (* 1 = 0.552143 loss)
I1130 17:12:13.648128 28372 sgd_solver.cpp:106] Iteration 11000, lr = 1e-05
I1130 17:12:19.093305 28372 solver.cpp:228] Iteration 11050, loss = 0.623456
I1130 17:12:19.093369 28372 solver.cpp:244]     Train net output #0: loss = 0.623456 (* 1 = 0.623456 loss)
I1130 17:12:19.093376 28372 sgd_solver.cpp:106] Iteration 11050, lr = 1e-05
I1130 17:12:24.135711 28372 solver.cpp:228] Iteration 11100, loss = 0.662877
I1130 17:12:24.135771 28372 solver.cpp:244]     Train net output #0: loss = 0.662877 (* 1 = 0.662877 loss)
I1130 17:12:24.135779 28372 sgd_solver.cpp:106] Iteration 11100, lr = 1e-05
I1130 17:12:30.090749 28372 solver.cpp:228] Iteration 11150, loss = 0.67505
I1130 17:12:30.090997 28372 solver.cpp:244]     Train net output #0: loss = 0.67505 (* 1 = 0.67505 loss)
I1130 17:12:30.091022 28372 sgd_solver.cpp:106] Iteration 11150, lr = 1e-05
I1130 17:12:35.069073 28372 solver.cpp:337] Iteration 11200, Testing net (#0)
I1130 17:12:44.836827 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641081
I1130 17:12:44.836880 28372 solver.cpp:404]     Test net output #1: loss = 0.624922 (* 1 = 0.624922 loss)
I1130 17:12:44.876574 28372 solver.cpp:228] Iteration 11200, loss = 0.525561
I1130 17:12:44.876623 28372 solver.cpp:244]     Train net output #0: loss = 0.525561 (* 1 = 0.525561 loss)
I1130 17:12:44.876633 28372 sgd_solver.cpp:106] Iteration 11200, lr = 1e-05
I1130 17:12:51.091159 28372 solver.cpp:228] Iteration 11250, loss = 0.549182
I1130 17:12:51.091217 28372 solver.cpp:244]     Train net output #0: loss = 0.549182 (* 1 = 0.549182 loss)
I1130 17:12:51.091226 28372 sgd_solver.cpp:106] Iteration 11250, lr = 1e-05
I1130 17:12:56.590991 28372 solver.cpp:228] Iteration 11300, loss = 0.568873
I1130 17:12:56.591053 28372 solver.cpp:244]     Train net output #0: loss = 0.568873 (* 1 = 0.568873 loss)
I1130 17:12:56.591061 28372 sgd_solver.cpp:106] Iteration 11300, lr = 1e-05
I1130 17:13:02.479171 28372 solver.cpp:228] Iteration 11350, loss = 0.582139
I1130 17:13:02.542927 28372 solver.cpp:244]     Train net output #0: loss = 0.582139 (* 1 = 0.582139 loss)
I1130 17:13:02.542958 28372 sgd_solver.cpp:106] Iteration 11350, lr = 1e-05
I1130 17:13:07.787209 28372 solver.cpp:337] Iteration 11400, Testing net (#0)
I1130 17:13:17.495482 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641406
I1130 17:13:17.495528 28372 solver.cpp:404]     Test net output #1: loss = 0.624454 (* 1 = 0.624454 loss)
I1130 17:13:17.546319 28372 solver.cpp:228] Iteration 11400, loss = 0.621765
I1130 17:13:17.546361 28372 solver.cpp:244]     Train net output #0: loss = 0.621765 (* 1 = 0.621765 loss)
I1130 17:13:17.546372 28372 sgd_solver.cpp:106] Iteration 11400, lr = 1e-05
I1130 17:13:22.810787 28372 solver.cpp:228] Iteration 11450, loss = 0.622257
I1130 17:13:22.810845 28372 solver.cpp:244]     Train net output #0: loss = 0.622257 (* 1 = 0.622257 loss)
I1130 17:13:22.810863 28372 sgd_solver.cpp:106] Iteration 11450, lr = 1e-05
I1130 17:13:27.548054 28372 solver.cpp:228] Iteration 11500, loss = 0.629484
I1130 17:13:27.548117 28372 solver.cpp:244]     Train net output #0: loss = 0.629484 (* 1 = 0.629484 loss)
I1130 17:13:27.548126 28372 sgd_solver.cpp:106] Iteration 11500, lr = 1e-05
I1130 17:13:33.198989 28372 solver.cpp:228] Iteration 11550, loss = 0.623746
I1130 17:13:34.542814 28372 solver.cpp:244]     Train net output #0: loss = 0.623746 (* 1 = 0.623746 loss)
I1130 17:13:34.542848 28372 sgd_solver.cpp:106] Iteration 11550, lr = 1e-05
I1130 17:13:38.256875 28372 solver.cpp:337] Iteration 11600, Testing net (#0)
I1130 17:13:41.820780 28372 blocking_queue.cpp:50] Data layer prefetch queue empty
I1130 17:13:45.778147 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641862
I1130 17:13:45.778209 28372 solver.cpp:404]     Test net output #1: loss = 0.624326 (* 1 = 0.624326 loss)
I1130 17:13:45.804847 28372 solver.cpp:228] Iteration 11600, loss = 0.568184
I1130 17:13:45.804884 28372 solver.cpp:244]     Train net output #0: loss = 0.568184 (* 1 = 0.568184 loss)
I1130 17:13:45.804895 28372 sgd_solver.cpp:106] Iteration 11600, lr = 1e-05
I1130 17:13:50.750174 28372 solver.cpp:228] Iteration 11650, loss = 0.701988
I1130 17:13:50.750257 28372 solver.cpp:244]     Train net output #0: loss = 0.701988 (* 1 = 0.701988 loss)
I1130 17:13:50.750277 28372 sgd_solver.cpp:106] Iteration 11650, lr = 1e-05
I1130 17:13:54.817893 28372 solver.cpp:228] Iteration 11700, loss = 0.624265
I1130 17:13:54.817952 28372 solver.cpp:244]     Train net output #0: loss = 0.624265 (* 1 = 0.624265 loss)
I1130 17:13:54.817958 28372 sgd_solver.cpp:106] Iteration 11700, lr = 1e-05
I1130 17:14:00.182629 28372 solver.cpp:228] Iteration 11750, loss = 0.625091
I1130 17:14:00.182679 28372 solver.cpp:244]     Train net output #0: loss = 0.625091 (* 1 = 0.625091 loss)
I1130 17:14:00.182687 28372 sgd_solver.cpp:106] Iteration 11750, lr = 1e-05
I1130 17:14:04.977932 28372 solver.cpp:337] Iteration 11800, Testing net (#0)
I1130 17:14:14.165607 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641471
I1130 17:14:14.165668 28372 solver.cpp:404]     Test net output #1: loss = 0.624606 (* 1 = 0.624606 loss)
I1130 17:14:14.191505 28372 solver.cpp:228] Iteration 11800, loss = 0.689489
I1130 17:14:14.191550 28372 solver.cpp:244]     Train net output #0: loss = 0.689489 (* 1 = 0.689489 loss)
I1130 17:14:14.191561 28372 sgd_solver.cpp:106] Iteration 11800, lr = 1e-05
I1130 17:14:19.618096 28372 solver.cpp:228] Iteration 11850, loss = 0.658238
I1130 17:14:19.618146 28372 solver.cpp:244]     Train net output #0: loss = 0.658238 (* 1 = 0.658238 loss)
I1130 17:14:19.618155 28372 sgd_solver.cpp:106] Iteration 11850, lr = 1e-05
I1130 17:14:25.003500 28372 solver.cpp:228] Iteration 11900, loss = 0.6344
I1130 17:14:25.003577 28372 solver.cpp:244]     Train net output #0: loss = 0.6344 (* 1 = 0.6344 loss)
I1130 17:14:25.003585 28372 sgd_solver.cpp:106] Iteration 11900, lr = 1e-05
I1130 17:14:29.109136 28372 solver.cpp:228] Iteration 11950, loss = 0.616666
I1130 17:14:29.109194 28372 solver.cpp:244]     Train net output #0: loss = 0.616666 (* 1 = 0.616666 loss)
I1130 17:14:29.109201 28372 sgd_solver.cpp:106] Iteration 11950, lr = 1e-05
I1130 17:14:34.162828 28372 solver.cpp:337] Iteration 12000, Testing net (#0)
I1130 17:14:42.862989 28372 solver.cpp:404]     Test net output #0: accuracy = 0.64056
I1130 17:14:42.863204 28372 solver.cpp:404]     Test net output #1: loss = 0.624216 (* 1 = 0.624216 loss)
I1130 17:14:42.914153 28372 solver.cpp:228] Iteration 12000, loss = 0.60746
I1130 17:14:42.914196 28372 solver.cpp:244]     Train net output #0: loss = 0.60746 (* 1 = 0.60746 loss)
I1130 17:14:42.914206 28372 sgd_solver.cpp:106] Iteration 12000, lr = 1e-05
I1130 17:14:47.988884 28372 solver.cpp:228] Iteration 12050, loss = 0.624132
I1130 17:14:47.988936 28372 solver.cpp:244]     Train net output #0: loss = 0.624132 (* 1 = 0.624132 loss)
I1130 17:14:47.988943 28372 sgd_solver.cpp:106] Iteration 12050, lr = 1e-05
I1130 17:14:52.790014 28372 solver.cpp:228] Iteration 12100, loss = 0.609401
I1130 17:14:52.790066 28372 solver.cpp:244]     Train net output #0: loss = 0.609401 (* 1 = 0.609401 loss)
I1130 17:14:52.790073 28372 sgd_solver.cpp:106] Iteration 12100, lr = 1e-05
I1130 17:14:58.887614 28372 solver.cpp:228] Iteration 12150, loss = 0.544288
I1130 17:14:58.887670 28372 solver.cpp:244]     Train net output #0: loss = 0.544288 (* 1 = 0.544288 loss)
I1130 17:14:58.887677 28372 sgd_solver.cpp:106] Iteration 12150, lr = 1e-05
I1130 17:15:04.168570 28372 solver.cpp:337] Iteration 12200, Testing net (#0)
I1130 17:15:14.043036 28372 solver.cpp:404]     Test net output #0: accuracy = 0.640104
I1130 17:15:14.075103 28372 solver.cpp:404]     Test net output #1: loss = 0.624523 (* 1 = 0.624523 loss)
I1130 17:15:14.103526 28372 solver.cpp:228] Iteration 12200, loss = 0.639071
I1130 17:15:14.103585 28372 solver.cpp:244]     Train net output #0: loss = 0.639071 (* 1 = 0.639071 loss)
I1130 17:15:14.103601 28372 sgd_solver.cpp:106] Iteration 12200, lr = 1e-05
I1130 17:15:19.654050 28372 solver.cpp:228] Iteration 12250, loss = 0.55968
I1130 17:15:19.654110 28372 solver.cpp:244]     Train net output #0: loss = 0.55968 (* 1 = 0.55968 loss)
I1130 17:15:19.654119 28372 sgd_solver.cpp:106] Iteration 12250, lr = 1e-05
I1130 17:15:23.922013 28372 solver.cpp:228] Iteration 12300, loss = 0.627206
I1130 17:15:23.922072 28372 solver.cpp:244]     Train net output #0: loss = 0.627206 (* 1 = 0.627206 loss)
I1130 17:15:23.922080 28372 sgd_solver.cpp:106] Iteration 12300, lr = 1e-05
I1130 17:15:28.664644 28372 solver.cpp:228] Iteration 12350, loss = 0.57902
I1130 17:15:28.664701 28372 solver.cpp:244]     Train net output #0: loss = 0.57902 (* 1 = 0.57902 loss)
I1130 17:15:28.664706 28372 sgd_solver.cpp:106] Iteration 12350, lr = 1e-05
I1130 17:15:33.233180 28372 solver.cpp:337] Iteration 12400, Testing net (#0)
I1130 17:15:40.800447 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641732
I1130 17:15:40.800500 28372 solver.cpp:404]     Test net output #1: loss = 0.624407 (* 1 = 0.624407 loss)
I1130 17:15:40.831100 28372 solver.cpp:228] Iteration 12400, loss = 0.605455
I1130 17:15:40.831166 28372 solver.cpp:244]     Train net output #0: loss = 0.605455 (* 1 = 0.605455 loss)
I1130 17:15:40.831176 28372 sgd_solver.cpp:106] Iteration 12400, lr = 1e-05
I1130 17:15:46.230384 28372 solver.cpp:228] Iteration 12450, loss = 0.609692
I1130 17:15:46.238375 28372 solver.cpp:244]     Train net output #0: loss = 0.609692 (* 1 = 0.609692 loss)
I1130 17:15:46.238416 28372 sgd_solver.cpp:106] Iteration 12450, lr = 1e-05
I1130 17:15:50.259124 28372 solver.cpp:228] Iteration 12500, loss = 0.653373
I1130 17:15:50.259181 28372 solver.cpp:244]     Train net output #0: loss = 0.653373 (* 1 = 0.653373 loss)
I1130 17:15:50.259191 28372 sgd_solver.cpp:106] Iteration 12500, lr = 1e-05
I1130 17:15:54.275099 28372 solver.cpp:228] Iteration 12550, loss = 0.573825
I1130 17:15:54.275143 28372 solver.cpp:244]     Train net output #0: loss = 0.573825 (* 1 = 0.573825 loss)
I1130 17:15:54.275149 28372 sgd_solver.cpp:106] Iteration 12550, lr = 1e-05
I1130 17:15:58.222182 28372 solver.cpp:337] Iteration 12600, Testing net (#0)
I1130 17:16:06.250151 28372 blocking_queue.cpp:50] Data layer prefetch queue empty
I1130 17:16:07.497572 28372 solver.cpp:404]     Test net output #0: accuracy = 0.639388
I1130 17:16:07.497623 28372 solver.cpp:404]     Test net output #1: loss = 0.624849 (* 1 = 0.624849 loss)
I1130 17:16:07.544903 28372 solver.cpp:228] Iteration 12600, loss = 0.578199
I1130 17:16:07.544950 28372 solver.cpp:244]     Train net output #0: loss = 0.578199 (* 1 = 0.578199 loss)
I1130 17:16:07.544961 28372 sgd_solver.cpp:106] Iteration 12600, lr = 1e-05
I1130 17:16:13.347555 28372 solver.cpp:228] Iteration 12650, loss = 0.516271
I1130 17:16:13.347617 28372 solver.cpp:244]     Train net output #0: loss = 0.516271 (* 1 = 0.516271 loss)
I1130 17:16:13.347625 28372 sgd_solver.cpp:106] Iteration 12650, lr = 1e-05
I1130 17:16:17.751974 28372 solver.cpp:228] Iteration 12700, loss = 0.676618
I1130 17:16:18.354521 28372 solver.cpp:244]     Train net output #0: loss = 0.676618 (* 1 = 0.676618 loss)
I1130 17:16:18.354552 28372 sgd_solver.cpp:106] Iteration 12700, lr = 1e-05
I1130 17:16:23.067517 28372 solver.cpp:228] Iteration 12750, loss = 0.605624
I1130 17:16:23.067567 28372 solver.cpp:244]     Train net output #0: loss = 0.605624 (* 1 = 0.605624 loss)
I1130 17:16:23.067575 28372 sgd_solver.cpp:106] Iteration 12750, lr = 1e-05
I1130 17:16:28.437535 28372 solver.cpp:337] Iteration 12800, Testing net (#0)
I1130 17:16:37.629634 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641471
I1130 17:16:37.629693 28372 solver.cpp:404]     Test net output #1: loss = 0.624519 (* 1 = 0.624519 loss)
I1130 17:16:37.655995 28372 solver.cpp:228] Iteration 12800, loss = 0.599883
I1130 17:16:37.656056 28372 solver.cpp:244]     Train net output #0: loss = 0.599883 (* 1 = 0.599883 loss)
I1130 17:16:37.656069 28372 sgd_solver.cpp:106] Iteration 12800, lr = 1e-05
I1130 17:16:43.000536 28372 solver.cpp:228] Iteration 12850, loss = 0.637105
I1130 17:16:43.000588 28372 solver.cpp:244]     Train net output #0: loss = 0.637105 (* 1 = 0.637105 loss)
I1130 17:16:43.000597 28372 sgd_solver.cpp:106] Iteration 12850, lr = 1e-05
I1130 17:16:48.894902 28372 solver.cpp:228] Iteration 12900, loss = 0.586283
I1130 17:16:48.895176 28372 solver.cpp:244]     Train net output #0: loss = 0.586283 (* 1 = 0.586283 loss)
I1130 17:16:48.895203 28372 sgd_solver.cpp:106] Iteration 12900, lr = 1e-05
I1130 17:16:53.215720 28372 solver.cpp:228] Iteration 12950, loss = 0.554112
I1130 17:16:53.215783 28372 solver.cpp:244]     Train net output #0: loss = 0.554112 (* 1 = 0.554112 loss)
I1130 17:16:53.215790 28372 sgd_solver.cpp:106] Iteration 12950, lr = 1e-05
I1130 17:16:57.184548 28372 solver.cpp:337] Iteration 13000, Testing net (#0)
I1130 17:17:05.179594 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641602
I1130 17:17:05.179646 28372 solver.cpp:404]     Test net output #1: loss = 0.624192 (* 1 = 0.624192 loss)
I1130 17:17:05.210343 28372 solver.cpp:228] Iteration 13000, loss = 0.572289
I1130 17:17:05.210391 28372 solver.cpp:244]     Train net output #0: loss = 0.572289 (* 1 = 0.572289 loss)
I1130 17:17:05.210400 28372 sgd_solver.cpp:106] Iteration 13000, lr = 1e-05
I1130 17:17:09.120930 28372 solver.cpp:228] Iteration 13050, loss = 0.611199
I1130 17:17:09.121002 28372 solver.cpp:244]     Train net output #0: loss = 0.611199 (* 1 = 0.611199 loss)
I1130 17:17:09.121011 28372 sgd_solver.cpp:106] Iteration 13050, lr = 1e-05
I1130 17:17:13.078187 28372 solver.cpp:228] Iteration 13100, loss = 0.598167
I1130 17:17:13.078260 28372 solver.cpp:244]     Train net output #0: loss = 0.598167 (* 1 = 0.598167 loss)
I1130 17:17:13.078270 28372 sgd_solver.cpp:106] Iteration 13100, lr = 1e-05
I1130 17:17:17.095083 28372 solver.cpp:228] Iteration 13150, loss = 0.616608
I1130 17:17:17.095127 28372 solver.cpp:244]     Train net output #0: loss = 0.616608 (* 1 = 0.616608 loss)
I1130 17:17:17.095131 28372 sgd_solver.cpp:106] Iteration 13150, lr = 1e-05
I1130 17:17:21.072124 28372 solver.cpp:337] Iteration 13200, Testing net (#0)
I1130 17:17:29.663902 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641471
I1130 17:17:29.663967 28372 solver.cpp:404]     Test net output #1: loss = 0.624635 (* 1 = 0.624635 loss)
I1130 17:17:29.694016 28372 solver.cpp:228] Iteration 13200, loss = 0.607627
I1130 17:17:29.694072 28372 solver.cpp:244]     Train net output #0: loss = 0.607627 (* 1 = 0.607627 loss)
I1130 17:17:29.694082 28372 sgd_solver.cpp:106] Iteration 13200, lr = 1e-05
I1130 17:17:34.527974 28372 solver.cpp:228] Iteration 13250, loss = 0.601646
I1130 17:17:34.528041 28372 solver.cpp:244]     Train net output #0: loss = 0.601646 (* 1 = 0.601646 loss)
I1130 17:17:34.528049 28372 sgd_solver.cpp:106] Iteration 13250, lr = 1e-05
I1130 17:17:38.538794 28372 solver.cpp:228] Iteration 13300, loss = 0.578217
I1130 17:17:38.538851 28372 solver.cpp:244]     Train net output #0: loss = 0.578217 (* 1 = 0.578217 loss)
I1130 17:17:38.538857 28372 sgd_solver.cpp:106] Iteration 13300, lr = 1e-05
I1130 17:17:42.601366 28372 solver.cpp:228] Iteration 13350, loss = 0.54725
I1130 17:17:42.601433 28372 solver.cpp:244]     Train net output #0: loss = 0.54725 (* 1 = 0.54725 loss)
I1130 17:17:42.601441 28372 sgd_solver.cpp:106] Iteration 13350, lr = 1e-05
I1130 17:17:47.976485 28372 solver.cpp:337] Iteration 13400, Testing net (#0)
I1130 17:17:56.126083 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641602
I1130 17:17:56.366720 28372 solver.cpp:404]     Test net output #1: loss = 0.624024 (* 1 = 0.624024 loss)
I1130 17:17:56.411823 28372 solver.cpp:228] Iteration 13400, loss = 0.58716
I1130 17:17:56.411895 28372 solver.cpp:244]     Train net output #0: loss = 0.58716 (* 1 = 0.58716 loss)
I1130 17:17:56.411913 28372 sgd_solver.cpp:106] Iteration 13400, lr = 1e-05
I1130 17:18:01.378446 28372 solver.cpp:228] Iteration 13450, loss = 0.591546
I1130 17:18:01.378494 28372 solver.cpp:244]     Train net output #0: loss = 0.591546 (* 1 = 0.591546 loss)
I1130 17:18:01.378501 28372 sgd_solver.cpp:106] Iteration 13450, lr = 1e-05
I1130 17:18:06.784791 28372 solver.cpp:228] Iteration 13500, loss = 0.615677
I1130 17:18:06.784858 28372 solver.cpp:244]     Train net output #0: loss = 0.615677 (* 1 = 0.615677 loss)
I1130 17:18:06.784867 28372 sgd_solver.cpp:106] Iteration 13500, lr = 1e-05
I1130 17:18:10.857435 28372 solver.cpp:228] Iteration 13550, loss = 0.563691
I1130 17:18:10.857491 28372 solver.cpp:244]     Train net output #0: loss = 0.563691 (* 1 = 0.563691 loss)
I1130 17:18:10.857501 28372 sgd_solver.cpp:106] Iteration 13550, lr = 1e-05
I1130 17:18:16.306305 28372 solver.cpp:337] Iteration 13600, Testing net (#0)
I1130 17:18:25.582293 28372 solver.cpp:404]     Test net output #0: accuracy = 0.642122
I1130 17:18:25.582352 28372 solver.cpp:404]     Test net output #1: loss = 0.624105 (* 1 = 0.624105 loss)
I1130 17:18:25.627665 28372 solver.cpp:228] Iteration 13600, loss = 0.570854
I1130 17:18:25.627710 28372 solver.cpp:244]     Train net output #0: loss = 0.570854 (* 1 = 0.570854 loss)
I1130 17:18:25.627720 28372 sgd_solver.cpp:106] Iteration 13600, lr = 1e-05
I1130 17:18:30.990056 28372 solver.cpp:228] Iteration 13650, loss = 0.624803
I1130 17:18:30.990324 28372 solver.cpp:244]     Train net output #0: loss = 0.624803 (* 1 = 0.624803 loss)
I1130 17:18:30.990350 28372 sgd_solver.cpp:106] Iteration 13650, lr = 1e-05
I1130 17:18:34.902034 28372 solver.cpp:228] Iteration 13700, loss = 0.588463
I1130 17:18:34.902081 28372 solver.cpp:244]     Train net output #0: loss = 0.588463 (* 1 = 0.588463 loss)
I1130 17:18:34.902091 28372 sgd_solver.cpp:106] Iteration 13700, lr = 1e-05
I1130 17:18:38.935650 28372 solver.cpp:228] Iteration 13750, loss = 0.560909
I1130 17:18:38.935710 28372 solver.cpp:244]     Train net output #0: loss = 0.560909 (* 1 = 0.560909 loss)
I1130 17:18:38.935719 28372 sgd_solver.cpp:106] Iteration 13750, lr = 1e-05
I1130 17:18:43.139670 28372 solver.cpp:337] Iteration 13800, Testing net (#0)
I1130 17:18:45.344220 28372 blocking_queue.cpp:50] Data layer prefetch queue empty
I1130 17:18:51.511229 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641667
I1130 17:18:51.511288 28372 solver.cpp:404]     Test net output #1: loss = 0.623247 (* 1 = 0.623247 loss)
I1130 17:18:51.541302 28372 solver.cpp:228] Iteration 13800, loss = 0.629065
I1130 17:18:51.541348 28372 solver.cpp:244]     Train net output #0: loss = 0.629065 (* 1 = 0.629065 loss)
I1130 17:18:51.541359 28372 sgd_solver.cpp:106] Iteration 13800, lr = 1e-05
I1130 17:18:56.674136 28372 solver.cpp:228] Iteration 13850, loss = 0.670579
I1130 17:18:56.674180 28372 solver.cpp:244]     Train net output #0: loss = 0.670579 (* 1 = 0.670579 loss)
I1130 17:18:56.674188 28372 sgd_solver.cpp:106] Iteration 13850, lr = 1e-05
I1130 17:19:01.574826 28372 solver.cpp:228] Iteration 13900, loss = 0.678517
I1130 17:19:01.604481 28372 solver.cpp:244]     Train net output #0: loss = 0.678517 (* 1 = 0.678517 loss)
I1130 17:19:01.604504 28372 sgd_solver.cpp:106] Iteration 13900, lr = 1e-05
I1130 17:19:06.991044 28372 solver.cpp:228] Iteration 13950, loss = 0.633267
I1130 17:19:06.991101 28372 solver.cpp:244]     Train net output #0: loss = 0.633267 (* 1 = 0.633267 loss)
I1130 17:19:06.991118 28372 sgd_solver.cpp:106] Iteration 13950, lr = 1e-05
I1130 17:19:12.551421 28372 solver.cpp:337] Iteration 14000, Testing net (#0)
I1130 17:19:22.441943 28372 solver.cpp:404]     Test net output #0: accuracy = 0.642904
I1130 17:19:22.442006 28372 solver.cpp:404]     Test net output #1: loss = 0.623532 (* 1 = 0.623532 loss)
I1130 17:19:22.470957 28372 solver.cpp:228] Iteration 14000, loss = 0.629902
I1130 17:19:22.471019 28372 solver.cpp:244]     Train net output #0: loss = 0.629902 (* 1 = 0.629902 loss)
I1130 17:19:22.471029 28372 sgd_solver.cpp:106] Iteration 14000, lr = 1e-05
I1130 17:19:27.720314 28372 solver.cpp:228] Iteration 14050, loss = 0.609798
I1130 17:19:27.720374 28372 solver.cpp:244]     Train net output #0: loss = 0.609798 (* 1 = 0.609798 loss)
I1130 17:19:27.720382 28372 sgd_solver.cpp:106] Iteration 14050, lr = 1e-05
I1130 17:19:33.125792 28372 solver.cpp:228] Iteration 14100, loss = 0.633611
I1130 17:19:33.126102 28372 solver.cpp:244]     Train net output #0: loss = 0.633611 (* 1 = 0.633611 loss)
I1130 17:19:33.126117 28372 sgd_solver.cpp:106] Iteration 14100, lr = 1e-05
I1130 17:19:38.508711 28372 solver.cpp:228] Iteration 14150, loss = 0.573943
I1130 17:19:38.508769 28372 solver.cpp:244]     Train net output #0: loss = 0.573943 (* 1 = 0.573943 loss)
I1130 17:19:38.508776 28372 sgd_solver.cpp:106] Iteration 14150, lr = 1e-05
I1130 17:19:43.656296 28372 solver.cpp:337] Iteration 14200, Testing net (#0)
I1130 17:19:52.244489 28372 solver.cpp:404]     Test net output #0: accuracy = 0.64056
I1130 17:19:52.244580 28372 solver.cpp:404]     Test net output #1: loss = 0.6244 (* 1 = 0.6244 loss)
I1130 17:19:52.273242 28372 solver.cpp:228] Iteration 14200, loss = 0.63055
I1130 17:19:52.273291 28372 solver.cpp:244]     Train net output #0: loss = 0.63055 (* 1 = 0.63055 loss)
I1130 17:19:52.273301 28372 sgd_solver.cpp:106] Iteration 14200, lr = 1e-05
I1130 17:19:56.974599 28372 solver.cpp:228] Iteration 14250, loss = 0.591677
I1130 17:19:56.974654 28372 solver.cpp:244]     Train net output #0: loss = 0.591677 (* 1 = 0.591677 loss)
I1130 17:19:56.974663 28372 sgd_solver.cpp:106] Iteration 14250, lr = 1e-05
I1130 17:20:01.031111 28372 solver.cpp:228] Iteration 14300, loss = 0.581811
I1130 17:20:01.031167 28372 solver.cpp:244]     Train net output #0: loss = 0.581811 (* 1 = 0.581811 loss)
I1130 17:20:01.031175 28372 sgd_solver.cpp:106] Iteration 14300, lr = 1e-05
I1130 17:20:05.899679 28372 solver.cpp:228] Iteration 14350, loss = 0.482367
I1130 17:20:06.542951 28372 solver.cpp:244]     Train net output #0: loss = 0.482367 (* 1 = 0.482367 loss)
I1130 17:20:06.542984 28372 sgd_solver.cpp:106] Iteration 14350, lr = 1e-05
I1130 17:20:11.542623 28372 solver.cpp:337] Iteration 14400, Testing net (#0)
I1130 17:20:21.313130 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641211
I1130 17:20:21.313189 28372 solver.cpp:404]     Test net output #1: loss = 0.624107 (* 1 = 0.624107 loss)
I1130 17:20:21.359736 28372 solver.cpp:228] Iteration 14400, loss = 0.615862
I1130 17:20:21.359797 28372 solver.cpp:244]     Train net output #0: loss = 0.615862 (* 1 = 0.615862 loss)
I1130 17:20:21.359808 28372 sgd_solver.cpp:106] Iteration 14400, lr = 1e-05
I1130 17:20:26.745815 28372 solver.cpp:228] Iteration 14450, loss = 0.610953
I1130 17:20:26.745867 28372 solver.cpp:244]     Train net output #0: loss = 0.610953 (* 1 = 0.610953 loss)
I1130 17:20:26.745875 28372 sgd_solver.cpp:106] Iteration 14450, lr = 1e-05
I1130 17:20:30.714665 28372 solver.cpp:228] Iteration 14500, loss = 0.571351
I1130 17:20:30.714728 28372 solver.cpp:244]     Train net output #0: loss = 0.571351 (* 1 = 0.571351 loss)
I1130 17:20:30.714735 28372 sgd_solver.cpp:106] Iteration 14500, lr = 1e-05
I1130 17:20:36.200851 28372 solver.cpp:228] Iteration 14550, loss = 0.525946
I1130 17:20:38.542968 28372 solver.cpp:244]     Train net output #0: loss = 0.525946 (* 1 = 0.525946 loss)
I1130 17:20:38.542997 28372 sgd_solver.cpp:106] Iteration 14550, lr = 1e-05
I1130 17:20:42.990998 28372 solver.cpp:337] Iteration 14600, Testing net (#0)
I1130 17:20:52.607836 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641602
I1130 17:20:52.607903 28372 solver.cpp:404]     Test net output #1: loss = 0.623847 (* 1 = 0.623847 loss)
I1130 17:20:52.653030 28372 solver.cpp:228] Iteration 14600, loss = 0.526567
I1130 17:20:52.653081 28372 solver.cpp:244]     Train net output #0: loss = 0.526567 (* 1 = 0.526567 loss)
I1130 17:20:52.653092 28372 sgd_solver.cpp:106] Iteration 14600, lr = 1e-05
I1130 17:20:57.949497 28372 solver.cpp:228] Iteration 14650, loss = 0.53372
I1130 17:20:57.949545 28372 solver.cpp:244]     Train net output #0: loss = 0.53372 (* 1 = 0.53372 loss)
I1130 17:20:57.949554 28372 sgd_solver.cpp:106] Iteration 14650, lr = 1e-05
I1130 17:21:03.111594 28372 solver.cpp:228] Iteration 14700, loss = 0.603625
I1130 17:21:03.111654 28372 solver.cpp:244]     Train net output #0: loss = 0.603625 (* 1 = 0.603625 loss)
I1130 17:21:03.111660 28372 sgd_solver.cpp:106] Iteration 14700, lr = 1e-05
I1130 17:21:07.486367 28372 solver.cpp:228] Iteration 14750, loss = 0.595148
I1130 17:21:08.670581 28372 solver.cpp:244]     Train net output #0: loss = 0.595148 (* 1 = 0.595148 loss)
I1130 17:21:08.670619 28372 sgd_solver.cpp:106] Iteration 14750, lr = 1e-05
I1130 17:21:13.609304 28372 solver.cpp:337] Iteration 14800, Testing net (#0)
I1130 17:21:22.597874 28372 solver.cpp:404]     Test net output #0: accuracy = 0.639063
I1130 17:21:22.597941 28372 solver.cpp:404]     Test net output #1: loss = 0.624554 (* 1 = 0.624554 loss)
I1130 17:21:22.639408 28372 solver.cpp:228] Iteration 14800, loss = 0.619112
I1130 17:21:22.639468 28372 solver.cpp:244]     Train net output #0: loss = 0.619112 (* 1 = 0.619112 loss)
I1130 17:21:22.639480 28372 sgd_solver.cpp:106] Iteration 14800, lr = 1e-05
I1130 17:21:26.550740 28372 solver.cpp:228] Iteration 14850, loss = 0.635287
I1130 17:21:26.550799 28372 solver.cpp:244]     Train net output #0: loss = 0.635287 (* 1 = 0.635287 loss)
I1130 17:21:26.550809 28372 sgd_solver.cpp:106] Iteration 14850, lr = 1e-05
I1130 17:21:30.621780 28372 solver.cpp:228] Iteration 14900, loss = 0.637772
I1130 17:21:30.621835 28372 solver.cpp:244]     Train net output #0: loss = 0.637772 (* 1 = 0.637772 loss)
I1130 17:21:30.621843 28372 sgd_solver.cpp:106] Iteration 14900, lr = 1e-05
I1130 17:21:35.917098 28372 solver.cpp:228] Iteration 14950, loss = 0.601113
I1130 17:21:35.917155 28372 solver.cpp:244]     Train net output #0: loss = 0.601113 (* 1 = 0.601113 loss)
I1130 17:21:35.917162 28372 sgd_solver.cpp:106] Iteration 14950, lr = 1e-05
I1130 17:21:41.214504 28372 solver.cpp:337] Iteration 15000, Testing net (#0)
I1130 17:21:46.145284 28372 blocking_queue.cpp:50] Data layer prefetch queue empty
I1130 17:21:49.061288 28372 solver.cpp:404]     Test net output #0: accuracy = 0.642187
I1130 17:21:49.061357 28372 solver.cpp:404]     Test net output #1: loss = 0.623479 (* 1 = 0.623479 loss)
I1130 17:21:49.091300 28372 solver.cpp:228] Iteration 15000, loss = 0.626221
I1130 17:21:49.091343 28372 solver.cpp:244]     Train net output #0: loss = 0.626221 (* 1 = 0.626221 loss)
I1130 17:21:49.091356 28372 sgd_solver.cpp:106] Iteration 15000, lr = 1e-06
I1130 17:21:54.057155 28372 solver.cpp:228] Iteration 15050, loss = 0.568508
I1130 17:21:54.057209 28372 solver.cpp:244]     Train net output #0: loss = 0.568508 (* 1 = 0.568508 loss)
I1130 17:21:54.057219 28372 sgd_solver.cpp:106] Iteration 15050, lr = 1e-06
I1130 17:21:59.963224 28372 solver.cpp:228] Iteration 15100, loss = 0.750579
I1130 17:21:59.963277 28372 solver.cpp:244]     Train net output #0: loss = 0.750579 (* 1 = 0.750579 loss)
I1130 17:21:59.963286 28372 sgd_solver.cpp:106] Iteration 15100, lr = 1e-06
I1130 17:22:04.867604 28372 solver.cpp:228] Iteration 15150, loss = 0.588447
I1130 17:22:04.867660 28372 solver.cpp:244]     Train net output #0: loss = 0.588447 (* 1 = 0.588447 loss)
I1130 17:22:04.867678 28372 sgd_solver.cpp:106] Iteration 15150, lr = 1e-06
I1130 17:22:10.056358 28372 solver.cpp:337] Iteration 15200, Testing net (#0)
I1130 17:22:19.095082 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641862
I1130 17:22:22.542960 28372 solver.cpp:404]     Test net output #1: loss = 0.623258 (* 1 = 0.623258 loss)
I1130 17:22:22.587103 28372 solver.cpp:228] Iteration 15200, loss = 0.637402
I1130 17:22:22.587168 28372 solver.cpp:244]     Train net output #0: loss = 0.637402 (* 1 = 0.637402 loss)
I1130 17:22:22.587188 28372 sgd_solver.cpp:106] Iteration 15200, lr = 1e-06
I1130 17:22:26.364325 28372 solver.cpp:228] Iteration 15250, loss = 0.53429
I1130 17:22:26.364384 28372 solver.cpp:244]     Train net output #0: loss = 0.53429 (* 1 = 0.53429 loss)
I1130 17:22:26.364392 28372 sgd_solver.cpp:106] Iteration 15250, lr = 1e-06
I1130 17:22:31.444061 28372 solver.cpp:228] Iteration 15300, loss = 0.575402
I1130 17:22:31.444164 28372 solver.cpp:244]     Train net output #0: loss = 0.575402 (* 1 = 0.575402 loss)
I1130 17:22:31.444171 28372 sgd_solver.cpp:106] Iteration 15300, lr = 1e-06
I1130 17:22:37.233335 28372 solver.cpp:228] Iteration 15350, loss = 0.538855
I1130 17:22:37.233395 28372 solver.cpp:244]     Train net output #0: loss = 0.538855 (* 1 = 0.538855 loss)
I1130 17:22:37.233403 28372 sgd_solver.cpp:106] Iteration 15350, lr = 1e-06
I1130 17:22:42.071813 28372 solver.cpp:337] Iteration 15400, Testing net (#0)
I1130 17:22:52.142931 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641016
I1130 17:22:52.339401 28372 solver.cpp:404]     Test net output #1: loss = 0.623902 (* 1 = 0.623902 loss)
I1130 17:22:52.378639 28372 solver.cpp:228] Iteration 15400, loss = 0.551667
I1130 17:22:52.378716 28372 solver.cpp:244]     Train net output #0: loss = 0.551667 (* 1 = 0.551667 loss)
I1130 17:22:52.378736 28372 sgd_solver.cpp:106] Iteration 15400, lr = 1e-06
I1130 17:22:58.186992 28372 solver.cpp:228] Iteration 15450, loss = 0.76222
I1130 17:22:58.187041 28372 solver.cpp:244]     Train net output #0: loss = 0.76222 (* 1 = 0.76222 loss)
I1130 17:22:58.187049 28372 sgd_solver.cpp:106] Iteration 15450, lr = 1e-06
I1130 17:23:02.158887 28372 solver.cpp:228] Iteration 15500, loss = 0.614715
I1130 17:23:02.158952 28372 solver.cpp:244]     Train net output #0: loss = 0.614715 (* 1 = 0.614715 loss)
I1130 17:23:02.158967 28372 sgd_solver.cpp:106] Iteration 15500, lr = 1e-06
I1130 17:23:06.824049 28372 solver.cpp:228] Iteration 15550, loss = 0.63306
I1130 17:23:06.824105 28372 solver.cpp:244]     Train net output #0: loss = 0.63306 (* 1 = 0.63306 loss)
I1130 17:23:06.824125 28372 sgd_solver.cpp:106] Iteration 15550, lr = 1e-06
I1130 17:23:10.840955 28372 solver.cpp:337] Iteration 15600, Testing net (#0)
I1130 17:23:20.566699 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641992
I1130 17:23:20.566748 28372 solver.cpp:404]     Test net output #1: loss = 0.623288 (* 1 = 0.623288 loss)
I1130 17:23:20.596139 28372 solver.cpp:228] Iteration 15600, loss = 0.669386
I1130 17:23:20.596182 28372 solver.cpp:244]     Train net output #0: loss = 0.669386 (* 1 = 0.669386 loss)
I1130 17:23:20.596192 28372 sgd_solver.cpp:106] Iteration 15600, lr = 1e-06
I1130 17:23:25.911062 28372 solver.cpp:228] Iteration 15650, loss = 0.525744
I1130 17:23:25.911298 28372 solver.cpp:244]     Train net output #0: loss = 0.525744 (* 1 = 0.525744 loss)
I1130 17:23:25.911308 28372 sgd_solver.cpp:106] Iteration 15650, lr = 1e-06
I1130 17:23:31.106822 28372 solver.cpp:228] Iteration 15700, loss = 0.550523
I1130 17:23:31.106874 28372 solver.cpp:244]     Train net output #0: loss = 0.550523 (* 1 = 0.550523 loss)
I1130 17:23:31.106880 28372 sgd_solver.cpp:106] Iteration 15700, lr = 1e-06
I1130 17:23:36.861119 28372 solver.cpp:228] Iteration 15750, loss = 0.59014
I1130 17:23:36.861174 28372 solver.cpp:244]     Train net output #0: loss = 0.59014 (* 1 = 0.59014 loss)
I1130 17:23:36.861182 28372 sgd_solver.cpp:106] Iteration 15750, lr = 1e-06
I1130 17:23:41.210398 28372 solver.cpp:337] Iteration 15800, Testing net (#0)
I1130 17:23:49.509513 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641081
I1130 17:23:49.509573 28372 solver.cpp:404]     Test net output #1: loss = 0.623857 (* 1 = 0.623857 loss)
I1130 17:23:49.536103 28372 solver.cpp:228] Iteration 15800, loss = 0.649001
I1130 17:23:49.536152 28372 solver.cpp:244]     Train net output #0: loss = 0.649001 (* 1 = 0.649001 loss)
I1130 17:23:49.536165 28372 sgd_solver.cpp:106] Iteration 15800, lr = 1e-06
I1130 17:23:53.570246 28372 solver.cpp:228] Iteration 15850, loss = 0.612179
I1130 17:23:53.570312 28372 solver.cpp:244]     Train net output #0: loss = 0.612179 (* 1 = 0.612179 loss)
I1130 17:23:53.570320 28372 sgd_solver.cpp:106] Iteration 15850, lr = 1e-06
I1130 17:23:57.621152 28372 solver.cpp:228] Iteration 15900, loss = 0.63107
I1130 17:23:58.542943 28372 solver.cpp:244]     Train net output #0: loss = 0.63107 (* 1 = 0.63107 loss)
I1130 17:23:58.542973 28372 sgd_solver.cpp:106] Iteration 15900, lr = 1e-06
I1130 17:24:04.312711 28372 solver.cpp:228] Iteration 15950, loss = 0.579566
I1130 17:24:04.312762 28372 solver.cpp:244]     Train net output #0: loss = 0.579566 (* 1 = 0.579566 loss)
I1130 17:24:04.312770 28372 sgd_solver.cpp:106] Iteration 15950, lr = 1e-06
I1130 17:24:09.272099 28372 solver.cpp:337] Iteration 16000, Testing net (#0)
I1130 17:24:18.897775 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641732
I1130 17:24:18.897837 28372 solver.cpp:404]     Test net output #1: loss = 0.623562 (* 1 = 0.623562 loss)
I1130 17:24:18.927332 28372 solver.cpp:228] Iteration 16000, loss = 0.576976
I1130 17:24:18.927386 28372 solver.cpp:244]     Train net output #0: loss = 0.576976 (* 1 = 0.576976 loss)
I1130 17:24:18.927395 28372 sgd_solver.cpp:106] Iteration 16000, lr = 1e-06
I1130 17:24:22.948493 28372 solver.cpp:228] Iteration 16050, loss = 0.54979
I1130 17:24:22.948545 28372 solver.cpp:244]     Train net output #0: loss = 0.54979 (* 1 = 0.54979 loss)
I1130 17:24:22.948554 28372 sgd_solver.cpp:106] Iteration 16050, lr = 1e-06
I1130 17:24:28.997303 28372 solver.cpp:228] Iteration 16100, loss = 0.584473
I1130 17:24:29.081904 28372 solver.cpp:244]     Train net output #0: loss = 0.584473 (* 1 = 0.584473 loss)
I1130 17:24:29.081934 28372 sgd_solver.cpp:106] Iteration 16100, lr = 1e-06
I1130 17:24:33.585078 28372 solver.cpp:228] Iteration 16150, loss = 0.576533
I1130 17:24:33.585145 28372 solver.cpp:244]     Train net output #0: loss = 0.576533 (* 1 = 0.576533 loss)
I1130 17:24:33.585161 28372 sgd_solver.cpp:106] Iteration 16150, lr = 1e-06
I1130 17:24:38.899111 28372 solver.cpp:337] Iteration 16200, Testing net (#0)
I1130 17:24:44.985677 28372 blocking_queue.cpp:50] Data layer prefetch queue empty
I1130 17:24:46.511641 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641341
I1130 17:24:46.511700 28372 solver.cpp:404]     Test net output #1: loss = 0.623519 (* 1 = 0.623519 loss)
I1130 17:24:46.538663 28372 solver.cpp:228] Iteration 16200, loss = 0.61756
I1130 17:24:46.538709 28372 solver.cpp:244]     Train net output #0: loss = 0.61756 (* 1 = 0.61756 loss)
I1130 17:24:46.538732 28372 sgd_solver.cpp:106] Iteration 16200, lr = 1e-06
I1130 17:24:51.747356 28372 solver.cpp:228] Iteration 16250, loss = 0.637477
I1130 17:24:51.747426 28372 solver.cpp:244]     Train net output #0: loss = 0.637477 (* 1 = 0.637477 loss)
I1130 17:24:51.747434 28372 sgd_solver.cpp:106] Iteration 16250, lr = 1e-06
I1130 17:24:55.758159 28372 solver.cpp:228] Iteration 16300, loss = 0.538886
I1130 17:24:55.758218 28372 solver.cpp:244]     Train net output #0: loss = 0.538886 (* 1 = 0.538886 loss)
I1130 17:24:55.758245 28372 sgd_solver.cpp:106] Iteration 16300, lr = 1e-06
I1130 17:25:00.395257 28372 solver.cpp:228] Iteration 16350, loss = 0.590941
I1130 17:25:02.542966 28372 solver.cpp:244]     Train net output #0: loss = 0.590941 (* 1 = 0.590941 loss)
I1130 17:25:02.542999 28372 sgd_solver.cpp:106] Iteration 16350, lr = 1e-06
I1130 17:25:06.538606 28372 solver.cpp:337] Iteration 16400, Testing net (#0)
I1130 17:25:13.811419 28372 solver.cpp:404]     Test net output #0: accuracy = 0.642057
I1130 17:25:13.811491 28372 solver.cpp:404]     Test net output #1: loss = 0.623395 (* 1 = 0.623395 loss)
I1130 17:25:13.841620 28372 solver.cpp:228] Iteration 16400, loss = 0.54709
I1130 17:25:13.841678 28372 solver.cpp:244]     Train net output #0: loss = 0.54709 (* 1 = 0.54709 loss)
I1130 17:25:13.841689 28372 sgd_solver.cpp:106] Iteration 16400, lr = 1e-06
I1130 17:25:19.929642 28372 solver.cpp:228] Iteration 16450, loss = 0.602655
I1130 17:25:19.929695 28372 solver.cpp:244]     Train net output #0: loss = 0.602655 (* 1 = 0.602655 loss)
I1130 17:25:19.929704 28372 sgd_solver.cpp:106] Iteration 16450, lr = 1e-06
I1130 17:25:24.892966 28372 solver.cpp:228] Iteration 16500, loss = 0.655488
I1130 17:25:24.893024 28372 solver.cpp:244]     Train net output #0: loss = 0.655488 (* 1 = 0.655488 loss)
I1130 17:25:24.893030 28372 sgd_solver.cpp:106] Iteration 16500, lr = 1e-06
I1130 17:25:28.865747 28372 solver.cpp:228] Iteration 16550, loss = 0.607217
I1130 17:25:28.865798 28372 solver.cpp:244]     Train net output #0: loss = 0.607217 (* 1 = 0.607217 loss)
I1130 17:25:28.865803 28372 sgd_solver.cpp:106] Iteration 16550, lr = 1e-06
I1130 17:25:34.128521 28372 solver.cpp:337] Iteration 16600, Testing net (#0)
I1130 17:25:41.664260 28372 solver.cpp:404]     Test net output #0: accuracy = 0.64043
I1130 17:25:41.664316 28372 solver.cpp:404]     Test net output #1: loss = 0.624096 (* 1 = 0.624096 loss)
I1130 17:25:41.694605 28372 solver.cpp:228] Iteration 16600, loss = 0.59648
I1130 17:25:41.694658 28372 solver.cpp:244]     Train net output #0: loss = 0.59648 (* 1 = 0.59648 loss)
I1130 17:25:41.694680 28372 sgd_solver.cpp:106] Iteration 16600, lr = 1e-06
I1130 17:25:45.670888 28372 solver.cpp:228] Iteration 16650, loss = 0.592336
I1130 17:25:45.670949 28372 solver.cpp:244]     Train net output #0: loss = 0.592336 (* 1 = 0.592336 loss)
I1130 17:25:45.670959 28372 sgd_solver.cpp:106] Iteration 16650, lr = 1e-06
I1130 17:25:51.389307 28372 solver.cpp:228] Iteration 16700, loss = 0.524979
I1130 17:25:51.389367 28372 solver.cpp:244]     Train net output #0: loss = 0.524979 (* 1 = 0.524979 loss)
I1130 17:25:51.389376 28372 sgd_solver.cpp:106] Iteration 16700, lr = 1e-06
I1130 17:25:56.125325 28372 solver.cpp:228] Iteration 16750, loss = 0.679106
I1130 17:25:56.125383 28372 solver.cpp:244]     Train net output #0: loss = 0.679106 (* 1 = 0.679106 loss)
I1130 17:25:56.125392 28372 sgd_solver.cpp:106] Iteration 16750, lr = 1e-06
I1130 17:26:00.158385 28372 solver.cpp:337] Iteration 16800, Testing net (#0)
I1130 17:26:07.793596 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641211
I1130 17:26:08.054641 28372 solver.cpp:404]     Test net output #1: loss = 0.62359 (* 1 = 0.62359 loss)
I1130 17:26:08.091761 28372 solver.cpp:228] Iteration 16800, loss = 0.55376
I1130 17:26:08.091836 28372 solver.cpp:244]     Train net output #0: loss = 0.55376 (* 1 = 0.55376 loss)
I1130 17:26:08.091857 28372 sgd_solver.cpp:106] Iteration 16800, lr = 1e-06
I1130 17:26:12.522984 28372 solver.cpp:228] Iteration 16850, loss = 0.558676
I1130 17:26:12.523046 28372 solver.cpp:244]     Train net output #0: loss = 0.558676 (* 1 = 0.558676 loss)
I1130 17:26:12.523053 28372 sgd_solver.cpp:106] Iteration 16850, lr = 1e-06
I1130 17:26:17.467166 28372 solver.cpp:228] Iteration 16900, loss = 0.533114
I1130 17:26:17.467212 28372 solver.cpp:244]     Train net output #0: loss = 0.533114 (* 1 = 0.533114 loss)
I1130 17:26:17.467221 28372 sgd_solver.cpp:106] Iteration 16900, lr = 1e-06
I1130 17:26:22.822868 28372 solver.cpp:228] Iteration 16950, loss = 0.562047
I1130 17:26:22.822931 28372 solver.cpp:244]     Train net output #0: loss = 0.562047 (* 1 = 0.562047 loss)
I1130 17:26:22.822939 28372 sgd_solver.cpp:106] Iteration 16950, lr = 1e-06
I1130 17:26:26.716593 28372 solver.cpp:337] Iteration 17000, Testing net (#0)
I1130 17:26:36.053762 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641016
I1130 17:26:36.053830 28372 solver.cpp:404]     Test net output #1: loss = 0.623855 (* 1 = 0.623855 loss)
I1130 17:26:36.096794 28372 solver.cpp:228] Iteration 17000, loss = 0.575614
I1130 17:26:36.096848 28372 solver.cpp:244]     Train net output #0: loss = 0.575614 (* 1 = 0.575614 loss)
I1130 17:26:36.096863 28372 sgd_solver.cpp:106] Iteration 17000, lr = 1e-06
I1130 17:26:41.722126 28372 solver.cpp:228] Iteration 17050, loss = 0.603512
I1130 17:26:41.759366 28372 solver.cpp:244]     Train net output #0: loss = 0.603512 (* 1 = 0.603512 loss)
I1130 17:26:41.759392 28372 sgd_solver.cpp:106] Iteration 17050, lr = 1e-06
I1130 17:26:45.885254 28372 solver.cpp:228] Iteration 17100, loss = 0.634406
I1130 17:26:45.885318 28372 solver.cpp:244]     Train net output #0: loss = 0.634406 (* 1 = 0.634406 loss)
I1130 17:26:45.885326 28372 sgd_solver.cpp:106] Iteration 17100, lr = 1e-06
I1130 17:26:51.172219 28372 solver.cpp:228] Iteration 17150, loss = 0.604136
I1130 17:26:51.172267 28372 solver.cpp:244]     Train net output #0: loss = 0.604136 (* 1 = 0.604136 loss)
I1130 17:26:51.172276 28372 sgd_solver.cpp:106] Iteration 17150, lr = 1e-06
I1130 17:26:56.260942 28372 solver.cpp:337] Iteration 17200, Testing net (#0)
I1130 17:27:04.968155 28372 blocking_queue.cpp:50] Data layer prefetch queue empty
I1130 17:27:05.902379 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641341
I1130 17:27:05.902441 28372 solver.cpp:404]     Test net output #1: loss = 0.62349 (* 1 = 0.62349 loss)
I1130 17:27:05.939157 28372 solver.cpp:228] Iteration 17200, loss = 0.512131
I1130 17:27:05.939216 28372 solver.cpp:244]     Train net output #0: loss = 0.512131 (* 1 = 0.512131 loss)
I1130 17:27:05.939227 28372 sgd_solver.cpp:106] Iteration 17200, lr = 1e-06
I1130 17:27:10.775279 28372 solver.cpp:228] Iteration 17250, loss = 0.628224
I1130 17:27:10.775336 28372 solver.cpp:244]     Train net output #0: loss = 0.628224 (* 1 = 0.628224 loss)
I1130 17:27:10.775343 28372 sgd_solver.cpp:106] Iteration 17250, lr = 1e-06
I1130 17:27:16.439771 28372 solver.cpp:228] Iteration 17300, loss = 0.524148
I1130 17:27:18.542958 28372 solver.cpp:244]     Train net output #0: loss = 0.524148 (* 1 = 0.524148 loss)
I1130 17:27:18.542986 28372 sgd_solver.cpp:106] Iteration 17300, lr = 1e-06
I1130 17:27:23.450557 28372 solver.cpp:228] Iteration 17350, loss = 0.582309
I1130 17:27:23.450621 28372 solver.cpp:244]     Train net output #0: loss = 0.582309 (* 1 = 0.582309 loss)
I1130 17:27:23.450630 28372 sgd_solver.cpp:106] Iteration 17350, lr = 1e-06
I1130 17:27:27.175025 28372 solver.cpp:337] Iteration 17400, Testing net (#0)
I1130 17:27:34.799805 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641081
I1130 17:27:34.799854 28372 solver.cpp:404]     Test net output #1: loss = 0.624233 (* 1 = 0.624233 loss)
I1130 17:27:34.849614 28372 solver.cpp:228] Iteration 17400, loss = 0.50944
I1130 17:27:34.849653 28372 solver.cpp:244]     Train net output #0: loss = 0.50944 (* 1 = 0.50944 loss)
I1130 17:27:34.849664 28372 sgd_solver.cpp:106] Iteration 17400, lr = 1e-06
I1130 17:27:40.972995 28372 solver.cpp:228] Iteration 17450, loss = 0.68917
I1130 17:27:40.973042 28372 solver.cpp:244]     Train net output #0: loss = 0.68917 (* 1 = 0.68917 loss)
I1130 17:27:40.973049 28372 sgd_solver.cpp:106] Iteration 17450, lr = 1e-06
I1130 17:27:46.394152 28372 solver.cpp:228] Iteration 17500, loss = 0.607946
I1130 17:27:46.394196 28372 solver.cpp:244]     Train net output #0: loss = 0.607946 (* 1 = 0.607946 loss)
I1130 17:27:46.394202 28372 sgd_solver.cpp:106] Iteration 17500, lr = 1e-06
I1130 17:27:51.207960 28372 solver.cpp:228] Iteration 17550, loss = 0.614585
I1130 17:27:51.208210 28372 solver.cpp:244]     Train net output #0: loss = 0.614585 (* 1 = 0.614585 loss)
I1130 17:27:51.208228 28372 sgd_solver.cpp:106] Iteration 17550, lr = 1e-06
I1130 17:27:55.955974 28372 solver.cpp:337] Iteration 17600, Testing net (#0)
I1130 17:28:05.155236 28372 solver.cpp:404]     Test net output #0: accuracy = 0.640495
I1130 17:28:05.155297 28372 solver.cpp:404]     Test net output #1: loss = 0.623871 (* 1 = 0.623871 loss)
I1130 17:28:05.192674 28372 solver.cpp:228] Iteration 17600, loss = 0.597402
I1130 17:28:05.192719 28372 solver.cpp:244]     Train net output #0: loss = 0.597402 (* 1 = 0.597402 loss)
I1130 17:28:05.192733 28372 sgd_solver.cpp:106] Iteration 17600, lr = 1e-06
I1130 17:28:10.574821 28372 solver.cpp:228] Iteration 17650, loss = 0.680567
I1130 17:28:10.574895 28372 solver.cpp:244]     Train net output #0: loss = 0.680567 (* 1 = 0.680567 loss)
I1130 17:28:10.574904 28372 sgd_solver.cpp:106] Iteration 17650, lr = 1e-06
I1130 17:28:14.962771 28372 solver.cpp:228] Iteration 17700, loss = 0.619751
I1130 17:28:14.962833 28372 solver.cpp:244]     Train net output #0: loss = 0.619751 (* 1 = 0.619751 loss)
I1130 17:28:14.962842 28372 sgd_solver.cpp:106] Iteration 17700, lr = 1e-06
I1130 17:28:20.219107 28372 solver.cpp:228] Iteration 17750, loss = 0.644723
I1130 17:28:20.219169 28372 solver.cpp:244]     Train net output #0: loss = 0.644723 (* 1 = 0.644723 loss)
I1130 17:28:20.219188 28372 sgd_solver.cpp:106] Iteration 17750, lr = 1e-06
I1130 17:28:25.797884 28372 solver.cpp:337] Iteration 17800, Testing net (#0)
I1130 17:28:33.566840 28372 solver.cpp:404]     Test net output #0: accuracy = 0.640625
I1130 17:28:33.566900 28372 solver.cpp:404]     Test net output #1: loss = 0.623867 (* 1 = 0.623867 loss)
I1130 17:28:33.593883 28372 solver.cpp:228] Iteration 17800, loss = 0.525418
I1130 17:28:33.593927 28372 solver.cpp:244]     Train net output #0: loss = 0.525418 (* 1 = 0.525418 loss)
I1130 17:28:33.593940 28372 sgd_solver.cpp:106] Iteration 17800, lr = 1e-06
I1130 17:28:38.922533 28372 solver.cpp:228] Iteration 17850, loss = 0.578507
I1130 17:28:38.922579 28372 solver.cpp:244]     Train net output #0: loss = 0.578507 (* 1 = 0.578507 loss)
I1130 17:28:38.922587 28372 sgd_solver.cpp:106] Iteration 17850, lr = 1e-06
I1130 17:28:45.181506 28372 solver.cpp:228] Iteration 17900, loss = 0.643517
I1130 17:28:45.181568 28372 solver.cpp:244]     Train net output #0: loss = 0.643517 (* 1 = 0.643517 loss)
I1130 17:28:45.181577 28372 sgd_solver.cpp:106] Iteration 17900, lr = 1e-06
I1130 17:28:50.047544 28372 solver.cpp:228] Iteration 17950, loss = 0.543408
I1130 17:28:50.047595 28372 solver.cpp:244]     Train net output #0: loss = 0.543408 (* 1 = 0.543408 loss)
I1130 17:28:50.047605 28372 sgd_solver.cpp:106] Iteration 17950, lr = 1e-06
I1130 17:28:55.195948 28372 solver.cpp:337] Iteration 18000, Testing net (#0)
I1130 17:29:03.432034 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641081
I1130 17:29:03.432293 28372 solver.cpp:404]     Test net output #1: loss = 0.623778 (* 1 = 0.623778 loss)
I1130 17:29:03.459468 28372 solver.cpp:228] Iteration 18000, loss = 0.620174
I1130 17:29:03.459520 28372 solver.cpp:244]     Train net output #0: loss = 0.620174 (* 1 = 0.620174 loss)
I1130 17:29:03.459537 28372 sgd_solver.cpp:106] Iteration 18000, lr = 1e-06
I1130 17:29:08.108721 28372 solver.cpp:228] Iteration 18050, loss = 0.633366
I1130 17:29:08.108793 28372 solver.cpp:244]     Train net output #0: loss = 0.633366 (* 1 = 0.633366 loss)
I1130 17:29:08.108801 28372 sgd_solver.cpp:106] Iteration 18050, lr = 1e-06
I1130 17:29:12.316843 28372 solver.cpp:228] Iteration 18100, loss = 0.621595
I1130 17:29:12.316897 28372 solver.cpp:244]     Train net output #0: loss = 0.621595 (* 1 = 0.621595 loss)
I1130 17:29:12.316906 28372 sgd_solver.cpp:106] Iteration 18100, lr = 1e-06
I1130 17:29:18.839987 28372 solver.cpp:228] Iteration 18150, loss = 0.621509
I1130 17:29:18.840047 28372 solver.cpp:244]     Train net output #0: loss = 0.621509 (* 1 = 0.621509 loss)
I1130 17:29:18.840067 28372 sgd_solver.cpp:106] Iteration 18150, lr = 1e-06
I1130 17:29:24.041278 28372 solver.cpp:337] Iteration 18200, Testing net (#0)
I1130 17:29:33.705785 28372 solver.cpp:404]     Test net output #0: accuracy = 0.640951
I1130 17:29:33.706006 28372 solver.cpp:404]     Test net output #1: loss = 0.623821 (* 1 = 0.623821 loss)
I1130 17:29:33.751869 28372 solver.cpp:228] Iteration 18200, loss = 0.655427
I1130 17:29:33.751921 28372 solver.cpp:244]     Train net output #0: loss = 0.655427 (* 1 = 0.655427 loss)
I1130 17:29:33.751935 28372 sgd_solver.cpp:106] Iteration 18200, lr = 1e-06
I1130 17:29:38.655133 28372 solver.cpp:228] Iteration 18250, loss = 0.670245
I1130 17:29:38.655177 28372 solver.cpp:244]     Train net output #0: loss = 0.670245 (* 1 = 0.670245 loss)
I1130 17:29:38.655185 28372 sgd_solver.cpp:106] Iteration 18250, lr = 1e-06
I1130 17:29:43.788617 28372 solver.cpp:228] Iteration 18300, loss = 0.659053
I1130 17:29:43.788663 28372 solver.cpp:244]     Train net output #0: loss = 0.659053 (* 1 = 0.659053 loss)
I1130 17:29:43.788671 28372 sgd_solver.cpp:106] Iteration 18300, lr = 1e-06
I1130 17:29:49.570291 28372 solver.cpp:228] Iteration 18350, loss = 0.630404
I1130 17:29:49.570349 28372 solver.cpp:244]     Train net output #0: loss = 0.630404 (* 1 = 0.630404 loss)
I1130 17:29:49.570358 28372 sgd_solver.cpp:106] Iteration 18350, lr = 1e-06
I1130 17:29:55.235112 28372 solver.cpp:337] Iteration 18400, Testing net (#0)
I1130 17:29:58.329972 28372 blocking_queue.cpp:50] Data layer prefetch queue empty
I1130 17:30:04.662230 28372 solver.cpp:404]     Test net output #0: accuracy = 0.64056
I1130 17:30:06.542976 28372 solver.cpp:404]     Test net output #1: loss = 0.624238 (* 1 = 0.624238 loss)
I1130 17:30:06.581493 28372 solver.cpp:228] Iteration 18400, loss = 0.659369
I1130 17:30:06.581567 28372 solver.cpp:244]     Train net output #0: loss = 0.659369 (* 1 = 0.659369 loss)
I1130 17:30:06.581588 28372 sgd_solver.cpp:106] Iteration 18400, lr = 1e-06
I1130 17:30:12.069243 28372 solver.cpp:228] Iteration 18450, loss = 0.567272
I1130 17:30:12.069295 28372 solver.cpp:244]     Train net output #0: loss = 0.567272 (* 1 = 0.567272 loss)
I1130 17:30:12.069304 28372 sgd_solver.cpp:106] Iteration 18450, lr = 1e-06
I1130 17:30:17.827065 28372 solver.cpp:228] Iteration 18500, loss = 0.54034
I1130 17:30:17.827129 28372 solver.cpp:244]     Train net output #0: loss = 0.54034 (* 1 = 0.54034 loss)
I1130 17:30:17.827150 28372 sgd_solver.cpp:106] Iteration 18500, lr = 1e-06
I1130 17:30:23.075083 28372 solver.cpp:228] Iteration 18550, loss = 0.636826
I1130 17:30:23.075141 28372 solver.cpp:244]     Train net output #0: loss = 0.636826 (* 1 = 0.636826 loss)
I1130 17:30:23.075151 28372 sgd_solver.cpp:106] Iteration 18550, lr = 1e-06
I1130 17:30:28.756328 28372 solver.cpp:337] Iteration 18600, Testing net (#0)
I1130 17:30:37.293985 28372 solver.cpp:404]     Test net output #0: accuracy = 0.640951
I1130 17:30:38.542961 28372 solver.cpp:404]     Test net output #1: loss = 0.623983 (* 1 = 0.623983 loss)
I1130 17:30:38.577961 28372 solver.cpp:228] Iteration 18600, loss = 0.610214
I1130 17:30:38.578039 28372 solver.cpp:244]     Train net output #0: loss = 0.610214 (* 1 = 0.610214 loss)
I1130 17:30:38.578060 28372 sgd_solver.cpp:106] Iteration 18600, lr = 1e-06
I1130 17:30:43.672171 28372 solver.cpp:228] Iteration 18650, loss = 0.626216
I1130 17:30:43.672217 28372 solver.cpp:244]     Train net output #0: loss = 0.626216 (* 1 = 0.626216 loss)
I1130 17:30:43.672226 28372 sgd_solver.cpp:106] Iteration 18650, lr = 1e-06
I1130 17:30:48.413167 28372 solver.cpp:228] Iteration 18700, loss = 0.721227
I1130 17:30:48.413244 28372 solver.cpp:244]     Train net output #0: loss = 0.721227 (* 1 = 0.721227 loss)
I1130 17:30:48.413259 28372 sgd_solver.cpp:106] Iteration 18700, lr = 1e-06
I1130 17:30:52.846655 28372 solver.cpp:228] Iteration 18750, loss = 0.769555
I1130 17:30:52.846717 28372 solver.cpp:244]     Train net output #0: loss = 0.769555 (* 1 = 0.769555 loss)
I1130 17:30:52.846725 28372 sgd_solver.cpp:106] Iteration 18750, lr = 1e-06
I1130 17:30:58.577574 28372 solver.cpp:337] Iteration 18800, Testing net (#0)
I1130 17:31:08.307634 28372 solver.cpp:404]     Test net output #0: accuracy = 0.64082
I1130 17:31:09.738870 28372 solver.cpp:404]     Test net output #1: loss = 0.624043 (* 1 = 0.624043 loss)
I1130 17:31:09.764763 28372 solver.cpp:228] Iteration 18800, loss = 0.563344
I1130 17:31:09.764842 28372 solver.cpp:244]     Train net output #0: loss = 0.563344 (* 1 = 0.563344 loss)
I1130 17:31:09.764865 28372 sgd_solver.cpp:106] Iteration 18800, lr = 1e-06
I1130 17:31:15.034459 28372 solver.cpp:228] Iteration 18850, loss = 0.509421
I1130 17:31:15.034520 28372 solver.cpp:244]     Train net output #0: loss = 0.509421 (* 1 = 0.509421 loss)
I1130 17:31:15.034529 28372 sgd_solver.cpp:106] Iteration 18850, lr = 1e-06
I1130 17:31:20.544199 28372 solver.cpp:228] Iteration 18900, loss = 0.628812
I1130 17:31:20.544256 28372 solver.cpp:244]     Train net output #0: loss = 0.628812 (* 1 = 0.628812 loss)
I1130 17:31:20.544265 28372 sgd_solver.cpp:106] Iteration 18900, lr = 1e-06
I1130 17:31:25.156509 28372 solver.cpp:228] Iteration 18950, loss = 0.547477
I1130 17:31:25.156590 28372 solver.cpp:244]     Train net output #0: loss = 0.547477 (* 1 = 0.547477 loss)
I1130 17:31:25.156605 28372 sgd_solver.cpp:106] Iteration 18950, lr = 1e-06
I1130 17:31:30.490708 28372 solver.cpp:337] Iteration 19000, Testing net (#0)
I1130 17:31:40.024428 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641016
I1130 17:31:40.222537 28372 solver.cpp:404]     Test net output #1: loss = 0.623958 (* 1 = 0.623958 loss)
I1130 17:31:40.263947 28372 solver.cpp:228] Iteration 19000, loss = 0.59024
I1130 17:31:40.264014 28372 solver.cpp:244]     Train net output #0: loss = 0.59024 (* 1 = 0.59024 loss)
I1130 17:31:40.264034 28372 sgd_solver.cpp:106] Iteration 19000, lr = 1e-06
I1130 17:31:45.815507 28372 solver.cpp:228] Iteration 19050, loss = 0.580318
I1130 17:31:45.815565 28372 solver.cpp:244]     Train net output #0: loss = 0.580318 (* 1 = 0.580318 loss)
I1130 17:31:45.815573 28372 sgd_solver.cpp:106] Iteration 19050, lr = 1e-06
I1130 17:31:49.828174 28372 solver.cpp:228] Iteration 19100, loss = 0.53409
I1130 17:31:49.828223 28372 solver.cpp:244]     Train net output #0: loss = 0.53409 (* 1 = 0.53409 loss)
I1130 17:31:49.828230 28372 sgd_solver.cpp:106] Iteration 19100, lr = 1e-06
I1130 17:31:53.847278 28372 solver.cpp:228] Iteration 19150, loss = 0.600502
I1130 17:31:53.847338 28372 solver.cpp:244]     Train net output #0: loss = 0.600502 (* 1 = 0.600502 loss)
I1130 17:31:53.847347 28372 sgd_solver.cpp:106] Iteration 19150, lr = 1e-06
I1130 17:31:59.750989 28372 solver.cpp:337] Iteration 19200, Testing net (#0)
I1130 17:32:09.678905 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641536
I1130 17:32:09.678963 28372 solver.cpp:404]     Test net output #1: loss = 0.623413 (* 1 = 0.623413 loss)
I1130 17:32:09.709302 28372 solver.cpp:228] Iteration 19200, loss = 0.547074
I1130 17:32:09.709337 28372 solver.cpp:244]     Train net output #0: loss = 0.547074 (* 1 = 0.547074 loss)
I1130 17:32:09.709350 28372 sgd_solver.cpp:106] Iteration 19200, lr = 1e-06
I1130 17:32:15.033140 28372 solver.cpp:228] Iteration 19250, loss = 0.687914
I1130 17:32:18.542958 28372 solver.cpp:244]     Train net output #0: loss = 0.687914 (* 1 = 0.687914 loss)
I1130 17:32:18.542991 28372 sgd_solver.cpp:106] Iteration 19250, lr = 1e-06
I1130 17:32:23.223237 28372 solver.cpp:228] Iteration 19300, loss = 0.679598
I1130 17:32:23.223289 28372 solver.cpp:244]     Train net output #0: loss = 0.679598 (* 1 = 0.679598 loss)
I1130 17:32:23.223300 28372 sgd_solver.cpp:106] Iteration 19300, lr = 1e-06
I1130 17:32:28.992853 28372 solver.cpp:228] Iteration 19350, loss = 0.479712
I1130 17:32:28.992911 28372 solver.cpp:244]     Train net output #0: loss = 0.479712 (* 1 = 0.479712 loss)
I1130 17:32:28.992920 28372 sgd_solver.cpp:106] Iteration 19350, lr = 1e-06
I1130 17:32:34.197216 28372 solver.cpp:337] Iteration 19400, Testing net (#0)
I1130 17:32:44.552517 28372 solver.cpp:404]     Test net output #0: accuracy = 0.640885
I1130 17:32:44.552567 28372 solver.cpp:404]     Test net output #1: loss = 0.623867 (* 1 = 0.623867 loss)
I1130 17:32:44.593232 28372 solver.cpp:228] Iteration 19400, loss = 0.614124
I1130 17:32:44.593276 28372 solver.cpp:244]     Train net output #0: loss = 0.614124 (* 1 = 0.614124 loss)
I1130 17:32:44.593287 28372 sgd_solver.cpp:106] Iteration 19400, lr = 1e-06
I1130 17:32:49.884711 28372 solver.cpp:228] Iteration 19450, loss = 0.588072
I1130 17:32:49.926697 28372 solver.cpp:244]     Train net output #0: loss = 0.588072 (* 1 = 0.588072 loss)
I1130 17:32:49.926723 28372 sgd_solver.cpp:106] Iteration 19450, lr = 1e-06
I1130 17:32:55.652185 28372 solver.cpp:228] Iteration 19500, loss = 0.554985
I1130 17:32:55.652235 28372 solver.cpp:244]     Train net output #0: loss = 0.554985 (* 1 = 0.554985 loss)
I1130 17:32:55.652242 28372 sgd_solver.cpp:106] Iteration 19500, lr = 1e-06
I1130 17:33:01.107015 28372 solver.cpp:228] Iteration 19550, loss = 0.580357
I1130 17:33:01.107061 28372 solver.cpp:244]     Train net output #0: loss = 0.580357 (* 1 = 0.580357 loss)
I1130 17:33:01.107070 28372 sgd_solver.cpp:106] Iteration 19550, lr = 1e-06
I1130 17:33:05.895381 28372 solver.cpp:337] Iteration 19600, Testing net (#0)
I1130 17:33:15.386277 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641341
I1130 17:33:15.386329 28372 solver.cpp:404]     Test net output #1: loss = 0.623725 (* 1 = 0.623725 loss)
I1130 17:33:15.427454 28372 solver.cpp:228] Iteration 19600, loss = 0.666187
I1130 17:33:15.427508 28372 solver.cpp:244]     Train net output #0: loss = 0.666187 (* 1 = 0.666187 loss)
I1130 17:33:15.427520 28372 sgd_solver.cpp:106] Iteration 19600, lr = 1e-06
I1130 17:33:20.724094 28372 solver.cpp:228] Iteration 19650, loss = 0.647097
I1130 17:33:20.724275 28372 solver.cpp:244]     Train net output #0: loss = 0.647097 (* 1 = 0.647097 loss)
I1130 17:33:20.724284 28372 sgd_solver.cpp:106] Iteration 19650, lr = 1e-06
I1130 17:33:26.854713 28372 solver.cpp:228] Iteration 19700, loss = 0.572007
I1130 17:33:26.854774 28372 solver.cpp:244]     Train net output #0: loss = 0.572007 (* 1 = 0.572007 loss)
I1130 17:33:26.854784 28372 sgd_solver.cpp:106] Iteration 19700, lr = 1e-06
I1130 17:33:31.703939 28372 solver.cpp:228] Iteration 19750, loss = 0.616682
I1130 17:33:31.703986 28372 solver.cpp:244]     Train net output #0: loss = 0.616682 (* 1 = 0.616682 loss)
I1130 17:33:31.703995 28372 sgd_solver.cpp:106] Iteration 19750, lr = 1e-06
I1130 17:33:35.596056 28372 solver.cpp:337] Iteration 19800, Testing net (#0)
I1130 17:33:39.122114 28372 blocking_queue.cpp:50] Data layer prefetch queue empty
I1130 17:33:43.376716 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641406
I1130 17:33:43.376773 28372 solver.cpp:404]     Test net output #1: loss = 0.623744 (* 1 = 0.623744 loss)
I1130 17:33:43.416791 28372 solver.cpp:228] Iteration 19800, loss = 0.559972
I1130 17:33:43.416849 28372 solver.cpp:244]     Train net output #0: loss = 0.559972 (* 1 = 0.559972 loss)
I1130 17:33:43.416870 28372 sgd_solver.cpp:106] Iteration 19800, lr = 1e-06
I1130 17:33:48.277704 28372 solver.cpp:228] Iteration 19850, loss = 0.616309
I1130 17:33:48.277760 28372 solver.cpp:244]     Train net output #0: loss = 0.616309 (* 1 = 0.616309 loss)
I1130 17:33:48.277765 28372 sgd_solver.cpp:106] Iteration 19850, lr = 1e-06
I1130 17:33:52.243255 28372 solver.cpp:228] Iteration 19900, loss = 0.559447
I1130 17:33:52.439832 28372 solver.cpp:244]     Train net output #0: loss = 0.559447 (* 1 = 0.559447 loss)
I1130 17:33:52.439862 28372 sgd_solver.cpp:106] Iteration 19900, lr = 1e-06
I1130 17:33:57.594422 28372 solver.cpp:228] Iteration 19950, loss = 0.567227
I1130 17:33:57.594478 28372 solver.cpp:244]     Train net output #0: loss = 0.567227 (* 1 = 0.567227 loss)
I1130 17:33:57.594488 28372 sgd_solver.cpp:106] Iteration 19950, lr = 1e-06
I1130 17:34:02.961735 28372 solver.cpp:454] Snapshotting to binary proto file /home/tbochens/Nets/FineTuning/Facebook/thumb_2/solver2/facebook_solv2_iter_20000.caffemodel
I1130 17:34:03.917978 28372 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/tbochens/Nets/FineTuning/Facebook/thumb_2/solver2/facebook_solv2_iter_20000.solverstate
I1130 17:34:04.279597 28372 solver.cpp:337] Iteration 20000, Testing net (#0)
I1130 17:34:13.539172 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641862
I1130 17:34:13.539223 28372 solver.cpp:404]     Test net output #1: loss = 0.623255 (* 1 = 0.623255 loss)
I1130 17:34:13.566781 28372 solver.cpp:228] Iteration 20000, loss = 0.561178
I1130 17:34:13.566820 28372 solver.cpp:244]     Train net output #0: loss = 0.561178 (* 1 = 0.561178 loss)
I1130 17:34:13.566831 28372 sgd_solver.cpp:106] Iteration 20000, lr = 1e-07
I1130 17:34:18.947389 28372 solver.cpp:228] Iteration 20050, loss = 0.614818
I1130 17:34:18.947450 28372 solver.cpp:244]     Train net output #0: loss = 0.614818 (* 1 = 0.614818 loss)
I1130 17:34:18.947458 28372 sgd_solver.cpp:106] Iteration 20050, lr = 1e-07
I1130 17:34:22.999524 28372 solver.cpp:228] Iteration 20100, loss = 0.59043
I1130 17:34:26.542956 28372 solver.cpp:244]     Train net output #0: loss = 0.59043 (* 1 = 0.59043 loss)
I1130 17:34:26.542986 28372 sgd_solver.cpp:106] Iteration 20100, lr = 1e-07
I1130 17:34:30.328677 28372 solver.cpp:228] Iteration 20150, loss = 0.560988
I1130 17:34:30.328740 28372 solver.cpp:244]     Train net output #0: loss = 0.560988 (* 1 = 0.560988 loss)
I1130 17:34:30.328749 28372 sgd_solver.cpp:106] Iteration 20150, lr = 1e-07
I1130 17:34:35.776792 28372 solver.cpp:337] Iteration 20200, Testing net (#0)
I1130 17:34:45.822412 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641016
I1130 17:34:45.822460 28372 solver.cpp:404]     Test net output #1: loss = 0.623859 (* 1 = 0.623859 loss)
I1130 17:34:45.855700 28372 solver.cpp:228] Iteration 20200, loss = 0.529577
I1130 17:34:45.855754 28372 solver.cpp:244]     Train net output #0: loss = 0.529577 (* 1 = 0.529577 loss)
I1130 17:34:45.855765 28372 sgd_solver.cpp:106] Iteration 20200, lr = 1e-07
I1130 17:34:51.603332 28372 solver.cpp:228] Iteration 20250, loss = 0.663796
I1130 17:34:51.603411 28372 solver.cpp:244]     Train net output #0: loss = 0.663796 (* 1 = 0.663796 loss)
I1130 17:34:51.603420 28372 sgd_solver.cpp:106] Iteration 20250, lr = 1e-07
I1130 17:34:56.219310 28372 solver.cpp:228] Iteration 20300, loss = 0.561779
I1130 17:34:56.219615 28372 solver.cpp:244]     Train net output #0: loss = 0.561779 (* 1 = 0.561779 loss)
I1130 17:34:56.219633 28372 sgd_solver.cpp:106] Iteration 20300, lr = 1e-07
I1130 17:35:00.646149 28372 solver.cpp:228] Iteration 20350, loss = 0.597052
I1130 17:35:00.646200 28372 solver.cpp:244]     Train net output #0: loss = 0.597052 (* 1 = 0.597052 loss)
I1130 17:35:00.646209 28372 sgd_solver.cpp:106] Iteration 20350, lr = 1e-07
I1130 17:35:06.100656 28372 solver.cpp:337] Iteration 20400, Testing net (#0)
I1130 17:35:15.537273 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641146
I1130 17:35:15.537336 28372 solver.cpp:404]     Test net output #1: loss = 0.624283 (* 1 = 0.624283 loss)
I1130 17:35:15.567045 28372 solver.cpp:228] Iteration 20400, loss = 0.603798
I1130 17:35:15.567075 28372 solver.cpp:244]     Train net output #0: loss = 0.603798 (* 1 = 0.603798 loss)
I1130 17:35:15.567086 28372 sgd_solver.cpp:106] Iteration 20400, lr = 1e-07
I1130 17:35:20.176265 28372 solver.cpp:228] Iteration 20450, loss = 0.501404
I1130 17:35:20.176316 28372 solver.cpp:244]     Train net output #0: loss = 0.501404 (* 1 = 0.501404 loss)
I1130 17:35:20.176326 28372 sgd_solver.cpp:106] Iteration 20450, lr = 1e-07
I1130 17:35:26.264897 28372 solver.cpp:228] Iteration 20500, loss = 0.552316
I1130 17:35:26.265166 28372 solver.cpp:244]     Train net output #0: loss = 0.552316 (* 1 = 0.552316 loss)
I1130 17:35:26.265185 28372 sgd_solver.cpp:106] Iteration 20500, lr = 1e-07
I1130 17:35:31.333684 28372 solver.cpp:228] Iteration 20550, loss = 0.599858
I1130 17:35:31.333736 28372 solver.cpp:244]     Train net output #0: loss = 0.599858 (* 1 = 0.599858 loss)
I1130 17:35:31.333744 28372 sgd_solver.cpp:106] Iteration 20550, lr = 1e-07
I1130 17:35:35.561990 28372 solver.cpp:337] Iteration 20600, Testing net (#0)
I1130 17:35:45.810500 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641602
I1130 17:35:45.810556 28372 solver.cpp:404]     Test net output #1: loss = 0.623767 (* 1 = 0.623767 loss)
I1130 17:35:45.854853 28372 solver.cpp:228] Iteration 20600, loss = 0.575245
I1130 17:35:45.854900 28372 solver.cpp:244]     Train net output #0: loss = 0.575245 (* 1 = 0.575245 loss)
I1130 17:35:45.854912 28372 sgd_solver.cpp:106] Iteration 20600, lr = 1e-07
I1130 17:35:50.724515 28372 solver.cpp:228] Iteration 20650, loss = 0.541215
I1130 17:35:50.724578 28372 solver.cpp:244]     Train net output #0: loss = 0.541215 (* 1 = 0.541215 loss)
I1130 17:35:50.724586 28372 sgd_solver.cpp:106] Iteration 20650, lr = 1e-07
I1130 17:35:55.912681 28372 solver.cpp:228] Iteration 20700, loss = 0.588745
I1130 17:35:55.912737 28372 solver.cpp:244]     Train net output #0: loss = 0.588745 (* 1 = 0.588745 loss)
I1130 17:35:55.912750 28372 sgd_solver.cpp:106] Iteration 20700, lr = 1e-07
I1130 17:36:00.190012 28372 solver.cpp:228] Iteration 20750, loss = 0.637969
I1130 17:36:00.287389 28372 solver.cpp:244]     Train net output #0: loss = 0.637969 (* 1 = 0.637969 loss)
I1130 17:36:00.287417 28372 sgd_solver.cpp:106] Iteration 20750, lr = 1e-07
I1130 17:36:05.453754 28372 solver.cpp:337] Iteration 20800, Testing net (#0)
I1130 17:36:14.800146 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641081
I1130 17:36:14.800207 28372 solver.cpp:404]     Test net output #1: loss = 0.623898 (* 1 = 0.623898 loss)
I1130 17:36:14.842784 28372 solver.cpp:228] Iteration 20800, loss = 0.639099
I1130 17:36:14.842844 28372 solver.cpp:244]     Train net output #0: loss = 0.639099 (* 1 = 0.639099 loss)
I1130 17:36:14.842857 28372 sgd_solver.cpp:106] Iteration 20800, lr = 1e-07
I1130 17:36:20.462216 28372 solver.cpp:228] Iteration 20850, loss = 0.539902
I1130 17:36:20.462299 28372 solver.cpp:244]     Train net output #0: loss = 0.539902 (* 1 = 0.539902 loss)
I1130 17:36:20.462304 28372 sgd_solver.cpp:106] Iteration 20850, lr = 1e-07
I1130 17:36:25.551925 28372 solver.cpp:228] Iteration 20900, loss = 0.636321
I1130 17:36:25.551980 28372 solver.cpp:244]     Train net output #0: loss = 0.636321 (* 1 = 0.636321 loss)
I1130 17:36:25.551990 28372 sgd_solver.cpp:106] Iteration 20900, lr = 1e-07
I1130 17:36:30.645658 28372 solver.cpp:228] Iteration 20950, loss = 0.619644
I1130 17:36:34.542971 28372 solver.cpp:244]     Train net output #0: loss = 0.619644 (* 1 = 0.619644 loss)
I1130 17:36:34.543022 28372 sgd_solver.cpp:106] Iteration 20950, lr = 1e-07
I1130 17:36:39.442076 28372 solver.cpp:337] Iteration 21000, Testing net (#0)
I1130 17:36:48.081925 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641471
I1130 17:36:48.082000 28372 solver.cpp:404]     Test net output #1: loss = 0.623758 (* 1 = 0.623758 loss)
I1130 17:36:48.111098 28372 solver.cpp:228] Iteration 21000, loss = 0.597294
I1130 17:36:48.111143 28372 solver.cpp:244]     Train net output #0: loss = 0.597294 (* 1 = 0.597294 loss)
I1130 17:36:48.111155 28372 sgd_solver.cpp:106] Iteration 21000, lr = 1e-07
I1130 17:36:53.719755 28372 solver.cpp:228] Iteration 21050, loss = 0.600953
I1130 17:36:53.719808 28372 solver.cpp:244]     Train net output #0: loss = 0.600953 (* 1 = 0.600953 loss)
I1130 17:36:53.719817 28372 sgd_solver.cpp:106] Iteration 21050, lr = 1e-07
I1130 17:36:59.292758 28372 solver.cpp:228] Iteration 21100, loss = 0.596555
I1130 17:36:59.292834 28372 solver.cpp:244]     Train net output #0: loss = 0.596555 (* 1 = 0.596555 loss)
I1130 17:36:59.292843 28372 sgd_solver.cpp:106] Iteration 21100, lr = 1e-07
I1130 17:37:04.872339 28372 solver.cpp:228] Iteration 21150, loss = 0.584073
I1130 17:37:04.872571 28372 solver.cpp:244]     Train net output #0: loss = 0.584073 (* 1 = 0.584073 loss)
I1130 17:37:04.872592 28372 sgd_solver.cpp:106] Iteration 21150, lr = 1e-07
I1130 17:37:10.503772 28372 solver.cpp:337] Iteration 21200, Testing net (#0)
I1130 17:37:18.965209 28372 blocking_queue.cpp:50] Data layer prefetch queue empty
I1130 17:37:19.749070 28372 solver.cpp:404]     Test net output #0: accuracy = 0.64082
I1130 17:37:19.749168 28372 solver.cpp:404]     Test net output #1: loss = 0.624158 (* 1 = 0.624158 loss)
I1130 17:37:19.775871 28372 solver.cpp:228] Iteration 21200, loss = 0.644903
I1130 17:37:19.775933 28372 solver.cpp:244]     Train net output #0: loss = 0.644903 (* 1 = 0.644903 loss)
I1130 17:37:19.775949 28372 sgd_solver.cpp:106] Iteration 21200, lr = 1e-07
I1130 17:37:23.757927 28372 solver.cpp:228] Iteration 21250, loss = 0.612659
I1130 17:37:23.757977 28372 solver.cpp:244]     Train net output #0: loss = 0.612659 (* 1 = 0.612659 loss)
I1130 17:37:23.757984 28372 sgd_solver.cpp:106] Iteration 21250, lr = 1e-07
I1130 17:37:28.609769 28372 solver.cpp:228] Iteration 21300, loss = 0.585695
I1130 17:37:28.609858 28372 solver.cpp:244]     Train net output #0: loss = 0.585695 (* 1 = 0.585695 loss)
I1130 17:37:28.609868 28372 sgd_solver.cpp:106] Iteration 21300, lr = 1e-07
I1130 17:37:33.741765 28372 solver.cpp:228] Iteration 21350, loss = 0.640974
I1130 17:37:33.741823 28372 solver.cpp:244]     Train net output #0: loss = 0.640974 (* 1 = 0.640974 loss)
I1130 17:37:33.741832 28372 sgd_solver.cpp:106] Iteration 21350, lr = 1e-07
I1130 17:37:39.311385 28372 solver.cpp:337] Iteration 21400, Testing net (#0)
I1130 17:37:47.602669 28372 solver.cpp:404]     Test net output #0: accuracy = 0.640234
I1130 17:37:47.602730 28372 solver.cpp:404]     Test net output #1: loss = 0.62441 (* 1 = 0.62441 loss)
I1130 17:37:47.633123 28372 solver.cpp:228] Iteration 21400, loss = 0.632966
I1130 17:37:47.633162 28372 solver.cpp:244]     Train net output #0: loss = 0.632966 (* 1 = 0.632966 loss)
I1130 17:37:47.633183 28372 sgd_solver.cpp:106] Iteration 21400, lr = 1e-07
I1130 17:37:53.589481 28372 solver.cpp:228] Iteration 21450, loss = 0.554788
I1130 17:37:53.589539 28372 solver.cpp:244]     Train net output #0: loss = 0.554788 (* 1 = 0.554788 loss)
I1130 17:37:53.589547 28372 sgd_solver.cpp:106] Iteration 21450, lr = 1e-07
I1130 17:37:59.101768 28372 solver.cpp:228] Iteration 21500, loss = 0.572455
I1130 17:37:59.101838 28372 solver.cpp:244]     Train net output #0: loss = 0.572455 (* 1 = 0.572455 loss)
I1130 17:37:59.101847 28372 sgd_solver.cpp:106] Iteration 21500, lr = 1e-07
I1130 17:38:04.570207 28372 solver.cpp:228] Iteration 21550, loss = 0.630657
I1130 17:38:04.570260 28372 solver.cpp:244]     Train net output #0: loss = 0.630657 (* 1 = 0.630657 loss)
I1130 17:38:04.570267 28372 sgd_solver.cpp:106] Iteration 21550, lr = 1e-07
I1130 17:38:09.564579 28372 solver.cpp:337] Iteration 21600, Testing net (#0)
I1130 17:38:18.293817 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641341
I1130 17:38:18.293877 28372 solver.cpp:404]     Test net output #1: loss = 0.623739 (* 1 = 0.623739 loss)
I1130 17:38:18.343772 28372 solver.cpp:228] Iteration 21600, loss = 0.55341
I1130 17:38:18.343827 28372 solver.cpp:244]     Train net output #0: loss = 0.55341 (* 1 = 0.55341 loss)
I1130 17:38:18.343861 28372 sgd_solver.cpp:106] Iteration 21600, lr = 1e-07
I1130 17:38:23.865509 28372 solver.cpp:228] Iteration 21650, loss = 0.608852
I1130 17:38:23.865561 28372 solver.cpp:244]     Train net output #0: loss = 0.608852 (* 1 = 0.608852 loss)
I1130 17:38:23.865568 28372 sgd_solver.cpp:106] Iteration 21650, lr = 1e-07
I1130 17:38:29.619437 28372 solver.cpp:228] Iteration 21700, loss = 0.566916
I1130 17:38:29.619478 28372 solver.cpp:244]     Train net output #0: loss = 0.566916 (* 1 = 0.566916 loss)
I1130 17:38:29.619487 28372 sgd_solver.cpp:106] Iteration 21700, lr = 1e-07
I1130 17:38:33.816063 28372 solver.cpp:228] Iteration 21750, loss = 0.604967
I1130 17:38:33.816125 28372 solver.cpp:244]     Train net output #0: loss = 0.604967 (* 1 = 0.604967 loss)
I1130 17:38:33.816133 28372 sgd_solver.cpp:106] Iteration 21750, lr = 1e-07
I1130 17:38:37.705955 28372 solver.cpp:337] Iteration 21800, Testing net (#0)
I1130 17:38:46.162267 28372 solver.cpp:404]     Test net output #0: accuracy = 0.642187
I1130 17:38:46.162497 28372 solver.cpp:404]     Test net output #1: loss = 0.623487 (* 1 = 0.623487 loss)
I1130 17:38:46.205859 28372 solver.cpp:228] Iteration 21800, loss = 0.6132
I1130 17:38:46.205924 28372 solver.cpp:244]     Train net output #0: loss = 0.6132 (* 1 = 0.6132 loss)
I1130 17:38:46.205940 28372 sgd_solver.cpp:106] Iteration 21800, lr = 1e-07
I1130 17:38:51.666790 28372 solver.cpp:228] Iteration 21850, loss = 0.602147
I1130 17:38:51.666846 28372 solver.cpp:244]     Train net output #0: loss = 0.602147 (* 1 = 0.602147 loss)
I1130 17:38:51.666854 28372 sgd_solver.cpp:106] Iteration 21850, lr = 1e-07
I1130 17:38:56.131650 28372 solver.cpp:228] Iteration 21900, loss = 0.625199
I1130 17:38:56.131709 28372 solver.cpp:244]     Train net output #0: loss = 0.625199 (* 1 = 0.625199 loss)
I1130 17:38:56.131718 28372 sgd_solver.cpp:106] Iteration 21900, lr = 1e-07
I1130 17:39:02.373194 28372 solver.cpp:228] Iteration 21950, loss = 0.635814
I1130 17:39:02.373244 28372 solver.cpp:244]     Train net output #0: loss = 0.635814 (* 1 = 0.635814 loss)
I1130 17:39:02.373251 28372 sgd_solver.cpp:106] Iteration 21950, lr = 1e-07
I1130 17:39:07.240293 28372 solver.cpp:337] Iteration 22000, Testing net (#0)
I1130 17:39:16.738191 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641016
I1130 17:39:16.738466 28372 solver.cpp:404]     Test net output #1: loss = 0.624018 (* 1 = 0.624018 loss)
I1130 17:39:16.782045 28372 solver.cpp:228] Iteration 22000, loss = 0.564741
I1130 17:39:16.782115 28372 solver.cpp:244]     Train net output #0: loss = 0.564741 (* 1 = 0.564741 loss)
I1130 17:39:16.782133 28372 sgd_solver.cpp:106] Iteration 22000, lr = 1e-07
I1130 17:39:21.779340 28372 solver.cpp:228] Iteration 22050, loss = 0.661001
I1130 17:39:21.779392 28372 solver.cpp:244]     Train net output #0: loss = 0.661001 (* 1 = 0.661001 loss)
I1130 17:39:21.779400 28372 sgd_solver.cpp:106] Iteration 22050, lr = 1e-07
I1130 17:39:25.905501 28372 solver.cpp:228] Iteration 22100, loss = 0.632504
I1130 17:39:25.905550 28372 solver.cpp:244]     Train net output #0: loss = 0.632504 (* 1 = 0.632504 loss)
I1130 17:39:25.905555 28372 sgd_solver.cpp:106] Iteration 22100, lr = 1e-07
I1130 17:39:29.927194 28372 solver.cpp:228] Iteration 22150, loss = 0.584687
I1130 17:39:29.927240 28372 solver.cpp:244]     Train net output #0: loss = 0.584687 (* 1 = 0.584687 loss)
I1130 17:39:29.927248 28372 sgd_solver.cpp:106] Iteration 22150, lr = 1e-07
I1130 17:39:35.300226 28372 solver.cpp:337] Iteration 22200, Testing net (#0)
I1130 17:39:43.127717 28372 solver.cpp:404]     Test net output #0: accuracy = 0.64056
I1130 17:39:43.127777 28372 solver.cpp:404]     Test net output #1: loss = 0.624044 (* 1 = 0.624044 loss)
I1130 17:39:43.158705 28372 solver.cpp:228] Iteration 22200, loss = 0.552341
I1130 17:39:43.158773 28372 solver.cpp:244]     Train net output #0: loss = 0.552341 (* 1 = 0.552341 loss)
I1130 17:39:43.158789 28372 sgd_solver.cpp:106] Iteration 22200, lr = 1e-07
I1130 17:39:48.471662 28372 solver.cpp:228] Iteration 22250, loss = 0.555023
I1130 17:39:48.471894 28372 solver.cpp:244]     Train net output #0: loss = 0.555023 (* 1 = 0.555023 loss)
I1130 17:39:48.471911 28372 sgd_solver.cpp:106] Iteration 22250, lr = 1e-07
I1130 17:39:54.324338 28372 solver.cpp:228] Iteration 22300, loss = 0.601916
I1130 17:39:54.324406 28372 solver.cpp:244]     Train net output #0: loss = 0.601916 (* 1 = 0.601916 loss)
I1130 17:39:54.324414 28372 sgd_solver.cpp:106] Iteration 22300, lr = 1e-07
I1130 17:39:58.868856 28372 solver.cpp:228] Iteration 22350, loss = 0.642274
I1130 17:39:58.868909 28372 solver.cpp:244]     Train net output #0: loss = 0.642274 (* 1 = 0.642274 loss)
I1130 17:39:58.868916 28372 sgd_solver.cpp:106] Iteration 22350, lr = 1e-07
I1130 17:40:04.625440 28372 solver.cpp:337] Iteration 22400, Testing net (#0)
I1130 17:40:06.770256 28372 blocking_queue.cpp:50] Data layer prefetch queue empty
I1130 17:40:12.560971 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641667
I1130 17:40:12.561033 28372 solver.cpp:404]     Test net output #1: loss = 0.623398 (* 1 = 0.623398 loss)
I1130 17:40:12.587867 28372 solver.cpp:228] Iteration 22400, loss = 0.623669
I1130 17:40:12.587919 28372 solver.cpp:244]     Train net output #0: loss = 0.623669 (* 1 = 0.623669 loss)
I1130 17:40:12.587932 28372 sgd_solver.cpp:106] Iteration 22400, lr = 1e-07
I1130 17:40:16.557061 28372 solver.cpp:228] Iteration 22450, loss = 0.591554
I1130 17:40:16.557124 28372 solver.cpp:244]     Train net output #0: loss = 0.591554 (* 1 = 0.591554 loss)
I1130 17:40:16.557132 28372 sgd_solver.cpp:106] Iteration 22450, lr = 1e-07
I1130 17:40:20.588359 28372 solver.cpp:228] Iteration 22500, loss = 0.556575
I1130 17:40:20.671363 28372 solver.cpp:244]     Train net output #0: loss = 0.556575 (* 1 = 0.556575 loss)
I1130 17:40:20.671402 28372 sgd_solver.cpp:106] Iteration 22500, lr = 1e-07
I1130 17:40:25.471716 28372 solver.cpp:228] Iteration 22550, loss = 0.625492
I1130 17:40:25.471791 28372 solver.cpp:244]     Train net output #0: loss = 0.625492 (* 1 = 0.625492 loss)
I1130 17:40:25.471801 28372 sgd_solver.cpp:106] Iteration 22550, lr = 1e-07
I1130 17:40:29.465962 28372 solver.cpp:337] Iteration 22600, Testing net (#0)
I1130 17:40:39.114027 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641602
I1130 17:40:39.114075 28372 solver.cpp:404]     Test net output #1: loss = 0.623905 (* 1 = 0.623905 loss)
I1130 17:40:39.143579 28372 solver.cpp:228] Iteration 22600, loss = 0.696569
I1130 17:40:39.143625 28372 solver.cpp:244]     Train net output #0: loss = 0.696569 (* 1 = 0.696569 loss)
I1130 17:40:39.143636 28372 sgd_solver.cpp:106] Iteration 22600, lr = 1e-07
I1130 17:40:43.279214 28372 solver.cpp:228] Iteration 22650, loss = 0.529776
I1130 17:40:43.279265 28372 solver.cpp:244]     Train net output #0: loss = 0.529776 (* 1 = 0.529776 loss)
I1130 17:40:43.279274 28372 sgd_solver.cpp:106] Iteration 22650, lr = 1e-07
I1130 17:40:49.261353 28372 solver.cpp:228] Iteration 22700, loss = 0.560098
I1130 17:40:49.261414 28372 solver.cpp:244]     Train net output #0: loss = 0.560098 (* 1 = 0.560098 loss)
I1130 17:40:49.261423 28372 sgd_solver.cpp:106] Iteration 22700, lr = 1e-07
I1130 17:40:54.559564 28372 solver.cpp:228] Iteration 22750, loss = 0.649012
I1130 17:40:58.542920 28372 solver.cpp:244]     Train net output #0: loss = 0.649012 (* 1 = 0.649012 loss)
I1130 17:40:58.542950 28372 sgd_solver.cpp:106] Iteration 22750, lr = 1e-07
I1130 17:41:02.191582 28372 solver.cpp:337] Iteration 22800, Testing net (#0)
I1130 17:41:10.022709 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641927
I1130 17:41:10.022773 28372 solver.cpp:404]     Test net output #1: loss = 0.623113 (* 1 = 0.623113 loss)
I1130 17:41:10.050577 28372 solver.cpp:228] Iteration 22800, loss = 0.575046
I1130 17:41:10.050635 28372 solver.cpp:244]     Train net output #0: loss = 0.575046 (* 1 = 0.575046 loss)
I1130 17:41:10.050647 28372 sgd_solver.cpp:106] Iteration 22800, lr = 1e-07
I1130 17:41:13.909987 28372 solver.cpp:228] Iteration 22850, loss = 0.563534
I1130 17:41:13.910045 28372 solver.cpp:244]     Train net output #0: loss = 0.563534 (* 1 = 0.563534 loss)
I1130 17:41:13.910053 28372 sgd_solver.cpp:106] Iteration 22850, lr = 1e-07
I1130 17:41:18.019091 28372 solver.cpp:228] Iteration 22900, loss = 0.551688
I1130 17:41:18.019178 28372 solver.cpp:244]     Train net output #0: loss = 0.551688 (* 1 = 0.551688 loss)
I1130 17:41:18.019187 28372 sgd_solver.cpp:106] Iteration 22900, lr = 1e-07
I1130 17:41:22.136330 28372 solver.cpp:228] Iteration 22950, loss = 0.532092
I1130 17:41:22.136381 28372 solver.cpp:244]     Train net output #0: loss = 0.532092 (* 1 = 0.532092 loss)
I1130 17:41:22.136390 28372 sgd_solver.cpp:106] Iteration 22950, lr = 1e-07
I1130 17:41:27.924069 28372 solver.cpp:337] Iteration 23000, Testing net (#0)
I1130 17:41:36.287619 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641602
I1130 17:41:36.287678 28372 solver.cpp:404]     Test net output #1: loss = 0.623465 (* 1 = 0.623465 loss)
I1130 17:41:36.341051 28372 solver.cpp:228] Iteration 23000, loss = 0.537334
I1130 17:41:36.341104 28372 solver.cpp:244]     Train net output #0: loss = 0.537334 (* 1 = 0.537334 loss)
I1130 17:41:36.341116 28372 sgd_solver.cpp:106] Iteration 23000, lr = 1e-07
I1130 17:41:41.602578 28372 solver.cpp:228] Iteration 23050, loss = 0.574862
I1130 17:41:41.602643 28372 solver.cpp:244]     Train net output #0: loss = 0.574862 (* 1 = 0.574862 loss)
I1130 17:41:41.602651 28372 sgd_solver.cpp:106] Iteration 23050, lr = 1e-07
I1130 17:41:47.136528 28372 solver.cpp:228] Iteration 23100, loss = 0.560319
I1130 17:41:47.136598 28372 solver.cpp:244]     Train net output #0: loss = 0.560319 (* 1 = 0.560319 loss)
I1130 17:41:47.136607 28372 sgd_solver.cpp:106] Iteration 23100, lr = 1e-07
I1130 17:41:52.550266 28372 solver.cpp:228] Iteration 23150, loss = 0.575189
I1130 17:41:52.550328 28372 solver.cpp:244]     Train net output #0: loss = 0.575189 (* 1 = 0.575189 loss)
I1130 17:41:52.550336 28372 sgd_solver.cpp:106] Iteration 23150, lr = 1e-07
I1130 17:41:57.084561 28372 solver.cpp:337] Iteration 23200, Testing net (#0)
I1130 17:42:06.760082 28372 solver.cpp:404]     Test net output #0: accuracy = 0.640885
I1130 17:42:10.543002 28372 solver.cpp:404]     Test net output #1: loss = 0.623716 (* 1 = 0.623716 loss)
I1130 17:42:10.579619 28372 solver.cpp:228] Iteration 23200, loss = 0.549253
I1130 17:42:10.579699 28372 solver.cpp:244]     Train net output #0: loss = 0.549253 (* 1 = 0.549253 loss)
I1130 17:42:10.579720 28372 sgd_solver.cpp:106] Iteration 23200, lr = 1e-07
I1130 17:42:14.355545 28372 solver.cpp:228] Iteration 23250, loss = 0.579195
I1130 17:42:14.355609 28372 solver.cpp:244]     Train net output #0: loss = 0.579195 (* 1 = 0.579195 loss)
I1130 17:42:14.355618 28372 sgd_solver.cpp:106] Iteration 23250, lr = 1e-07
I1130 17:42:19.915242 28372 solver.cpp:228] Iteration 23300, loss = 0.607776
I1130 17:42:19.915293 28372 solver.cpp:244]     Train net output #0: loss = 0.607776 (* 1 = 0.607776 loss)
I1130 17:42:19.915302 28372 sgd_solver.cpp:106] Iteration 23300, lr = 1e-07
I1130 17:42:25.423588 28372 solver.cpp:228] Iteration 23350, loss = 0.547936
I1130 17:42:25.423636 28372 solver.cpp:244]     Train net output #0: loss = 0.547936 (* 1 = 0.547936 loss)
I1130 17:42:25.423645 28372 sgd_solver.cpp:106] Iteration 23350, lr = 1e-07
I1130 17:42:30.481732 28372 solver.cpp:337] Iteration 23400, Testing net (#0)
I1130 17:42:40.039351 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641211
I1130 17:42:42.542940 28372 solver.cpp:404]     Test net output #1: loss = 0.62382 (* 1 = 0.62382 loss)
I1130 17:42:42.588850 28372 solver.cpp:228] Iteration 23400, loss = 0.556437
I1130 17:42:42.588917 28372 solver.cpp:244]     Train net output #0: loss = 0.556437 (* 1 = 0.556437 loss)
I1130 17:42:42.588935 28372 sgd_solver.cpp:106] Iteration 23400, lr = 1e-07
I1130 17:42:48.463659 28372 solver.cpp:228] Iteration 23450, loss = 0.649682
I1130 17:42:48.463714 28372 solver.cpp:244]     Train net output #0: loss = 0.649682 (* 1 = 0.649682 loss)
I1130 17:42:48.463722 28372 sgd_solver.cpp:106] Iteration 23450, lr = 1e-07
I1130 17:42:53.932034 28372 solver.cpp:228] Iteration 23500, loss = 0.674272
I1130 17:42:53.932085 28372 solver.cpp:244]     Train net output #0: loss = 0.674272 (* 1 = 0.674272 loss)
I1130 17:42:53.932092 28372 sgd_solver.cpp:106] Iteration 23500, lr = 1e-07
I1130 17:42:59.388085 28372 solver.cpp:228] Iteration 23550, loss = 0.555383
I1130 17:42:59.388149 28372 solver.cpp:244]     Train net output #0: loss = 0.555383 (* 1 = 0.555383 loss)
I1130 17:42:59.388157 28372 sgd_solver.cpp:106] Iteration 23550, lr = 1e-07
I1130 17:43:04.773253 28372 solver.cpp:337] Iteration 23600, Testing net (#0)
I1130 17:43:06.108302 28372 blocking_queue.cpp:50] Data layer prefetch queue empty
I1130 17:43:14.993399 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641081
I1130 17:43:18.542918 28372 solver.cpp:404]     Test net output #1: loss = 0.62409 (* 1 = 0.62409 loss)
I1130 17:43:18.570989 28372 solver.cpp:228] Iteration 23600, loss = 0.486178
I1130 17:43:18.571053 28372 solver.cpp:244]     Train net output #0: loss = 0.486178 (* 1 = 0.486178 loss)
I1130 17:43:18.571074 28372 sgd_solver.cpp:106] Iteration 23600, lr = 1e-07
I1130 17:43:23.368278 28372 solver.cpp:228] Iteration 23650, loss = 0.660252
I1130 17:43:23.368335 28372 solver.cpp:244]     Train net output #0: loss = 0.660252 (* 1 = 0.660252 loss)
I1130 17:43:23.368343 28372 sgd_solver.cpp:106] Iteration 23650, lr = 1e-07
I1130 17:43:29.491946 28372 solver.cpp:228] Iteration 23700, loss = 0.563806
I1130 17:43:29.492017 28372 solver.cpp:244]     Train net output #0: loss = 0.563806 (* 1 = 0.563806 loss)
I1130 17:43:29.492039 28372 sgd_solver.cpp:106] Iteration 23700, lr = 1e-07
I1130 17:43:34.706961 28372 solver.cpp:228] Iteration 23750, loss = 0.528257
I1130 17:43:34.707010 28372 solver.cpp:244]     Train net output #0: loss = 0.528257 (* 1 = 0.528257 loss)
I1130 17:43:34.707018 28372 sgd_solver.cpp:106] Iteration 23750, lr = 1e-07
I1130 17:43:40.883019 28372 solver.cpp:337] Iteration 23800, Testing net (#0)
I1130 17:43:50.458324 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641602
I1130 17:43:50.491717 28372 solver.cpp:404]     Test net output #1: loss = 0.623999 (* 1 = 0.623999 loss)
I1130 17:43:50.520961 28372 solver.cpp:228] Iteration 23800, loss = 0.516286
I1130 17:43:50.521020 28372 solver.cpp:244]     Train net output #0: loss = 0.516286 (* 1 = 0.516286 loss)
I1130 17:43:50.521039 28372 sgd_solver.cpp:106] Iteration 23800, lr = 1e-07
I1130 17:43:54.422091 28372 solver.cpp:228] Iteration 23850, loss = 0.599048
I1130 17:43:54.422149 28372 solver.cpp:244]     Train net output #0: loss = 0.599048 (* 1 = 0.599048 loss)
I1130 17:43:54.422158 28372 sgd_solver.cpp:106] Iteration 23850, lr = 1e-07
I1130 17:43:59.563136 28372 solver.cpp:228] Iteration 23900, loss = 0.557166
I1130 17:43:59.563199 28372 solver.cpp:244]     Train net output #0: loss = 0.557166 (* 1 = 0.557166 loss)
I1130 17:43:59.563206 28372 sgd_solver.cpp:106] Iteration 23900, lr = 1e-07
I1130 17:44:04.054889 28372 solver.cpp:228] Iteration 23950, loss = 0.710347
I1130 17:44:04.054949 28372 solver.cpp:244]     Train net output #0: loss = 0.710347 (* 1 = 0.710347 loss)
I1130 17:44:04.054957 28372 sgd_solver.cpp:106] Iteration 23950, lr = 1e-07
I1130 17:44:09.271178 28372 solver.cpp:337] Iteration 24000, Testing net (#0)
I1130 17:44:17.840903 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641211
I1130 17:44:17.840963 28372 solver.cpp:404]     Test net output #1: loss = 0.624112 (* 1 = 0.624112 loss)
I1130 17:44:17.887852 28372 solver.cpp:228] Iteration 24000, loss = 0.680964
I1130 17:44:17.887909 28372 solver.cpp:244]     Train net output #0: loss = 0.680964 (* 1 = 0.680964 loss)
I1130 17:44:17.887923 28372 sgd_solver.cpp:106] Iteration 24000, lr = 1e-07
I1130 17:44:22.089838 28372 solver.cpp:228] Iteration 24050, loss = 0.670085
I1130 17:44:22.542958 28372 solver.cpp:244]     Train net output #0: loss = 0.670085 (* 1 = 0.670085 loss)
I1130 17:44:22.542989 28372 sgd_solver.cpp:106] Iteration 24050, lr = 1e-07
I1130 17:44:26.429446 28372 solver.cpp:228] Iteration 24100, loss = 0.57512
I1130 17:44:26.429505 28372 solver.cpp:244]     Train net output #0: loss = 0.57512 (* 1 = 0.57512 loss)
I1130 17:44:26.429515 28372 sgd_solver.cpp:106] Iteration 24100, lr = 1e-07
I1130 17:44:30.465811 28372 solver.cpp:228] Iteration 24150, loss = 0.549476
I1130 17:44:30.465854 28372 solver.cpp:244]     Train net output #0: loss = 0.549476 (* 1 = 0.549476 loss)
I1130 17:44:30.465863 28372 sgd_solver.cpp:106] Iteration 24150, lr = 1e-07
I1130 17:44:36.503319 28372 solver.cpp:337] Iteration 24200, Testing net (#0)
I1130 17:44:45.272020 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641667
I1130 17:44:45.272080 28372 solver.cpp:404]     Test net output #1: loss = 0.624037 (* 1 = 0.624037 loss)
I1130 17:44:45.298352 28372 solver.cpp:228] Iteration 24200, loss = 0.545341
I1130 17:44:45.298394 28372 solver.cpp:244]     Train net output #0: loss = 0.545341 (* 1 = 0.545341 loss)
I1130 17:44:45.298409 28372 sgd_solver.cpp:106] Iteration 24200, lr = 1e-07
I1130 17:44:49.276914 28372 solver.cpp:228] Iteration 24250, loss = 0.559578
I1130 17:44:49.276969 28372 solver.cpp:244]     Train net output #0: loss = 0.559578 (* 1 = 0.559578 loss)
I1130 17:44:49.276989 28372 sgd_solver.cpp:106] Iteration 24250, lr = 1e-07
I1130 17:44:53.731294 28372 solver.cpp:228] Iteration 24300, loss = 0.608094
I1130 17:44:54.542667 28372 solver.cpp:244]     Train net output #0: loss = 0.608094 (* 1 = 0.608094 loss)
I1130 17:44:54.542698 28372 sgd_solver.cpp:106] Iteration 24300, lr = 1e-07
I1130 17:44:58.544004 28372 solver.cpp:228] Iteration 24350, loss = 0.623565
I1130 17:44:58.544066 28372 solver.cpp:244]     Train net output #0: loss = 0.623565 (* 1 = 0.623565 loss)
I1130 17:44:58.544075 28372 sgd_solver.cpp:106] Iteration 24350, lr = 1e-07
I1130 17:45:04.452630 28372 solver.cpp:337] Iteration 24400, Testing net (#0)
I1130 17:45:14.251399 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641341
I1130 17:45:14.251448 28372 solver.cpp:404]     Test net output #1: loss = 0.623567 (* 1 = 0.623567 loss)
I1130 17:45:14.296877 28372 solver.cpp:228] Iteration 24400, loss = 0.636455
I1130 17:45:14.296921 28372 solver.cpp:244]     Train net output #0: loss = 0.636455 (* 1 = 0.636455 loss)
I1130 17:45:14.296932 28372 sgd_solver.cpp:106] Iteration 24400, lr = 1e-07
I1130 17:45:19.992640 28372 solver.cpp:228] Iteration 24450, loss = 0.677808
I1130 17:45:19.992683 28372 solver.cpp:244]     Train net output #0: loss = 0.677808 (* 1 = 0.677808 loss)
I1130 17:45:19.992692 28372 sgd_solver.cpp:106] Iteration 24450, lr = 1e-07
I1130 17:45:25.147871 28372 solver.cpp:228] Iteration 24500, loss = 0.625144
I1130 17:45:25.190337 28372 solver.cpp:244]     Train net output #0: loss = 0.625144 (* 1 = 0.625144 loss)
I1130 17:45:25.190361 28372 sgd_solver.cpp:106] Iteration 24500, lr = 1e-07
I1130 17:45:29.489939 28372 solver.cpp:228] Iteration 24550, loss = 0.633211
I1130 17:45:29.490006 28372 solver.cpp:244]     Train net output #0: loss = 0.633211 (* 1 = 0.633211 loss)
I1130 17:45:29.490015 28372 sgd_solver.cpp:106] Iteration 24550, lr = 1e-07
I1130 17:45:34.574079 28372 solver.cpp:337] Iteration 24600, Testing net (#0)
I1130 17:45:44.422194 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641211
I1130 17:45:44.422250 28372 solver.cpp:404]     Test net output #1: loss = 0.624027 (* 1 = 0.624027 loss)
I1130 17:45:44.463299 28372 solver.cpp:228] Iteration 24600, loss = 0.600543
I1130 17:45:44.463345 28372 solver.cpp:244]     Train net output #0: loss = 0.600543 (* 1 = 0.600543 loss)
I1130 17:45:44.463356 28372 sgd_solver.cpp:106] Iteration 24600, lr = 1e-07
I1130 17:45:50.330560 28372 solver.cpp:228] Iteration 24650, loss = 0.550845
I1130 17:45:50.330611 28372 solver.cpp:244]     Train net output #0: loss = 0.550845 (* 1 = 0.550845 loss)
I1130 17:45:50.330621 28372 sgd_solver.cpp:106] Iteration 24650, lr = 1e-07
I1130 17:45:54.342222 28372 solver.cpp:228] Iteration 24700, loss = 0.65545
I1130 17:45:54.342279 28372 solver.cpp:244]     Train net output #0: loss = 0.65545 (* 1 = 0.65545 loss)
I1130 17:45:54.342288 28372 sgd_solver.cpp:106] Iteration 24700, lr = 1e-07
I1130 17:45:58.403095 28372 solver.cpp:228] Iteration 24750, loss = 0.600532
I1130 17:45:58.542956 28372 solver.cpp:244]     Train net output #0: loss = 0.600532 (* 1 = 0.600532 loss)
I1130 17:45:58.542982 28372 sgd_solver.cpp:106] Iteration 24750, lr = 1e-07
I1130 17:46:02.527804 28372 solver.cpp:337] Iteration 24800, Testing net (#0)
I1130 17:46:07.567178 28372 blocking_queue.cpp:50] Data layer prefetch queue empty
I1130 17:46:10.097267 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641276
I1130 17:46:10.097328 28372 solver.cpp:404]     Test net output #1: loss = 0.623962 (* 1 = 0.623962 loss)
I1130 17:46:10.128021 28372 solver.cpp:228] Iteration 24800, loss = 0.597588
I1130 17:46:10.128078 28372 solver.cpp:244]     Train net output #0: loss = 0.597588 (* 1 = 0.597588 loss)
I1130 17:46:10.128090 28372 sgd_solver.cpp:106] Iteration 24800, lr = 1e-07
I1130 17:46:15.193764 28372 solver.cpp:228] Iteration 24850, loss = 0.682887
I1130 17:46:15.193828 28372 solver.cpp:244]     Train net output #0: loss = 0.682887 (* 1 = 0.682887 loss)
I1130 17:46:15.193837 28372 sgd_solver.cpp:106] Iteration 24850, lr = 1e-07
I1130 17:46:20.390331 28372 solver.cpp:228] Iteration 24900, loss = 0.617904
I1130 17:46:20.390399 28372 solver.cpp:244]     Train net output #0: loss = 0.617904 (* 1 = 0.617904 loss)
I1130 17:46:20.390408 28372 sgd_solver.cpp:106] Iteration 24900, lr = 1e-07
I1130 17:46:24.967732 28372 solver.cpp:228] Iteration 24950, loss = 0.57133
I1130 17:46:24.967787 28372 solver.cpp:244]     Train net output #0: loss = 0.57133 (* 1 = 0.57133 loss)
I1130 17:46:24.967794 28372 sgd_solver.cpp:106] Iteration 24950, lr = 1e-07
I1130 17:46:28.864166 28372 solver.cpp:337] Iteration 25000, Testing net (#0)
I1130 17:46:36.681638 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641667
I1130 17:46:36.681702 28372 solver.cpp:404]     Test net output #1: loss = 0.623796 (* 1 = 0.623796 loss)
I1130 17:46:36.715958 28372 solver.cpp:228] Iteration 25000, loss = 0.559358
I1130 17:46:36.716013 28372 solver.cpp:244]     Train net output #0: loss = 0.559358 (* 1 = 0.559358 loss)
I1130 17:46:36.716024 28372 sgd_solver.cpp:106] Iteration 25000, lr = 1e-08
I1130 17:46:41.637375 28372 solver.cpp:228] Iteration 25050, loss = 0.50174
I1130 17:46:41.637441 28372 solver.cpp:244]     Train net output #0: loss = 0.50174 (* 1 = 0.50174 loss)
I1130 17:46:41.637450 28372 sgd_solver.cpp:106] Iteration 25050, lr = 1e-08
I1130 17:46:47.314563 28372 solver.cpp:228] Iteration 25100, loss = 0.560531
I1130 17:46:47.314607 28372 solver.cpp:244]     Train net output #0: loss = 0.560531 (* 1 = 0.560531 loss)
I1130 17:46:47.314616 28372 sgd_solver.cpp:106] Iteration 25100, lr = 1e-08
I1130 17:46:52.967187 28372 solver.cpp:228] Iteration 25150, loss = 0.59434
I1130 17:46:52.967236 28372 solver.cpp:244]     Train net output #0: loss = 0.59434 (* 1 = 0.59434 loss)
I1130 17:46:52.967247 28372 sgd_solver.cpp:106] Iteration 25150, lr = 1e-08
I1130 17:46:57.416677 28372 solver.cpp:337] Iteration 25200, Testing net (#0)
I1130 17:47:04.930145 28372 solver.cpp:404]     Test net output #0: accuracy = 0.642187
I1130 17:47:04.930853 28372 solver.cpp:404]     Test net output #1: loss = 0.623188 (* 1 = 0.623188 loss)
I1130 17:47:04.961995 28372 solver.cpp:228] Iteration 25200, loss = 0.510489
I1130 17:47:04.962035 28372 solver.cpp:244]     Train net output #0: loss = 0.510489 (* 1 = 0.510489 loss)
I1130 17:47:04.962054 28372 sgd_solver.cpp:106] Iteration 25200, lr = 1e-08
I1130 17:47:09.304821 28372 solver.cpp:228] Iteration 25250, loss = 0.541308
I1130 17:47:09.304879 28372 solver.cpp:244]     Train net output #0: loss = 0.541308 (* 1 = 0.541308 loss)
I1130 17:47:09.304889 28372 sgd_solver.cpp:106] Iteration 25250, lr = 1e-08
I1130 17:47:14.375236 28372 solver.cpp:228] Iteration 25300, loss = 0.614894
I1130 17:47:14.375304 28372 solver.cpp:244]     Train net output #0: loss = 0.614894 (* 1 = 0.614894 loss)
I1130 17:47:14.375313 28372 sgd_solver.cpp:106] Iteration 25300, lr = 1e-08
I1130 17:47:19.451510 28372 solver.cpp:228] Iteration 25350, loss = 0.623781
I1130 17:47:19.451568 28372 solver.cpp:244]     Train net output #0: loss = 0.623781 (* 1 = 0.623781 loss)
I1130 17:47:19.451575 28372 sgd_solver.cpp:106] Iteration 25350, lr = 1e-08
I1130 17:47:23.311072 28372 solver.cpp:337] Iteration 25400, Testing net (#0)
I1130 17:47:32.945865 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641667
I1130 17:47:32.945925 28372 solver.cpp:404]     Test net output #1: loss = 0.623314 (* 1 = 0.623314 loss)
I1130 17:47:32.971702 28372 solver.cpp:228] Iteration 25400, loss = 0.620776
I1130 17:47:32.971745 28372 solver.cpp:244]     Train net output #0: loss = 0.620776 (* 1 = 0.620776 loss)
I1130 17:47:32.971755 28372 sgd_solver.cpp:106] Iteration 25400, lr = 1e-08
I1130 17:47:37.305835 28372 solver.cpp:228] Iteration 25450, loss = 0.659208
I1130 17:47:37.306083 28372 solver.cpp:244]     Train net output #0: loss = 0.659208 (* 1 = 0.659208 loss)
I1130 17:47:37.306118 28372 sgd_solver.cpp:106] Iteration 25450, lr = 1e-08
I1130 17:47:42.093122 28372 solver.cpp:228] Iteration 25500, loss = 0.566479
I1130 17:47:42.093174 28372 solver.cpp:244]     Train net output #0: loss = 0.566479 (* 1 = 0.566479 loss)
I1130 17:47:42.093183 28372 sgd_solver.cpp:106] Iteration 25500, lr = 1e-08
I1130 17:47:46.122683 28372 solver.cpp:228] Iteration 25550, loss = 0.566058
I1130 17:47:46.122741 28372 solver.cpp:244]     Train net output #0: loss = 0.566058 (* 1 = 0.566058 loss)
I1130 17:47:46.122748 28372 sgd_solver.cpp:106] Iteration 25550, lr = 1e-08
I1130 17:47:50.586601 28372 solver.cpp:337] Iteration 25600, Testing net (#0)
I1130 17:48:00.111232 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641016
I1130 17:48:00.111289 28372 solver.cpp:404]     Test net output #1: loss = 0.624273 (* 1 = 0.624273 loss)
I1130 17:48:00.139956 28372 solver.cpp:228] Iteration 25600, loss = 0.607652
I1130 17:48:00.139999 28372 solver.cpp:244]     Train net output #0: loss = 0.607652 (* 1 = 0.607652 loss)
I1130 17:48:00.140012 28372 sgd_solver.cpp:106] Iteration 25600, lr = 1e-08
I1130 17:48:05.058195 28372 solver.cpp:228] Iteration 25650, loss = 0.588887
I1130 17:48:05.058256 28372 solver.cpp:244]     Train net output #0: loss = 0.588887 (* 1 = 0.588887 loss)
I1130 17:48:05.058267 28372 sgd_solver.cpp:106] Iteration 25650, lr = 1e-08
I1130 17:48:10.727620 28372 solver.cpp:228] Iteration 25700, loss = 0.57385
I1130 17:48:10.747830 28372 solver.cpp:244]     Train net output #0: loss = 0.57385 (* 1 = 0.57385 loss)
I1130 17:48:10.747854 28372 sgd_solver.cpp:106] Iteration 25700, lr = 1e-08
I1130 17:48:16.015626 28372 solver.cpp:228] Iteration 25750, loss = 0.603999
I1130 17:48:16.015682 28372 solver.cpp:244]     Train net output #0: loss = 0.603999 (* 1 = 0.603999 loss)
I1130 17:48:16.015689 28372 sgd_solver.cpp:106] Iteration 25750, lr = 1e-08
I1130 17:48:21.337013 28372 solver.cpp:337] Iteration 25800, Testing net (#0)
I1130 17:48:27.962666 28372 blocking_queue.cpp:50] Data layer prefetch queue empty
I1130 17:48:29.338430 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641862
I1130 17:48:29.338481 28372 solver.cpp:404]     Test net output #1: loss = 0.623624 (* 1 = 0.623624 loss)
I1130 17:48:29.368279 28372 solver.cpp:228] Iteration 25800, loss = 0.589625
I1130 17:48:29.368316 28372 solver.cpp:244]     Train net output #0: loss = 0.589625 (* 1 = 0.589625 loss)
I1130 17:48:29.368327 28372 sgd_solver.cpp:106] Iteration 25800, lr = 1e-08
I1130 17:48:34.780530 28372 solver.cpp:228] Iteration 25850, loss = 0.582631
I1130 17:48:34.780580 28372 solver.cpp:244]     Train net output #0: loss = 0.582631 (* 1 = 0.582631 loss)
I1130 17:48:34.780588 28372 sgd_solver.cpp:106] Iteration 25850, lr = 1e-08
I1130 17:48:39.781132 28372 solver.cpp:228] Iteration 25900, loss = 0.530821
I1130 17:48:39.781208 28372 solver.cpp:244]     Train net output #0: loss = 0.530821 (* 1 = 0.530821 loss)
I1130 17:48:39.781222 28372 sgd_solver.cpp:106] Iteration 25900, lr = 1e-08
I1130 17:48:45.298429 28372 solver.cpp:228] Iteration 25950, loss = 0.623848
I1130 17:48:45.298665 28372 solver.cpp:244]     Train net output #0: loss = 0.623848 (* 1 = 0.623848 loss)
I1130 17:48:45.298699 28372 sgd_solver.cpp:106] Iteration 25950, lr = 1e-08
I1130 17:48:50.643596 28372 solver.cpp:337] Iteration 26000, Testing net (#0)
I1130 17:49:00.942142 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641667
I1130 17:49:00.942203 28372 solver.cpp:404]     Test net output #1: loss = 0.623638 (* 1 = 0.623638 loss)
I1130 17:49:00.971580 28372 solver.cpp:228] Iteration 26000, loss = 0.638392
I1130 17:49:00.971623 28372 solver.cpp:244]     Train net output #0: loss = 0.638392 (* 1 = 0.638392 loss)
I1130 17:49:00.971633 28372 sgd_solver.cpp:106] Iteration 26000, lr = 1e-08
I1130 17:49:05.401131 28372 solver.cpp:228] Iteration 26050, loss = 0.652689
I1130 17:49:05.401196 28372 solver.cpp:244]     Train net output #0: loss = 0.652689 (* 1 = 0.652689 loss)
I1130 17:49:05.401206 28372 sgd_solver.cpp:106] Iteration 26050, lr = 1e-08
I1130 17:49:10.969211 28372 solver.cpp:228] Iteration 26100, loss = 0.63439
I1130 17:49:10.969264 28372 solver.cpp:244]     Train net output #0: loss = 0.63439 (* 1 = 0.63439 loss)
I1130 17:49:10.969272 28372 sgd_solver.cpp:106] Iteration 26100, lr = 1e-08
I1130 17:49:14.929013 28372 solver.cpp:228] Iteration 26150, loss = 0.483461
I1130 17:49:14.929057 28372 solver.cpp:244]     Train net output #0: loss = 0.483461 (* 1 = 0.483461 loss)
I1130 17:49:14.929066 28372 sgd_solver.cpp:106] Iteration 26150, lr = 1e-08
I1130 17:49:19.981514 28372 solver.cpp:337] Iteration 26200, Testing net (#0)
I1130 17:49:28.528967 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641602
I1130 17:49:28.529026 28372 solver.cpp:404]     Test net output #1: loss = 0.623801 (* 1 = 0.623801 loss)
I1130 17:49:28.569855 28372 solver.cpp:228] Iteration 26200, loss = 0.548594
I1130 17:49:28.569939 28372 solver.cpp:244]     Train net output #0: loss = 0.548594 (* 1 = 0.548594 loss)
I1130 17:49:28.569962 28372 sgd_solver.cpp:106] Iteration 26200, lr = 1e-08
I1130 17:49:32.799253 28372 solver.cpp:228] Iteration 26250, loss = 0.598756
I1130 17:49:32.799314 28372 solver.cpp:244]     Train net output #0: loss = 0.598756 (* 1 = 0.598756 loss)
I1130 17:49:32.799334 28372 sgd_solver.cpp:106] Iteration 26250, lr = 1e-08
I1130 17:49:37.411692 28372 solver.cpp:228] Iteration 26300, loss = 0.563596
I1130 17:49:37.411754 28372 solver.cpp:244]     Train net output #0: loss = 0.563596 (* 1 = 0.563596 loss)
I1130 17:49:37.411762 28372 sgd_solver.cpp:106] Iteration 26300, lr = 1e-08
I1130 17:49:43.743768 28372 solver.cpp:228] Iteration 26350, loss = 0.634882
I1130 17:49:43.743816 28372 solver.cpp:244]     Train net output #0: loss = 0.634882 (* 1 = 0.634882 loss)
I1130 17:49:43.743824 28372 sgd_solver.cpp:106] Iteration 26350, lr = 1e-08
I1130 17:49:48.142607 28372 solver.cpp:337] Iteration 26400, Testing net (#0)
I1130 17:49:55.830577 28372 solver.cpp:404]     Test net output #0: accuracy = 0.640625
I1130 17:49:57.782960 28372 solver.cpp:404]     Test net output #1: loss = 0.624429 (* 1 = 0.624429 loss)
I1130 17:49:57.822548 28372 solver.cpp:228] Iteration 26400, loss = 0.559456
I1130 17:49:57.822633 28372 solver.cpp:244]     Train net output #0: loss = 0.559456 (* 1 = 0.559456 loss)
I1130 17:49:57.822659 28372 sgd_solver.cpp:106] Iteration 26400, lr = 1e-08
I1130 17:50:02.607827 28372 solver.cpp:228] Iteration 26450, loss = 0.652306
I1130 17:50:02.607879 28372 solver.cpp:244]     Train net output #0: loss = 0.652306 (* 1 = 0.652306 loss)
I1130 17:50:02.607898 28372 sgd_solver.cpp:106] Iteration 26450, lr = 1e-08
I1130 17:50:07.608490 28372 solver.cpp:228] Iteration 26500, loss = 0.592708
I1130 17:50:07.608558 28372 solver.cpp:244]     Train net output #0: loss = 0.592708 (* 1 = 0.592708 loss)
I1130 17:50:07.608567 28372 sgd_solver.cpp:106] Iteration 26500, lr = 1e-08
I1130 17:50:12.147194 28372 solver.cpp:228] Iteration 26550, loss = 0.585209
I1130 17:50:12.147259 28372 solver.cpp:244]     Train net output #0: loss = 0.585209 (* 1 = 0.585209 loss)
I1130 17:50:12.147267 28372 sgd_solver.cpp:106] Iteration 26550, lr = 1e-08
I1130 17:50:18.508700 28372 solver.cpp:337] Iteration 26600, Testing net (#0)
I1130 17:50:26.158884 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641276
I1130 17:50:26.255472 28372 solver.cpp:404]     Test net output #1: loss = 0.623945 (* 1 = 0.623945 loss)
I1130 17:50:26.281946 28372 solver.cpp:228] Iteration 26600, loss = 0.55551
I1130 17:50:26.282021 28372 solver.cpp:244]     Train net output #0: loss = 0.55551 (* 1 = 0.55551 loss)
I1130 17:50:26.282044 28372 sgd_solver.cpp:106] Iteration 26600, lr = 1e-08
I1130 17:50:30.255404 28372 solver.cpp:228] Iteration 26650, loss = 0.632509
I1130 17:50:30.255467 28372 solver.cpp:244]     Train net output #0: loss = 0.632509 (* 1 = 0.632509 loss)
I1130 17:50:30.255476 28372 sgd_solver.cpp:106] Iteration 26650, lr = 1e-08
I1130 17:50:35.564225 28372 solver.cpp:228] Iteration 26700, loss = 0.6005
I1130 17:50:35.564285 28372 solver.cpp:244]     Train net output #0: loss = 0.6005 (* 1 = 0.6005 loss)
I1130 17:50:35.564303 28372 sgd_solver.cpp:106] Iteration 26700, lr = 1e-08
I1130 17:50:41.784298 28372 solver.cpp:228] Iteration 26750, loss = 0.623262
I1130 17:50:41.784340 28372 solver.cpp:244]     Train net output #0: loss = 0.623262 (* 1 = 0.623262 loss)
I1130 17:50:41.784348 28372 sgd_solver.cpp:106] Iteration 26750, lr = 1e-08
I1130 17:50:47.626533 28372 solver.cpp:337] Iteration 26800, Testing net (#0)
I1130 17:50:55.718741 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641732
I1130 17:50:55.718825 28372 solver.cpp:404]     Test net output #1: loss = 0.623593 (* 1 = 0.623593 loss)
I1130 17:50:55.747597 28372 solver.cpp:228] Iteration 26800, loss = 0.625948
I1130 17:50:55.747660 28372 solver.cpp:244]     Train net output #0: loss = 0.625948 (* 1 = 0.625948 loss)
I1130 17:50:55.747673 28372 sgd_solver.cpp:106] Iteration 26800, lr = 1e-08
I1130 17:51:00.496286 28372 solver.cpp:228] Iteration 26850, loss = 0.543028
I1130 17:51:00.536985 28372 solver.cpp:244]     Train net output #0: loss = 0.543028 (* 1 = 0.543028 loss)
I1130 17:51:00.537012 28372 sgd_solver.cpp:106] Iteration 26850, lr = 1e-08
I1130 17:51:06.424088 28372 solver.cpp:228] Iteration 26900, loss = 0.594633
I1130 17:51:06.424147 28372 solver.cpp:244]     Train net output #0: loss = 0.594633 (* 1 = 0.594633 loss)
I1130 17:51:06.424167 28372 sgd_solver.cpp:106] Iteration 26900, lr = 1e-08
I1130 17:51:11.543216 28372 solver.cpp:228] Iteration 26950, loss = 0.523596
I1130 17:51:11.543278 28372 solver.cpp:244]     Train net output #0: loss = 0.523596 (* 1 = 0.523596 loss)
I1130 17:51:11.543289 28372 sgd_solver.cpp:106] Iteration 26950, lr = 1e-08
I1130 17:51:16.874932 28372 solver.cpp:337] Iteration 27000, Testing net (#0)
I1130 17:51:17.605178 28372 blocking_queue.cpp:50] Data layer prefetch queue empty
I1130 17:51:26.480530 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641602
I1130 17:51:26.480581 28372 solver.cpp:404]     Test net output #1: loss = 0.623538 (* 1 = 0.623538 loss)
I1130 17:51:26.529186 28372 solver.cpp:228] Iteration 27000, loss = 0.610396
I1130 17:51:26.529228 28372 solver.cpp:244]     Train net output #0: loss = 0.610396 (* 1 = 0.610396 loss)
I1130 17:51:26.529239 28372 sgd_solver.cpp:106] Iteration 27000, lr = 1e-08
I1130 17:51:31.782618 28372 solver.cpp:228] Iteration 27050, loss = 0.552587
I1130 17:51:34.542943 28372 solver.cpp:244]     Train net output #0: loss = 0.552587 (* 1 = 0.552587 loss)
I1130 17:51:34.542979 28372 sgd_solver.cpp:106] Iteration 27050, lr = 1e-08
I1130 17:51:40.297907 28372 solver.cpp:228] Iteration 27100, loss = 0.624768
I1130 17:51:40.297958 28372 solver.cpp:244]     Train net output #0: loss = 0.624768 (* 1 = 0.624768 loss)
I1130 17:51:40.297966 28372 sgd_solver.cpp:106] Iteration 27100, lr = 1e-08
I1130 17:51:46.202031 28372 solver.cpp:228] Iteration 27150, loss = 0.615873
I1130 17:51:46.202082 28372 solver.cpp:244]     Train net output #0: loss = 0.615873 (* 1 = 0.615873 loss)
I1130 17:51:46.202091 28372 sgd_solver.cpp:106] Iteration 27150, lr = 1e-08
I1130 17:51:51.700366 28372 solver.cpp:337] Iteration 27200, Testing net (#0)
I1130 17:52:01.754148 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641927
I1130 17:52:01.754197 28372 solver.cpp:404]     Test net output #1: loss = 0.623186 (* 1 = 0.623186 loss)
I1130 17:52:01.783783 28372 solver.cpp:228] Iteration 27200, loss = 0.610713
I1130 17:52:02.542706 28372 solver.cpp:244]     Train net output #0: loss = 0.610713 (* 1 = 0.610713 loss)
I1130 17:52:02.542824 28372 sgd_solver.cpp:106] Iteration 27200, lr = 1e-08
I1130 17:52:07.524907 28372 solver.cpp:228] Iteration 27250, loss = 0.575408
I1130 17:52:07.524974 28372 solver.cpp:244]     Train net output #0: loss = 0.575408 (* 1 = 0.575408 loss)
I1130 17:52:07.524983 28372 sgd_solver.cpp:106] Iteration 27250, lr = 1e-08
I1130 17:52:11.540730 28372 solver.cpp:228] Iteration 27300, loss = 0.497215
I1130 17:52:11.540799 28372 solver.cpp:244]     Train net output #0: loss = 0.497215 (* 1 = 0.497215 loss)
I1130 17:52:11.540808 28372 sgd_solver.cpp:106] Iteration 27300, lr = 1e-08
I1130 17:52:16.400429 28372 solver.cpp:228] Iteration 27350, loss = 0.60891
I1130 17:52:16.400480 28372 solver.cpp:244]     Train net output #0: loss = 0.60891 (* 1 = 0.60891 loss)
I1130 17:52:16.400490 28372 sgd_solver.cpp:106] Iteration 27350, lr = 1e-08
I1130 17:52:22.324473 28372 solver.cpp:337] Iteration 27400, Testing net (#0)
I1130 17:52:31.912305 28372 solver.cpp:404]     Test net output #0: accuracy = 0.64043
I1130 17:52:32.003239 28372 solver.cpp:404]     Test net output #1: loss = 0.624511 (* 1 = 0.624511 loss)
I1130 17:52:32.045862 28372 solver.cpp:228] Iteration 27400, loss = 0.698987
I1130 17:52:32.045917 28372 solver.cpp:244]     Train net output #0: loss = 0.698987 (* 1 = 0.698987 loss)
I1130 17:52:32.045933 28372 sgd_solver.cpp:106] Iteration 27400, lr = 1e-08
I1130 17:52:37.676501 28372 solver.cpp:228] Iteration 27450, loss = 0.602432
I1130 17:52:37.676558 28372 solver.cpp:244]     Train net output #0: loss = 0.602432 (* 1 = 0.602432 loss)
I1130 17:52:37.676565 28372 sgd_solver.cpp:106] Iteration 27450, lr = 1e-08
I1130 17:52:43.558867 28372 solver.cpp:228] Iteration 27500, loss = 0.639874
I1130 17:52:43.558930 28372 solver.cpp:244]     Train net output #0: loss = 0.639874 (* 1 = 0.639874 loss)
I1130 17:52:43.558939 28372 sgd_solver.cpp:106] Iteration 27500, lr = 1e-08
I1130 17:52:48.137639 28372 solver.cpp:228] Iteration 27550, loss = 0.518729
I1130 17:52:48.137702 28372 solver.cpp:244]     Train net output #0: loss = 0.518729 (* 1 = 0.518729 loss)
I1130 17:52:48.137712 28372 sgd_solver.cpp:106] Iteration 27550, lr = 1e-08
I1130 17:52:52.677711 28372 solver.cpp:337] Iteration 27600, Testing net (#0)
I1130 17:53:02.526839 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641211
I1130 17:53:06.542953 28372 solver.cpp:404]     Test net output #1: loss = 0.624045 (* 1 = 0.624045 loss)
I1130 17:53:06.586930 28372 solver.cpp:228] Iteration 27600, loss = 0.639901
I1130 17:53:06.586992 28372 solver.cpp:244]     Train net output #0: loss = 0.639901 (* 1 = 0.639901 loss)
I1130 17:53:06.587009 28372 sgd_solver.cpp:106] Iteration 27600, lr = 1e-08
I1130 17:53:11.238924 28372 solver.cpp:228] Iteration 27650, loss = 0.627812
I1130 17:53:11.238983 28372 solver.cpp:244]     Train net output #0: loss = 0.627812 (* 1 = 0.627812 loss)
I1130 17:53:11.238991 28372 sgd_solver.cpp:106] Iteration 27650, lr = 1e-08
I1130 17:53:15.010992 28372 solver.cpp:228] Iteration 27700, loss = 0.515179
I1130 17:53:15.011061 28372 solver.cpp:244]     Train net output #0: loss = 0.515179 (* 1 = 0.515179 loss)
I1130 17:53:15.011070 28372 sgd_solver.cpp:106] Iteration 27700, lr = 1e-08
I1130 17:53:18.911239 28372 solver.cpp:228] Iteration 27750, loss = 0.591386
I1130 17:53:18.911296 28372 solver.cpp:244]     Train net output #0: loss = 0.591386 (* 1 = 0.591386 loss)
I1130 17:53:18.911304 28372 sgd_solver.cpp:106] Iteration 27750, lr = 1e-08
I1130 17:53:24.187793 28372 solver.cpp:337] Iteration 27800, Testing net (#0)
I1130 17:53:32.767742 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641471
I1130 17:53:33.006855 28372 solver.cpp:404]     Test net output #1: loss = 0.623898 (* 1 = 0.623898 loss)
I1130 17:53:33.032599 28372 solver.cpp:228] Iteration 27800, loss = 0.595773
I1130 17:53:33.032657 28372 solver.cpp:244]     Train net output #0: loss = 0.595773 (* 1 = 0.595773 loss)
I1130 17:53:33.032678 28372 sgd_solver.cpp:106] Iteration 27800, lr = 1e-08
I1130 17:53:37.857725 28372 solver.cpp:228] Iteration 27850, loss = 0.563873
I1130 17:53:37.857775 28372 solver.cpp:244]     Train net output #0: loss = 0.563873 (* 1 = 0.563873 loss)
I1130 17:53:37.857784 28372 sgd_solver.cpp:106] Iteration 27850, lr = 1e-08
I1130 17:53:42.235823 28372 solver.cpp:228] Iteration 27900, loss = 0.603546
I1130 17:53:42.235896 28372 solver.cpp:244]     Train net output #0: loss = 0.603546 (* 1 = 0.603546 loss)
I1130 17:53:42.235904 28372 sgd_solver.cpp:106] Iteration 27900, lr = 1e-08
I1130 17:53:47.763746 28372 solver.cpp:228] Iteration 27950, loss = 0.555495
I1130 17:53:47.763808 28372 solver.cpp:244]     Train net output #0: loss = 0.555495 (* 1 = 0.555495 loss)
I1130 17:53:47.763814 28372 sgd_solver.cpp:106] Iteration 27950, lr = 1e-08
I1130 17:53:53.243315 28372 solver.cpp:337] Iteration 28000, Testing net (#0)
I1130 17:54:02.020118 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641341
I1130 17:54:02.020177 28372 solver.cpp:404]     Test net output #1: loss = 0.624067 (* 1 = 0.624067 loss)
I1130 17:54:02.049986 28372 solver.cpp:228] Iteration 28000, loss = 0.577799
I1130 17:54:02.050040 28372 solver.cpp:244]     Train net output #0: loss = 0.577799 (* 1 = 0.577799 loss)
I1130 17:54:02.050052 28372 sgd_solver.cpp:106] Iteration 28000, lr = 1e-08
I1130 17:54:07.200142 28372 solver.cpp:228] Iteration 28050, loss = 0.554145
I1130 17:54:07.221599 28372 solver.cpp:244]     Train net output #0: loss = 0.554145 (* 1 = 0.554145 loss)
I1130 17:54:07.221608 28372 sgd_solver.cpp:106] Iteration 28050, lr = 1e-08
I1130 17:54:11.566699 28372 solver.cpp:228] Iteration 28100, loss = 0.624195
I1130 17:54:11.566753 28372 solver.cpp:244]     Train net output #0: loss = 0.624195 (* 1 = 0.624195 loss)
I1130 17:54:11.566761 28372 sgd_solver.cpp:106] Iteration 28100, lr = 1e-08
I1130 17:54:15.776202 28372 solver.cpp:228] Iteration 28150, loss = 0.625487
I1130 17:54:15.776263 28372 solver.cpp:244]     Train net output #0: loss = 0.625487 (* 1 = 0.625487 loss)
I1130 17:54:15.776271 28372 sgd_solver.cpp:106] Iteration 28150, lr = 1e-08
I1130 17:54:20.650413 28372 solver.cpp:337] Iteration 28200, Testing net (#0)
I1130 17:54:30.267586 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641536
I1130 17:54:30.267637 28372 solver.cpp:404]     Test net output #1: loss = 0.623632 (* 1 = 0.623632 loss)
I1130 17:54:30.296816 28372 solver.cpp:228] Iteration 28200, loss = 0.60231
I1130 17:54:30.296859 28372 solver.cpp:244]     Train net output #0: loss = 0.60231 (* 1 = 0.60231 loss)
I1130 17:54:30.296869 28372 sgd_solver.cpp:106] Iteration 28200, lr = 1e-08
I1130 17:54:35.663933 28372 solver.cpp:228] Iteration 28250, loss = 0.642608
I1130 17:54:35.663985 28372 solver.cpp:244]     Train net output #0: loss = 0.642608 (* 1 = 0.642608 loss)
I1130 17:54:35.663995 28372 sgd_solver.cpp:106] Iteration 28250, lr = 1e-08
I1130 17:54:40.306790 28372 solver.cpp:228] Iteration 28300, loss = 0.577628
I1130 17:54:40.642277 28372 solver.cpp:244]     Train net output #0: loss = 0.577628 (* 1 = 0.577628 loss)
I1130 17:54:40.642398 28372 sgd_solver.cpp:106] Iteration 28300, lr = 1e-08
I1130 17:54:45.274494 28372 solver.cpp:228] Iteration 28350, loss = 0.689101
I1130 17:54:45.274557 28372 solver.cpp:244]     Train net output #0: loss = 0.689101 (* 1 = 0.689101 loss)
I1130 17:54:45.274566 28372 sgd_solver.cpp:106] Iteration 28350, lr = 1e-08
I1130 17:54:50.462209 28372 solver.cpp:337] Iteration 28400, Testing net (#0)
I1130 17:54:51.700563 28372 blocking_queue.cpp:50] Data layer prefetch queue empty
I1130 17:54:59.681610 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641081
I1130 17:54:59.681677 28372 solver.cpp:404]     Test net output #1: loss = 0.623927 (* 1 = 0.623927 loss)
I1130 17:54:59.711596 28372 solver.cpp:228] Iteration 28400, loss = 0.686474
I1130 17:54:59.711666 28372 solver.cpp:244]     Train net output #0: loss = 0.686474 (* 1 = 0.686474 loss)
I1130 17:54:59.711678 28372 sgd_solver.cpp:106] Iteration 28400, lr = 1e-08
I1130 17:55:04.058838 28372 solver.cpp:228] Iteration 28450, loss = 0.614773
I1130 17:55:04.058893 28372 solver.cpp:244]     Train net output #0: loss = 0.614773 (* 1 = 0.614773 loss)
I1130 17:55:04.058903 28372 sgd_solver.cpp:106] Iteration 28450, lr = 1e-08
I1130 17:55:09.107800 28372 solver.cpp:228] Iteration 28500, loss = 0.60664
I1130 17:55:09.107864 28372 solver.cpp:244]     Train net output #0: loss = 0.60664 (* 1 = 0.60664 loss)
I1130 17:55:09.107872 28372 sgd_solver.cpp:106] Iteration 28500, lr = 1e-08
I1130 17:55:14.914971 28372 solver.cpp:228] Iteration 28550, loss = 0.541987
I1130 17:55:14.915253 28372 solver.cpp:244]     Train net output #0: loss = 0.541987 (* 1 = 0.541987 loss)
I1130 17:55:14.915280 28372 sgd_solver.cpp:106] Iteration 28550, lr = 1e-08
I1130 17:55:18.740420 28372 solver.cpp:337] Iteration 28600, Testing net (#0)
I1130 17:55:26.720144 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641406
I1130 17:55:26.720201 28372 solver.cpp:404]     Test net output #1: loss = 0.62383 (* 1 = 0.62383 loss)
I1130 17:55:26.763509 28372 solver.cpp:228] Iteration 28600, loss = 0.624615
I1130 17:55:26.763576 28372 solver.cpp:244]     Train net output #0: loss = 0.624615 (* 1 = 0.624615 loss)
I1130 17:55:26.763587 28372 sgd_solver.cpp:106] Iteration 28600, lr = 1e-08
I1130 17:55:31.115914 28372 solver.cpp:228] Iteration 28650, loss = 0.615196
I1130 17:55:31.115979 28372 solver.cpp:244]     Train net output #0: loss = 0.615196 (* 1 = 0.615196 loss)
I1130 17:55:31.115989 28372 sgd_solver.cpp:106] Iteration 28650, lr = 1e-08
I1130 17:55:37.108172 28372 solver.cpp:228] Iteration 28700, loss = 0.579002
I1130 17:55:37.108225 28372 solver.cpp:244]     Train net output #0: loss = 0.579002 (* 1 = 0.579002 loss)
I1130 17:55:37.108234 28372 sgd_solver.cpp:106] Iteration 28700, lr = 1e-08
I1130 17:55:42.144536 28372 solver.cpp:228] Iteration 28750, loss = 0.582333
I1130 17:55:42.144588 28372 solver.cpp:244]     Train net output #0: loss = 0.582333 (* 1 = 0.582333 loss)
I1130 17:55:42.144598 28372 sgd_solver.cpp:106] Iteration 28750, lr = 1e-08
I1130 17:55:46.117787 28372 solver.cpp:337] Iteration 28800, Testing net (#0)
I1130 17:55:54.397811 28372 solver.cpp:404]     Test net output #0: accuracy = 0.64043
I1130 17:55:54.397873 28372 solver.cpp:404]     Test net output #1: loss = 0.624453 (* 1 = 0.624453 loss)
I1130 17:55:54.428861 28372 solver.cpp:228] Iteration 28800, loss = 0.557209
I1130 17:55:54.428935 28372 solver.cpp:244]     Train net output #0: loss = 0.557209 (* 1 = 0.557209 loss)
I1130 17:55:54.428953 28372 sgd_solver.cpp:106] Iteration 28800, lr = 1e-08
I1130 17:55:58.367442 28372 solver.cpp:228] Iteration 28850, loss = 0.553912
I1130 17:55:58.367504 28372 solver.cpp:244]     Train net output #0: loss = 0.553912 (* 1 = 0.553912 loss)
I1130 17:55:58.367512 28372 sgd_solver.cpp:106] Iteration 28850, lr = 1e-08
I1130 17:56:02.477718 28372 solver.cpp:228] Iteration 28900, loss = 0.506827
I1130 17:56:02.477799 28372 solver.cpp:244]     Train net output #0: loss = 0.506827 (* 1 = 0.506827 loss)
I1130 17:56:02.477807 28372 sgd_solver.cpp:106] Iteration 28900, lr = 1e-08
I1130 17:56:07.709802 28372 solver.cpp:228] Iteration 28950, loss = 0.582163
I1130 17:56:07.709861 28372 solver.cpp:244]     Train net output #0: loss = 0.582163 (* 1 = 0.582163 loss)
I1130 17:56:07.709877 28372 sgd_solver.cpp:106] Iteration 28950, lr = 1e-08
I1130 17:56:12.377121 28372 solver.cpp:337] Iteration 29000, Testing net (#0)
I1130 17:56:22.604989 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641471
I1130 17:56:26.542966 28372 solver.cpp:404]     Test net output #1: loss = 0.624165 (* 1 = 0.624165 loss)
I1130 17:56:26.583010 28372 solver.cpp:228] Iteration 29000, loss = 0.610143
I1130 17:56:26.583082 28372 solver.cpp:244]     Train net output #0: loss = 0.610143 (* 1 = 0.610143 loss)
I1130 17:56:26.583102 28372 sgd_solver.cpp:106] Iteration 29000, lr = 1e-08
I1130 17:56:30.429872 28372 solver.cpp:228] Iteration 29050, loss = 0.725216
I1130 17:56:30.429934 28372 solver.cpp:244]     Train net output #0: loss = 0.725216 (* 1 = 0.725216 loss)
I1130 17:56:30.429942 28372 sgd_solver.cpp:106] Iteration 29050, lr = 1e-08
I1130 17:56:34.229305 28372 solver.cpp:228] Iteration 29100, loss = 0.588181
I1130 17:56:34.229346 28372 solver.cpp:244]     Train net output #0: loss = 0.588181 (* 1 = 0.588181 loss)
I1130 17:56:34.229349 28372 sgd_solver.cpp:106] Iteration 29100, lr = 1e-08
I1130 17:56:39.222441 28372 solver.cpp:228] Iteration 29150, loss = 0.559265
I1130 17:56:39.222489 28372 solver.cpp:244]     Train net output #0: loss = 0.559265 (* 1 = 0.559265 loss)
I1130 17:56:39.222498 28372 sgd_solver.cpp:106] Iteration 29150, lr = 1e-08
I1130 17:56:44.400893 28372 solver.cpp:337] Iteration 29200, Testing net (#0)
I1130 17:56:53.623491 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641341
I1130 17:56:53.623750 28372 solver.cpp:404]     Test net output #1: loss = 0.623898 (* 1 = 0.623898 loss)
I1130 17:56:53.675088 28372 solver.cpp:228] Iteration 29200, loss = 0.606217
I1130 17:56:53.675148 28372 solver.cpp:244]     Train net output #0: loss = 0.606217 (* 1 = 0.606217 loss)
I1130 17:56:53.675164 28372 sgd_solver.cpp:106] Iteration 29200, lr = 1e-08
I1130 17:56:59.642536 28372 solver.cpp:228] Iteration 29250, loss = 0.493702
I1130 17:56:59.642585 28372 solver.cpp:244]     Train net output #0: loss = 0.493702 (* 1 = 0.493702 loss)
I1130 17:56:59.642591 28372 sgd_solver.cpp:106] Iteration 29250, lr = 1e-08
I1130 17:57:05.164981 28372 solver.cpp:228] Iteration 29300, loss = 0.610822
I1130 17:57:05.165038 28372 solver.cpp:244]     Train net output #0: loss = 0.610822 (* 1 = 0.610822 loss)
I1130 17:57:05.165046 28372 sgd_solver.cpp:106] Iteration 29300, lr = 1e-08
I1130 17:57:10.869534 28372 solver.cpp:228] Iteration 29350, loss = 0.560984
I1130 17:57:10.869593 28372 solver.cpp:244]     Train net output #0: loss = 0.560984 (* 1 = 0.560984 loss)
I1130 17:57:10.869601 28372 sgd_solver.cpp:106] Iteration 29350, lr = 1e-08
I1130 17:57:16.391736 28372 solver.cpp:337] Iteration 29400, Testing net (#0)
I1130 17:57:26.196723 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641341
I1130 17:57:26.542567 28372 solver.cpp:404]     Test net output #1: loss = 0.624173 (* 1 = 0.624173 loss)
I1130 17:57:26.587965 28372 solver.cpp:228] Iteration 29400, loss = 0.675097
I1130 17:57:26.588029 28372 solver.cpp:244]     Train net output #0: loss = 0.675097 (* 1 = 0.675097 loss)
I1130 17:57:26.588047 28372 sgd_solver.cpp:106] Iteration 29400, lr = 1e-08
I1130 17:57:31.800699 28372 solver.cpp:228] Iteration 29450, loss = 0.638345
I1130 17:57:31.800752 28372 solver.cpp:244]     Train net output #0: loss = 0.638345 (* 1 = 0.638345 loss)
I1130 17:57:31.800762 28372 sgd_solver.cpp:106] Iteration 29450, lr = 1e-08
I1130 17:57:37.208408 28372 solver.cpp:228] Iteration 29500, loss = 0.593511
I1130 17:57:37.208472 28372 solver.cpp:244]     Train net output #0: loss = 0.593511 (* 1 = 0.593511 loss)
I1130 17:57:37.208482 28372 sgd_solver.cpp:106] Iteration 29500, lr = 1e-08
I1130 17:57:42.010608 28372 solver.cpp:228] Iteration 29550, loss = 0.60616
I1130 17:57:42.010685 28372 solver.cpp:244]     Train net output #0: loss = 0.60616 (* 1 = 0.60616 loss)
I1130 17:57:42.010695 28372 sgd_solver.cpp:106] Iteration 29550, lr = 1e-08
I1130 17:57:47.700063 28372 solver.cpp:337] Iteration 29600, Testing net (#0)
I1130 17:57:51.363620 28372 blocking_queue.cpp:50] Data layer prefetch queue empty
I1130 17:57:57.070875 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641211
I1130 17:57:58.542898 28372 solver.cpp:404]     Test net output #1: loss = 0.623596 (* 1 = 0.623596 loss)
I1130 17:57:58.591167 28372 solver.cpp:228] Iteration 29600, loss = 0.573365
I1130 17:57:58.591349 28372 solver.cpp:244]     Train net output #0: loss = 0.573365 (* 1 = 0.573365 loss)
I1130 17:57:58.591383 28372 sgd_solver.cpp:106] Iteration 29600, lr = 1e-08
I1130 17:58:02.615850 28372 solver.cpp:228] Iteration 29650, loss = 0.636179
I1130 17:58:02.615912 28372 solver.cpp:244]     Train net output #0: loss = 0.636179 (* 1 = 0.636179 loss)
I1130 17:58:02.615921 28372 sgd_solver.cpp:106] Iteration 29650, lr = 1e-08
I1130 17:58:07.809769 28372 solver.cpp:228] Iteration 29700, loss = 0.696141
I1130 17:58:07.809824 28372 solver.cpp:244]     Train net output #0: loss = 0.696141 (* 1 = 0.696141 loss)
I1130 17:58:07.809829 28372 sgd_solver.cpp:106] Iteration 29700, lr = 1e-08
I1130 17:58:12.663969 28372 solver.cpp:228] Iteration 29750, loss = 0.62253
I1130 17:58:12.664026 28372 solver.cpp:244]     Train net output #0: loss = 0.62253 (* 1 = 0.62253 loss)
I1130 17:58:12.664036 28372 sgd_solver.cpp:106] Iteration 29750, lr = 1e-08
I1130 17:58:17.141808 28372 solver.cpp:337] Iteration 29800, Testing net (#0)
I1130 17:58:26.685837 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641797
I1130 17:58:26.685907 28372 solver.cpp:404]     Test net output #1: loss = 0.623652 (* 1 = 0.623652 loss)
I1130 17:58:26.715550 28372 solver.cpp:228] Iteration 29800, loss = 0.642246
I1130 17:58:26.715603 28372 solver.cpp:244]     Train net output #0: loss = 0.642246 (* 1 = 0.642246 loss)
I1130 17:58:26.715621 28372 sgd_solver.cpp:106] Iteration 29800, lr = 1e-08
I1130 17:58:31.806993 28372 solver.cpp:228] Iteration 29850, loss = 0.54236
I1130 17:58:34.542922 28372 solver.cpp:244]     Train net output #0: loss = 0.54236 (* 1 = 0.54236 loss)
I1130 17:58:34.542953 28372 sgd_solver.cpp:106] Iteration 29850, lr = 1e-08
I1130 17:58:40.042832 28372 solver.cpp:228] Iteration 29900, loss = 0.513496
I1130 17:58:40.042888 28372 solver.cpp:244]     Train net output #0: loss = 0.513496 (* 1 = 0.513496 loss)
I1130 17:58:40.042907 28372 sgd_solver.cpp:106] Iteration 29900, lr = 1e-08
I1130 17:58:45.439180 28372 solver.cpp:228] Iteration 29950, loss = 0.563044
I1130 17:58:45.439240 28372 solver.cpp:244]     Train net output #0: loss = 0.563044 (* 1 = 0.563044 loss)
I1130 17:58:45.439249 28372 sgd_solver.cpp:106] Iteration 29950, lr = 1e-08
I1130 17:58:50.869015 28372 solver.cpp:454] Snapshotting to binary proto file /home/tbochens/Nets/FineTuning/Facebook/thumb_2/solver2/facebook_solv2_iter_30000.caffemodel
I1130 17:58:51.810055 28372 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /home/tbochens/Nets/FineTuning/Facebook/thumb_2/solver2/facebook_solv2_iter_30000.solverstate
I1130 17:58:52.171591 28372 solver.cpp:317] Iteration 30000, loss = 0.622267
I1130 17:58:52.171624 28372 solver.cpp:337] Iteration 30000, Testing net (#0)
I1130 17:59:00.601478 28372 solver.cpp:404]     Test net output #0: accuracy = 0.641862
I1130 17:59:00.601548 28372 solver.cpp:404]     Test net output #1: loss = 0.623002 (* 1 = 0.623002 loss)
I1130 17:59:00.601553 28372 solver.cpp:322] Optimization Done.
I1130 17:59:00.601557 28372 caffe.cpp:254] Optimization Done.
